{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f764a8c0",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc5131e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version:  0.23.1\n",
      "TF version:  2.6.0\n",
      "GPU installed:  True\n",
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "print(\"sklearn version: \", sklearn.__version__)\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "print(\"TF version: \", tf.__version__)\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "# GPU test\n",
    "print(\"GPU installed: \",tf.test.is_built_with_gpu_support())\n",
    "\n",
    "# To prevent \"CUDNN_STATUS_ALLOC_FAILED\" error with GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "    \n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"cnn\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "    \n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")    \n",
    "\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebe6228",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb392325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#작성자 전민재\n",
    "import csv\n",
    "def load_Emist(exsitNumpy=False, needTranspose=True):\n",
    "    if (exsitNumpy == False):\n",
    "        #\"./emnist-byclass-test.csv\"\n",
    "        #train-set\n",
    "        #\"공용/datasets/Emnist/\" 위치에 csv 저장 \n",
    "        csv_train_data_file = open(\"../공용/datasets/Emnist/train_data.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "        csv_train_label_file = open(\"../공용/datasets/Emnist/train_label.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "    \n",
    "        \n",
    "        f_train = csv.reader(csv_train_data_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "        l_train=csv.reader(csv_train_label_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "        #valid-set\n",
    "    \n",
    "        csv_valid_data_file = open(\"../공용/datasets/Emnist/valid_data.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "        csv_valid_label_file = open(\"../공용/datasets/Emnist/valid_label.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "        \n",
    "        f_valid = csv.reader(csv_valid_data_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "        l_valid = csv.reader(csv_valid_label_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "        X_train=[]\n",
    "        y_train=[]\n",
    "        X_valid=[]\n",
    "        y_valid=[]\n",
    "        for i, row in enumerate(f_train):\n",
    "            #행마다 int로 형변환\n",
    "            for idx, char in enumerate(row):\n",
    "                row[idx]=int(char)\n",
    "            #train\n",
    "            #data 추가    \n",
    "            X_train.append(row)\n",
    "            \n",
    "        for i, row in enumerate(f_valid):\n",
    "            #행마다 int로 형변환\n",
    "            for idx, char in enumerate(row):\n",
    "                row[idx]=int(char)\n",
    "            #valid\n",
    "            #data 추가    \n",
    "            X_valid.append(row)\n",
    "\n",
    "\n",
    "        for i, row in enumerate(l_train):\n",
    "\n",
    "            #train\n",
    "            #label 추가\n",
    "            y_train.append(int(row[0]))\n",
    "            \n",
    "        for i, row in enumerate(l_valid):\n",
    "\n",
    "            #valid\n",
    "            #label 추가\n",
    "            y_valid.append(int(row[0]))\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "        #train\n",
    "        X_train=np.array(X_train,dtype=np.uint8)\n",
    "        X_train=X_train.reshape(-1,28,28)\n",
    "        #valid\n",
    "        X_valid=np.array(X_valid,dtype=np.uint8)\n",
    "        X_valid=X_valid.reshape(-1,28,28)\n",
    "        \n",
    "        csv_train_data_file.close()\n",
    "        csv_train_label_file.close()\n",
    "        csv_valid_data_file.close()\n",
    "        csv_valid_label_file.close()\n",
    "        \n",
    "        #kaggle dataset이 시계반대방향으로 90도 회전 되있고 상하 반전 되어있음\n",
    "        def rotate_90(m):\n",
    "            N = len(m)\n",
    "            ret = [[0] * N for _ in range(N)]\n",
    "\n",
    "            for r in range(N):\n",
    "                for c in range(N):\n",
    "                    ret[c][N-1-r] = m[r][c]\n",
    "            return np.array(ret,dtype=np.uint8)\n",
    "\n",
    "        def vreflect(m):\n",
    "            N = len(m)\n",
    "            ret = [[0] * N for _ in range(N)]\n",
    "\n",
    "            for r in range(N):\n",
    "                for c in range(N):\n",
    "                    ret[r][c] = m[r][N-1-c]\n",
    "            return np.array(ret,dtype=np.uint8)\n",
    "        \n",
    "        if needTranspose == True:\n",
    "            #train\n",
    "            #회전\n",
    "            for idx,i in enumerate(X_train):\n",
    "                X_train[idx]=rotate_90(i)\n",
    "            #상하반전\n",
    "            for idx,i in enumerate(X_train):\n",
    "                X_train[idx]=vreflect(i)\n",
    "\n",
    "            #valid\n",
    "            #회전\n",
    "            for idx,i in enumerate(X_valid):\n",
    "                X_valid[idx]=rotate_90(i)\n",
    "            #상하반전\n",
    "            for idx,i in enumerate(X_valid):\n",
    "                X_valid[idx]=vreflect(i)\n",
    "\n",
    "       \n",
    "        \n",
    "        \n",
    "        #저장용\n",
    "        #train\n",
    "        #(533917,28,28)\n",
    "        \n",
    "        np.save('../공용/X_train',np.array(X_train,dtype=np.uint8))\n",
    "        np.save('../공용/y_train',np.array(y_train,dtype=np.uint8))\n",
    "        #valid\n",
    "        np.save('../공용/X_valid',np.array(X_valid,dtype=np.uint8))\n",
    "        np.save('../공용/y_valid',np.array(y_valid,dtype=np.uint8))\n",
    "        \n",
    "   \n",
    "    X_train=np.load('../공용/X_train.npy')\n",
    "    y_train=np.load('../공용/y_train.npy')\n",
    "    X_valid=np.load('../공용/X_valid.npy')\n",
    "    y_valid=np.load('../공용/y_valid.npy')\n",
    "    \n",
    "    return X_train, y_train, X_valid, y_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "992ca3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((533917, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현\n",
    "#npy 파일이 존재할 경우 exsitNumpy = True, 업으면 False\n",
    "X_train, y_train, X_valid, y_valid = load_Emist(exsitNumpy=True)\n",
    "X_train.shape,X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "95670441",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_letters = X_train[np.where(y_train>10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0bcfaf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_letters = y_train[np.where(y_train>10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0fc68fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (3):\n",
    "    X_train = np.append(X_train,X_train_letters,axis=0)\n",
    "    y_train = np.append(y_train, y_train_letters,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1010600b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1329679, 28, 28)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75d32e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_letters, y_train_letters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b59908c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "ids=1\n",
    "X_new=X_train[ids]\n",
    "y_new=y_train[ids]\n",
    "c=X_new.reshape(28,28)\n",
    "\n",
    "\n",
    "plt.imshow(c, cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6210caf",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d0d3c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1329679"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현\n",
    "#data, batch size 성정\n",
    "train_size=len(X_train)\n",
    "valid_size=len(X_valid)\n",
    "batch_size=16\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fa708fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1329679, 784), (164015, 784))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현\n",
    "X_train=np.reshape(X_train,[-1,784])\n",
    "X_valid=np.reshape(X_valid,[-1,784])\n",
    "X_train.shape,X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8a28503f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1329679, 1), (164015, 1))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현\n",
    "y_train=np.reshape(y_train,[-1,1])\n",
    "y_valid=np.reshape(y_valid,[-1,1])\n",
    "\n",
    "y_train.shape,y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a2a03a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_inputs = 784\n"
     ]
    }
   ],
   "source": [
    "n_inputs = X_train.shape[-1]\n",
    "print(\"n_inputs =\",n_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "440f1be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10, rewrite=False):\n",
    "    \n",
    "    Emnist_dir = os.path.join(\"../공용/datasets\", \"Emnist\")\n",
    "    os.makedirs(Emnist_dir, exist_ok=True)\n",
    "    path_format = os.path.join(Emnist_dir, \"my_{}_{:02d}.csv\")\n",
    "\n",
    "    filepaths = []\n",
    "    m = len(data)\n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        filepaths.append(part_csv)\n",
    "        if rewrite:\n",
    "            \n",
    "            try:\n",
    "                with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
    "                    if header is not None:\n",
    "                        f.write(header)\n",
    "                        f.write(\"\\n\")\n",
    "                    for row_idx in row_indices:\n",
    "                        f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                        f.write(\"\\n\")\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            try:\n",
    "                with open(part_csv, \"xt\", encoding=\"utf-8\") as f:\n",
    "                    if header is not None:\n",
    "                        f.write(header)\n",
    "                        f.write(\"\\n\")\n",
    "                    for row_idx in row_indices:\n",
    "                        f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                        f.write(\"\\n\")\n",
    "            except:\n",
    "                continue\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "11127cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full=np.append(X_train,y_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "64f1f30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1329679, 785)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a64fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "#메모리 해제\n",
    "del X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe23c2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2244"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c0e91e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "train_filepaths = save_to_multiple_csv_files(train_full, \"train\", n_parts=20,rewrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dad8af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_full=np.append(X_valid,y_valid,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "348552a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "#메모리 해제\n",
    "del X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7a06441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b4dd6f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "\n",
    "valid_filepaths = save_to_multiple_csv_files(valid_full, \"valid\", n_parts=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0394a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현\n",
    "#메모리 해제\n",
    "import gc\n",
    "del valid_full, train_full\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce6bf342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "\n",
    "def dataaugmentation(X):\n",
    "    datagen=ImageDataGenerator(rotation_range=40,width_shift_range = 0.2, \n",
    "        height_shift_range = 0.2)\n",
    "    #영어 부분 2배 생성\n",
    "    #차원변환 \n",
    "    X=tf.reshape(X,[28,28,1])\n",
    "\n",
    "    #새로운 데이터 생성\n",
    "    angle=(random.random()%1)*0.8 - 0.4\n",
    "    image_result =tfa.image.rotate(X, tf.constant(angle))#rotate -pi/10 ~ pi/10\n",
    "    shift=(random.random()%1)*2 - 1\n",
    "    image_result=tfa.image.translate(image_result,[tf.constant(shift),tf.constant(shift)])\n",
    "    \n",
    "    return image_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "02720cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "@tf.function\n",
    "def preprocess_mobilenet_v2(line,randomize=False):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    x=tf.reshape(x,[28,28,1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    augment_image = x\n",
    "    if y > 10 and randomize:\n",
    "        augment_image = dataaugmentation(x)\n",
    "        \n",
    "        \n",
    "    resized_image = tf.image.resize(augment_image, [224, 224])\n",
    "    if resized_image.shape[2] == 1:\n",
    "        temp=tf.concat([resized_image,resized_image],2)\n",
    "        resized_image=tf.concat([temp,resized_image],2)\n",
    "    final_image = keras.applications.mobilenet_v2.preprocess_input(resized_image)\n",
    "    \n",
    "    return final_image, y\n",
    "\n",
    "@tf.function\n",
    "def preprocess_resnet50(line,randomize=False):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    x=tf.reshape(x,[28,28,1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    augment_image = x\n",
    "    if y > 10 and randomize:\n",
    "        augment_image = dataaugmentation(x)\n",
    "        \n",
    "        \n",
    "    resized_image = tf.image.resize(augment_image, [224, 224])\n",
    "    if resized_image.shape[2] == 1:\n",
    "        temp=tf.concat([resized_image,resized_image],2)\n",
    "        resized_image=tf.concat([temp,resized_image],2)\n",
    "    final_image = keras.applications.resnet50.preprocess_input(resized_image)\n",
    "    \n",
    "    return final_image, y\n",
    "\n",
    "@tf.function\n",
    "def preprocess_vgg16(line,randomize=False):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    x=tf.reshape(x,[28,28,1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    augment_image = x\n",
    "    if y > 10 and randomize:\n",
    "        augment_image = dataaugmentation(x)\n",
    "        \n",
    "        \n",
    "    resized_image = tf.image.resize(augment_image, [224, 224])\n",
    "    if resized_image.shape[2] == 1:\n",
    "        temp=tf.concat([resized_image,resized_image],2)\n",
    "        resized_image=tf.concat([temp,resized_image],2)\n",
    "    final_image = keras.applications.vgg16.preprocess_input(resized_image)\n",
    "    \n",
    "    return final_image, y\n",
    "\n",
    "@tf.function\n",
    "def preprocess_renet(line,randomize=False):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    x=tf.reshape(x,[28,28,1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    augment_image = x\n",
    "    if y > 10 and randomize:\n",
    "        augment_image = dataaugmentation(x)\n",
    "        \n",
    "   \n",
    "    return augment_image, y\n",
    "\n",
    "@tf.function\n",
    "def preprocess_xception(line,randomize=False):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    x=tf.reshape(x,[28,28,1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    augment_image = x\n",
    "    if y > 10 and randomize:\n",
    "        augment_image = dataaugmentation(x)\n",
    "        \n",
    "        \n",
    "    resized_image = tf.image.resize(augment_image, [224, 224])\n",
    "    if resized_image.shape[2] == 1:\n",
    "        temp=tf.concat([resized_image,resized_image],2)\n",
    "        resized_image=tf.concat([temp,resized_image],2)\n",
    "    final_image = keras.applications.xception.preprocess_input(resized_image)\n",
    "    \n",
    "    return final_image, y\n",
    "\n",
    "@tf.function\n",
    "def preprocess_inception_v3(line,randomize=False):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    x=tf.reshape(x,[28,28,1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    augment_image = x\n",
    "    if y > 10 and randomize:\n",
    "        augment_image = dataaugmentation(x)\n",
    "        \n",
    "        \n",
    "    resized_image = tf.image.resize(augment_image, [224, 224])\n",
    "    if resized_image.shape[2] == 1:\n",
    "        temp=tf.concat([resized_image,resized_image],2)\n",
    "        resized_image=tf.concat([temp,resized_image],2)\n",
    "    final_image = keras.applications.inception_v3.preprocess_input(resized_image)\n",
    "    \n",
    "    return final_image, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f19c3404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "from enum import Enum\n",
    "class eModelName(Enum):\n",
    "    mobilenet_v2 = 0,\n",
    "    resnet50 = 1,\n",
    "    vgg16 = 3,\n",
    "    renet = 4,\n",
    "    xception = 5,\n",
    "    inception_v3 = 6\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e800fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "from functools import partial\n",
    "def csv_reader_dataset(filepaths, model_name, repeat=1, n_readers=5,\n",
    "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
    "                       n_parse_threads=5, batch_size=32,randomize=True):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    if model_name == eModelName.mobilenet_v2:\n",
    "        dataset = dataset.map(partial(preprocess_mobilenet_v2,randomize=randomize), num_parallel_calls=n_parse_threads)\n",
    "        print(model_name.name)\n",
    "    elif model_name == eModelName.resnet50:\n",
    "        dataset = dataset.map(partial(preprocess_resnet50,randomize=randomize), num_parallel_calls=n_parse_threads)\n",
    "        print(model_name.name)\n",
    "    elif model_name == eModelName.vgg16:\n",
    "        dataset = dataset.map(partial(preprocess_vgg16,randomize=randomize), num_parallel_calls=n_parse_threads)\n",
    "        print(model_name.name)\n",
    "    elif model_name == eModelName.renet:\n",
    "        dataset = dataset.map(partial(preprocess_renet,randomize=randomize), num_parallel_calls=n_parse_threads)\n",
    "        print(model_name.name)\n",
    "    elif model_name == eModelName.xception:\n",
    "        dataset = dataset.map(partial(preprocess_xception,randomize=randomize), num_parallel_calls=n_parse_threads)\n",
    "        print(model_name.name)\n",
    "    elif model_name == eModelName.inception_v3:\n",
    "        dataset = dataset.map(partial(preprocess_inception_v3,randomize=randomize), num_parallel_calls=n_parse_threads)\n",
    "        print(model_name.name)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bbe46310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_v2\n",
      "mobilenet_v2\n",
      "mobilenet_v2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset shapes: ((None, 224, 224, 3), (None, 1)), types: (tf.float32, tf.float32)>,\n",
       " <PrefetchDataset shapes: ((None, 224, 224, 3), (None, 1)), types: (tf.float32, tf.float32)>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현\n",
    "#csv_reader_dataset의 파라미터 model_name에 eModelNAme class의 맴버 변수 중 사용할 모델 입력\n",
    "#ex) model_name = eModelName.inception_v3, model_name = eModelName.renet \n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "train_set = csv_reader_dataset(train_filepaths, model_name = eModelName.mobilenet_v2, batch_size=batch_size, \n",
    "                               repeat=None,n_read_threads=tf.data.experimental.AUTOTUNE)\n",
    "train_set_noaug = csv_reader_dataset(train_filepaths, model_name = eModelName.mobilenet_v2, batch_size=batch_size, \n",
    "                               repeat=None,n_read_threads=tf.data.experimental.AUTOTUNE, randomize = False)\n",
    "valid_set = csv_reader_dataset(valid_filepaths, model_name = eModelName.mobilenet_v2, batch_size=batch_size, \n",
    "                               n_read_threads=tf.data.experimental.AUTOTUNE, repeat=None, randomize = False)\n",
    "train_set_noaug,valid_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6e2e3b",
   "metadata": {},
   "source": [
    "# SMV2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d633ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "class Inveted_Residual_Block(keras.layers.Layer):\n",
    "    def __init__(self,c,s=1,t=1,n=1,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.layers.ReLU(max_value=6)\n",
    "        self.main_layers = [\n",
    "            \n",
    "            ]\n",
    "        self.strides_layers=[\n",
    "           ]\n",
    "        self.s=s\n",
    "        self.t=t\n",
    "        self.c=c\n",
    "        self.n=n\n",
    "        \n",
    "    def build(self,batch_input_shape):\n",
    "        print(self.name,\": batch_input_shape =\",batch_input_shape)\n",
    "        \n",
    "        self.main_layers = [\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=batch_input_shape[-1]*self.t, kernel_size=1,strides=1, \n",
    "                                padding=\"SAME\", activation=self.activation),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.DepthwiseConv2D(kernel_size=3, strides=1,padding=\"SAME\", activation=self.activation),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=self.c,kernel_size=1, strides=1,padding=\"SAME\", activation=self.activation),\n",
    "            ]\n",
    "        self.strides_layers=[\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=batch_input_shape[-1]*self.t, kernel_size=1,strides=1,\n",
    "                                padding=\"SAME\", activation=self.activation),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.DepthwiseConv2D(kernel_size=3, strides=self.s,padding=\"SAME\",activation=self.activation),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=self.c, kernel_size=1,strides=1,padding=\"SAME\",activation=self.activation),\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        \n",
    "        for n in range(0,self.n):\n",
    "            if n == 0:\n",
    "                for layer in self.strides_layers:\n",
    "                    Z = layer(Z)\n",
    "            else:\n",
    "                skip_Z = Z\n",
    "                for layer in self.main_layers:\n",
    "                    Z = layer(Z)\n",
    "                \n",
    "                Z += skip_Z\n",
    "    \n",
    "        return Z\n",
    "    \n",
    "    def get_config(self):\n",
    "        base=super().get_config()\n",
    "        return{**base,\"s\":self.s,\"t\":self.t,\"c\":self.c,\"n\":self.n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "558fc86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "IRB1 : batch_input_shape = (None, 112, 112, 32)\n",
      "IRB2 : batch_input_shape = (None, 112, 112, 16)\n",
      "IRB3 : batch_input_shape = (None, 56, 56, 16)\n",
      "IRB4 : batch_input_shape = (None, 28, 28, 32)\n",
      "IRB5 : batch_input_shape = (None, 14, 14, 64)\n",
      "IRB6 : batch_input_shape = (None, 7, 7, 128)\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_15 (Batc (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 112, 112, 32)      896       \n",
      "_________________________________________________________________\n",
      "IRB1 (Inveted_Residual_Block (None, 112, 112, 16)      2288      \n",
      "_________________________________________________________________\n",
      "IRB2 (Inveted_Residual_Block (None, 56, 56, 16)        6688      \n",
      "_________________________________________________________________\n",
      "IRB3 (Inveted_Residual_Block (None, 28, 28, 32)        19456     \n",
      "_________________________________________________________________\n",
      "IRB4 (Inveted_Residual_Block (None, 14, 14, 64)        67584     \n",
      "_________________________________________________________________\n",
      "IRB5 (Inveted_Residual_Block (None, 7, 7, 128)         108416    \n",
      "_________________________________________________________________\n",
      "IRB6 (Inveted_Residual_Block (None, 7, 7, 1024)        1200640   \n",
      "_________________________________________________________________\n",
      "re_lu_55 (ReLU)              (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 62)                63550     \n",
      "=================================================================\n",
      "Total params: 1,473,626\n",
      "Trainable params: 1,460,916\n",
      "Non-trainable params: 12,710\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#황성현\n",
    "#multygpu\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[224,224,3]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "831ada96",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'smv2_l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-8d775c489bbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcheck_last_cb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"smv2l_nadam_last.h5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mearlystop_cb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m history=smv2_l.fit(train_set, batch_size = batch_size,\n\u001b[0m\u001b[1;32m     12\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_size\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'smv2_l' is not defined"
     ]
    }
   ],
   "source": [
    "#황성현 \n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L%Y%m%d-%H%M%S\")\n",
    "\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_last.h5\",save_best_only=True)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_l.fit(train_set, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495173b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "smv2_l.save(\"smv2l_nadam_last.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab6bdb5",
   "metadata": {},
   "source": [
    "# SMV2P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cea33932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 112, 112, 32)\n",
      "IRB2 : batch_input_shape = (None, 112, 112, 16)\n",
      "IRB3 : batch_input_shape = (None, 56, 56, 32)\n",
      "IRB4 : batch_input_shape = (None, 28, 28, 64)\n",
      "IRB5 : batch_input_shape = (None, 14, 14, 64)\n",
      "IRB6 : batch_input_shape = (None, 7, 7, 128)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_4 (Batch (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 32)      896       \n",
      "_________________________________________________________________\n",
      "IRB1 (Inveted_Residual_Block (None, 112, 112, 16)      2288      \n",
      "_________________________________________________________________\n",
      "IRB2 (Inveted_Residual_Block (None, 56, 56, 32)        9856      \n",
      "_________________________________________________________________\n",
      "IRB3 (Inveted_Residual_Block (None, 28, 28, 64)        67584     \n",
      "_________________________________________________________________\n",
      "IRB4 (Inveted_Residual_Block (None, 14, 14, 64)        151168    \n",
      "_________________________________________________________________\n",
      "IRB5 (Inveted_Residual_Block (None, 7, 7, 128)         108416    \n",
      "_________________________________________________________________\n",
      "IRB6 (Inveted_Residual_Block (None, 7, 7, 1024)        1200640   \n",
      "_________________________________________________________________\n",
      "re_lu_20 (ReLU)              (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 62)                63550     \n",
      "=================================================================\n",
      "Total params: 1,608,506\n",
      "Trainable params: 1,592,532\n",
      "Non-trainable params: 15,974\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#황성현\n",
    "with strategy.scope():\n",
    "    n_classes=62\n",
    "    smv2_p=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[224,224,3]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=32,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_p.summary()\n",
    "    smv2_p.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "33c8228f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "INFO:tensorflow:batch_all_reduce: 116 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 116 all-reduces with algorithm = nccl, num_packs = 1\n",
      "41552/41552 [==============================] - 4478s 107ms/step - loss: 0.3839 - accuracy: 0.8680 - val_loss: 5.9704 - val_accuracy: 0.3080\n",
      "Epoch 2/300\n",
      "41552/41552 [==============================] - 4422s 106ms/step - loss: 0.3190 - accuracy: 0.8827 - val_loss: 2.1717 - val_accuracy: 0.6591\n",
      "Epoch 3/300\n",
      "41552/41552 [==============================] - 4420s 106ms/step - loss: 0.2998 - accuracy: 0.8894 - val_loss: 2.7346 - val_accuracy: 0.6143\n",
      "Epoch 4/300\n",
      "41552/41552 [==============================] - 4411s 106ms/step - loss: 0.3061 - accuracy: 0.8864 - val_loss: 1.8020 - val_accuracy: 0.7005\n",
      "Epoch 5/300\n",
      "41552/41552 [==============================] - 4424s 106ms/step - loss: 0.3005 - accuracy: 0.8882 - val_loss: 2.5975 - val_accuracy: 0.6392\n",
      "Epoch 6/300\n",
      "41552/41552 [==============================] - 4401s 106ms/step - loss: 0.3003 - accuracy: 0.8884 - val_loss: 1.7739 - val_accuracy: 0.6988\n",
      "Epoch 7/300\n",
      "41552/41552 [==============================] - 4418s 106ms/step - loss: 0.3221 - accuracy: 0.8795 - val_loss: 2.3270 - val_accuracy: 0.6572\n",
      "Epoch 8/300\n",
      "41552/41552 [==============================] - 4421s 106ms/step - loss: 0.2990 - accuracy: 0.8886 - val_loss: 1.7881 - val_accuracy: 0.6934\n",
      "Epoch 9/300\n",
      "41552/41552 [==============================] - 4446s 107ms/step - loss: 0.3157 - accuracy: 0.8828 - val_loss: 1.3234 - val_accuracy: 0.7524\n",
      "Epoch 10/300\n",
      "41552/41552 [==============================] - 4461s 107ms/step - loss: 0.3381 - accuracy: 0.8744 - val_loss: 12.6891 - val_accuracy: 0.0540\n",
      "Epoch 11/300\n",
      "41552/41552 [==============================] - 4456s 107ms/step - loss: 0.3188 - accuracy: 0.8810 - val_loss: 1.6040 - val_accuracy: 0.7113\n",
      "Epoch 12/300\n",
      "41552/41552 [==============================] - 4473s 108ms/step - loss: 0.3073 - accuracy: 0.8862 - val_loss: 1.8713 - val_accuracy: 0.6818\n",
      "Epoch 13/300\n",
      "41552/41552 [==============================] - 4468s 108ms/step - loss: 3.5037 - accuracy: 0.1410 - val_loss: 60.9303 - val_accuracy: 0.0034\n",
      "Epoch 14/300\n",
      "41552/41552 [==============================] - 4444s 107ms/step - loss: 3.8621 - accuracy: 0.0588 - val_loss: 31.5947 - val_accuracy: 0.0026\n",
      "Epoch 15/300\n",
      "41552/41552 [==============================] - 4450s 107ms/step - loss: 3.8667 - accuracy: 0.0552 - val_loss: 48.2032 - val_accuracy: 0.0025\n",
      "Epoch 16/300\n",
      "41552/41552 [==============================] - 4386s 106ms/step - loss: 3.8738 - accuracy: 0.0592 - val_loss: 13.4360 - val_accuracy: 0.0089\n",
      "Epoch 17/300\n",
      "41552/41552 [==============================] - 4374s 105ms/step - loss: 3.8544 - accuracy: 0.0553 - val_loss: 10.2395 - val_accuracy: 0.0073\n",
      "Epoch 18/300\n",
      "41552/41552 [==============================] - 4362s 105ms/step - loss: 3.8699 - accuracy: 0.0570 - val_loss: 17.0552 - val_accuracy: 0.0073\n",
      "Epoch 19/300\n",
      "41552/41552 [==============================] - 4372s 105ms/step - loss: 3.8555 - accuracy: 0.0571 - val_loss: 21.8589 - val_accuracy: 0.0044\n"
     ]
    }
   ],
   "source": [
    "#황성현 \n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2P%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2p_nadam_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2p_nadam_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_p.fit(train_set, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d0b2fc",
   "metadata": {},
   "source": [
    "min val loss = 1.3234 at 9 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "811798e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 112, 112, 32)\n",
      "IRB2 : batch_input_shape = (None, 112, 112, 16)\n",
      "IRB3 : batch_input_shape = (None, 56, 56, 32)\n",
      "IRB4 : batch_input_shape = (None, 28, 28, 64)\n",
      "IRB5 : batch_input_shape = (None, 14, 14, 64)\n",
      "IRB6 : batch_input_shape = (None, 7, 7, 128)\n"
     ]
    }
   ],
   "source": [
    "smv2_p=keras.models.load_model(\n",
    "    \"smv2p_nadam_best.h5\",custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bb71888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "939b80ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 17285), started 9:56:56 ago. (Use '!kill 17285' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ade5fa72bbfc5cb0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ade5fa72bbfc5cb0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/SMV2P20220525-203629"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c2b5b343",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: Input 0 of layer sequential_8 is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: (None, 28, 28)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dsd/.local/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n",
      "    yield\n",
      "  File \"/home/dsd/.local/lib/python3.6/site-packages/tensorflow/python/distribute/mirrored_run.py\", line 346, in run\n",
      "    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n",
      "  File \"/home/dsd/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 692, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/home/dsd/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 382, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/home/dsd/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 463, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/dsd/.local/lib/python3.6/site-packages/keras/engine/training.py\", line 1313, in run_step\n",
      "    outputs = model.test_step(data)\n",
      "  File \"/home/dsd/.local/lib/python3.6/site-packages/keras/engine/training.py\", line 1267, in test_step\n",
      "    y_pred = self(x, training=False)\n",
      "  File \"/home/dsd/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 1020, in __call__\n",
      "    input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n",
      "  File \"/home/dsd/.local/lib/python3.6/site-packages/keras/engine/input_spec.py\", line 218, in assert_input_compatibility\n",
      "    str(tuple(shape)))\n",
      "ValueError: Input 0 of layer sequential_8 is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: (None, 28, 28)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/dsd/.local/lib/python3.6/site-packages/keras/engine/training.py:1330 test_function  *\n        return step_function(self, iterator)\n    /home/dsd/.local/lib/python3.6/site-packages/keras/engine/training.py:1320 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/dsd/.local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/dsd/.local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/dsd/.local/lib/python3.6/site-packages/tensorflow/python/distribute/mirrored_strategy.py:671 _call_for_each_replica\n        self._container_strategy(), fn, args, kwargs)\n    /home/dsd/.local/lib/python3.6/site-packages/tensorflow/python/distribute/mirrored_run.py:104 call_for_each_replica\n        return _call_for_each_replica(strategy, fn, args, kwargs)\n    /home/dsd/.local/lib/python3.6/site-packages/tensorflow/python/distribute/mirrored_run.py:246 _call_for_each_replica\n        coord.join(threads)\n    /home/dsd/.local/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py:389 join\n        six.reraise(*self._exc_info_to_raise)\n    /home/dsd/.local/lib/python3.6/site-packages/six.py:703 reraise\n        raise value\n    /home/dsd/.local/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py:297 stop_on_exception\n        yield\n    /home/dsd/.local/lib/python3.6/site-packages/tensorflow/python/distribute/mirrored_run.py:346 run\n        self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n    /home/dsd/.local/lib/python3.6/site-packages/keras/engine/training.py:1313 run_step  **\n        outputs = model.test_step(data)\n    /home/dsd/.local/lib/python3.6/site-packages/keras/engine/training.py:1267 test_step\n        y_pred = self(x, training=False)\n    /home/dsd/.local/lib/python3.6/site-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/dsd/.local/lib/python3.6/site-packages/keras/engine/input_spec.py:218 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_8 is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: (None, 28, 28)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-04e47490cfe0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msmv2_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m-> 3038\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3458\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3459\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3460\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3381\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3382\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3383\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/dsd/.local/lib/python3.6/site-packages/keras/engine/training.py:1330 test_function  *\n        return step_function(self, iterator)\n    /home/dsd/.local/lib/python3.6/site-packages/keras/engine/training.py:1320 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/dsd/.local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/dsd/.local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/dsd/.local/lib/python3.6/site-packages/tensorflow/python/distribute/mirrored_strategy.py:671 _call_for_each_replica\n        self._container_strategy(), fn, args, kwargs)\n    /home/dsd/.local/lib/python3.6/site-packages/tensorflow/python/distribute/mirrored_run.py:104 call_for_each_replica\n        return _call_for_each_replica(strategy, fn, args, kwargs)\n    /home/dsd/.local/lib/python3.6/site-packages/tensorflow/python/distribute/mirrored_run.py:246 _call_for_each_replica\n        coord.join(threads)\n    /home/dsd/.local/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py:389 join\n        six.reraise(*self._exc_info_to_raise)\n    /home/dsd/.local/lib/python3.6/site-packages/six.py:703 reraise\n        raise value\n    /home/dsd/.local/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py:297 stop_on_exception\n        yield\n    /home/dsd/.local/lib/python3.6/site-packages/tensorflow/python/distribute/mirrored_run.py:346 run\n        self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n    /home/dsd/.local/lib/python3.6/site-packages/keras/engine/training.py:1313 run_step  **\n        outputs = model.test_step(data)\n    /home/dsd/.local/lib/python3.6/site-packages/keras/engine/training.py:1267 test_step\n        y_pred = self(x, training=False)\n    /home/dsd/.local/lib/python3.6/site-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/dsd/.local/lib/python3.6/site-packages/keras/engine/input_spec.py:218 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_8 is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: (None, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "smv2_p.evaluate(X_valid[np.where(y_valid>10)],y_valid[np.where(y_valid>10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3f0a1e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "smv2p_pred=smv2_p.predict(valid_set,steps=int(valid_size/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a56bbb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_GPU_THREAD_MODE\"]=\"gpu_private\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639541bc",
   "metadata": {},
   "source": [
    "# smv2p fit no augmentation train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4af5a253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "IRB1 : batch_input_shape = (None, 112, 112, 32)\n",
      "IRB2 : batch_input_shape = (None, 112, 112, 16)\n",
      "IRB3 : batch_input_shape = (None, 56, 56, 32)\n",
      "IRB4 : batch_input_shape = (None, 28, 28, 64)\n",
      "IRB5 : batch_input_shape = (None, 14, 14, 64)\n",
      "IRB6 : batch_input_shape = (None, 7, 7, 128)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_6 (Batch (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 32)      896       \n",
      "_________________________________________________________________\n",
      "IRB1 (Inveted_Residual_Block (None, 112, 112, 16)      2288      \n",
      "_________________________________________________________________\n",
      "IRB2 (Inveted_Residual_Block (None, 56, 56, 32)        9856      \n",
      "_________________________________________________________________\n",
      "IRB3 (Inveted_Residual_Block (None, 28, 28, 64)        67584     \n",
      "_________________________________________________________________\n",
      "IRB4 (Inveted_Residual_Block (None, 14, 14, 64)        151168    \n",
      "_________________________________________________________________\n",
      "IRB5 (Inveted_Residual_Block (None, 7, 7, 128)         108416    \n",
      "_________________________________________________________________\n",
      "IRB6 (Inveted_Residual_Block (None, 7, 7, 1024)        1200640   \n",
      "_________________________________________________________________\n",
      "re_lu_27 (ReLU)              (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 62)                63550     \n",
      "=================================================================\n",
      "Total params: 1,608,506\n",
      "Trainable params: 1,592,532\n",
      "Non-trainable params: 15,974\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#황성현\n",
    "#multygpu\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    n_classes=62\n",
    "    smv2_p_noaug=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[224,224,3]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=32,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_p_noaug.summary()\n",
    "    smv2_p_noaug.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69c4ae11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/SMV2P_NOAUG20220528-150031\n",
      "Epoch 1/200\n",
      "INFO:tensorflow:batch_all_reduce: 116 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 116 all-reduces with algorithm = nccl, num_packs = 1\n",
      "16684/16684 [==============================] - 1862s 109ms/step - loss: 0.5501 - accuracy: 0.8159 - val_loss: 0.4324 - val_accuracy: 0.8431\n",
      "Epoch 2/200\n",
      "16684/16684 [==============================] - 1806s 108ms/step - loss: 0.4065 - accuracy: 0.8536 - val_loss: 18.6655 - val_accuracy: 0.0065\n",
      "Epoch 3/200\n",
      "16684/16684 [==============================] - 1809s 108ms/step - loss: 0.3934 - accuracy: 0.8566 - val_loss: 0.3841 - val_accuracy: 0.8563\n",
      "Epoch 4/200\n",
      "16684/16684 [==============================] - 1812s 109ms/step - loss: 0.3763 - accuracy: 0.8625 - val_loss: 0.3960 - val_accuracy: 0.8534\n",
      "Epoch 5/200\n",
      "16684/16684 [==============================] - 1817s 109ms/step - loss: 0.3763 - accuracy: 0.8615 - val_loss: 0.5103 - val_accuracy: 0.8172\n",
      "Epoch 6/200\n",
      "16684/16684 [==============================] - 1814s 109ms/step - loss: 0.3715 - accuracy: 0.8629 - val_loss: 0.3766 - val_accuracy: 0.8617\n",
      "Epoch 7/200\n",
      "16684/16684 [==============================] - 1804s 108ms/step - loss: 0.3680 - accuracy: 0.8644 - val_loss: 0.3707 - val_accuracy: 0.8629\n",
      "Epoch 8/200\n",
      "16684/16684 [==============================] - 1801s 108ms/step - loss: 0.3625 - accuracy: 0.8656 - val_loss: 0.3671 - val_accuracy: 0.8660\n",
      "Epoch 9/200\n",
      "16684/16684 [==============================] - 1802s 108ms/step - loss: 0.3662 - accuracy: 0.8648 - val_loss: 1.5798 - val_accuracy: 0.6430\n",
      "Epoch 10/200\n",
      "   70/16684 [..............................] - ETA: 29:36 - loss: 0.4196 - accuracy: 0.8411"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-d164b3600ddf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_size\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     epochs=200,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb,lr_callback])\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#황성현 \n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2P_NOAUG%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2p_noaug_nadam_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2p_noaug_nadam_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "lr_callback=keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.5)\n",
    "history2=smv2_p_noaug.fit(train_set_noaug, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=200,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb,lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a2ce058",
   "metadata": {},
   "outputs": [],
   "source": [
    "smv2_p_noaug.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",metrics=[\"accuracy\"],\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb58daee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/SMV2P_NOAUG20220528-193809\n",
      "ERROR:tensorflow:Failed to start profiler: Another profiler is running.\n",
      "Epoch 1/200\n",
      "INFO:tensorflow:batch_all_reduce: 116 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 116 all-reduces with algorithm = nccl, num_packs = 1\n",
      "  499/16684 [..............................] - ETA: 28:34 - loss: 0.3699 - accuracy: 0.8660ERROR:tensorflow:Failed to start profiler: Another profiler is running.\n",
      "16684/16684 [==============================] - 1869s 111ms/step - loss: 0.3633 - accuracy: 0.8659 - val_loss: 0.3677 - val_accuracy: 0.8637\n",
      "Epoch 2/200\n",
      "16684/16684 [==============================] - 1879s 113ms/step - loss: 0.3564 - accuracy: 0.8670 - val_loss: 1.4050 - val_accuracy: 0.6574\n",
      "Epoch 3/200\n",
      "16684/16684 [==============================] - 1888s 113ms/step - loss: 0.3624 - accuracy: 0.8654 - val_loss: 1.2642 - val_accuracy: 0.6330\n",
      "Epoch 4/200\n",
      "16684/16684 [==============================] - 1860s 111ms/step - loss: 0.3583 - accuracy: 0.8664 - val_loss: 0.3631 - val_accuracy: 0.8652\n",
      "Epoch 5/200\n",
      "16684/16684 [==============================] - 1846s 111ms/step - loss: 0.3627 - accuracy: 0.8658 - val_loss: 0.3630 - val_accuracy: 0.8670\n",
      "Epoch 6/200\n",
      "16684/16684 [==============================] - 1847s 111ms/step - loss: 0.3622 - accuracy: 0.8650 - val_loss: 0.4737 - val_accuracy: 0.8312\n",
      "Epoch 7/200\n",
      "16684/16684 [==============================] - 1856s 111ms/step - loss: 0.3643 - accuracy: 0.8645 - val_loss: 0.3704 - val_accuracy: 0.8643\n",
      "Epoch 8/200\n",
      "16684/16684 [==============================] - 1850s 111ms/step - loss: 0.3655 - accuracy: 0.8639 - val_loss: 0.3998 - val_accuracy: 0.8476\n",
      "Epoch 9/200\n",
      "16684/16684 [==============================] - 1871s 112ms/step - loss: 0.3685 - accuracy: 0.8630 - val_loss: 0.3720 - val_accuracy: 0.8636\n",
      "Epoch 10/200\n",
      "16684/16684 [==============================] - 1851s 111ms/step - loss: 0.3447 - accuracy: 0.8705 - val_loss: 0.3576 - val_accuracy: 0.8693\n",
      "Epoch 11/200\n",
      "16684/16684 [==============================] - 1850s 111ms/step - loss: 0.3379 - accuracy: 0.8724 - val_loss: 0.3661 - val_accuracy: 0.8647\n",
      "Epoch 12/200\n",
      "16684/16684 [==============================] - 1857s 111ms/step - loss: 0.3300 - accuracy: 0.8752 - val_loss: 0.4448 - val_accuracy: 0.8364\n",
      "Epoch 13/200\n",
      "16684/16684 [==============================] - 1888s 113ms/step - loss: 0.3299 - accuracy: 0.8744 - val_loss: 1.3639 - val_accuracy: 0.6487\n",
      "Epoch 14/200\n",
      "16684/16684 [==============================] - 1863s 112ms/step - loss: 0.3264 - accuracy: 0.8759 - val_loss: 0.3541 - val_accuracy: 0.8693\n",
      "Epoch 15/200\n",
      "16684/16684 [==============================] - 1930s 116ms/step - loss: 0.3223 - accuracy: 0.8770 - val_loss: 0.3573 - val_accuracy: 0.8698\n",
      "Epoch 16/200\n",
      "16684/16684 [==============================] - 1898s 114ms/step - loss: 0.3175 - accuracy: 0.8786 - val_loss: 0.3578 - val_accuracy: 0.8698\n",
      "Epoch 17/200\n",
      "16684/16684 [==============================] - 1931s 116ms/step - loss: 0.3191 - accuracy: 0.8777 - val_loss: 0.3606 - val_accuracy: 0.8697\n",
      "Epoch 18/200\n",
      "16684/16684 [==============================] - 1891s 113ms/step - loss: 0.3289 - accuracy: 0.8749 - val_loss: 0.3592 - val_accuracy: 0.8673\n",
      "Epoch 19/200\n",
      "16684/16684 [==============================] - 1886s 113ms/step - loss: 0.3157 - accuracy: 0.8786 - val_loss: 0.3460 - val_accuracy: 0.8724\n",
      "Epoch 20/200\n",
      "16684/16684 [==============================] - 1854s 111ms/step - loss: 0.3028 - accuracy: 0.8830 - val_loss: 8.5381 - val_accuracy: 0.0779\n",
      "Epoch 21/200\n",
      "16684/16684 [==============================] - 1852s 111ms/step - loss: 0.2953 - accuracy: 0.8857 - val_loss: 18.7772 - val_accuracy: 0.0125\n",
      "Epoch 22/200\n",
      "16684/16684 [==============================] - 1847s 111ms/step - loss: 0.2943 - accuracy: 0.8861 - val_loss: 0.3510 - val_accuracy: 0.8724\n",
      "Epoch 23/200\n",
      "16684/16684 [==============================] - 1860s 111ms/step - loss: 0.2835 - accuracy: 0.8893 - val_loss: 4.7020 - val_accuracy: 0.4703\n",
      "Epoch 24/200\n",
      "16684/16684 [==============================] - 1857s 111ms/step - loss: 0.2791 - accuracy: 0.8915 - val_loss: 0.3510 - val_accuracy: 0.8732\n",
      "Epoch 25/200\n",
      "16684/16684 [==============================] - 1842s 110ms/step - loss: 0.2740 - accuracy: 0.8929 - val_loss: 0.3553 - val_accuracy: 0.8717\n",
      "Epoch 26/200\n",
      "16684/16684 [==============================] - 1838s 110ms/step - loss: 0.2663 - accuracy: 0.8952 - val_loss: 0.3583 - val_accuracy: 0.8730\n",
      "Epoch 27/200\n",
      "16684/16684 [==============================] - 1877s 112ms/step - loss: 0.2631 - accuracy: 0.8964 - val_loss: 0.3982 - val_accuracy: 0.8526\n",
      "Epoch 28/200\n",
      "16684/16684 [==============================] - 1855s 111ms/step - loss: 0.2575 - accuracy: 0.8987 - val_loss: 0.4146 - val_accuracy: 0.8472\n",
      "Epoch 29/200\n",
      "16684/16684 [==============================] - 1851s 111ms/step - loss: 0.2550 - accuracy: 0.8996 - val_loss: 0.3610 - val_accuracy: 0.8729\n"
     ]
    }
   ],
   "source": [
    "#황성현 \n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2P_NOAUG%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2p_noaug_nadam_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2p_noaug_nadam_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "lr_callback=keras.callbacks.ReduceLROnPlateau(patience=4, factor=0.5)\n",
    "history2=smv2_p_noaug.fit(train_set_noaug, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=200,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb,lr_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a02fc8",
   "metadata": {},
   "source": [
    "# smv2p  augmentaion and /2 batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "995af871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "IRB1 : batch_input_shape = (None, 112, 112, 32)\n",
      "IRB2 : batch_input_shape = (None, 112, 112, 16)\n",
      "IRB3 : batch_input_shape = (None, 56, 56, 32)\n",
      "IRB4 : batch_input_shape = (None, 28, 28, 64)\n",
      "IRB5 : batch_input_shape = (None, 14, 14, 64)\n",
      "IRB6 : batch_input_shape = (None, 7, 7, 128)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_8 (Batch (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 112, 112, 32)      896       \n",
      "_________________________________________________________________\n",
      "IRB1 (Inveted_Residual_Block (None, 112, 112, 16)      2288      \n",
      "_________________________________________________________________\n",
      "IRB2 (Inveted_Residual_Block (None, 56, 56, 32)        9856      \n",
      "_________________________________________________________________\n",
      "IRB3 (Inveted_Residual_Block (None, 28, 28, 64)        67584     \n",
      "_________________________________________________________________\n",
      "IRB4 (Inveted_Residual_Block (None, 14, 14, 64)        151168    \n",
      "_________________________________________________________________\n",
      "IRB5 (Inveted_Residual_Block (None, 7, 7, 128)         108416    \n",
      "_________________________________________________________________\n",
      "IRB6 (Inveted_Residual_Block (None, 7, 7, 1024)        1200640   \n",
      "_________________________________________________________________\n",
      "re_lu_34 (ReLU)              (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 62)                63550     \n",
      "=================================================================\n",
      "Total params: 1,608,506\n",
      "Trainable params: 1,592,532\n",
      "Non-trainable params: 15,974\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#황성현\n",
    "#multygpu\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    n_classes=62\n",
    "    smv2_p=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[224,224,3]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=32,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_p.summary()\n",
    "    smv2_p.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6c213d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/SMV2P_NOAUG20220529-104823\n",
      "ERROR:tensorflow:Failed to start profiler: Another profiler is running.\n",
      "Epoch 1/200\n",
      "  499/83104 [..............................] - ETA: 1:39:31 - loss: 0.5245 - accuracy: 0.8079ERROR:tensorflow:Failed to start profiler: Another profiler is running.\n",
      "83104/83104 [==============================] - 5971s 72ms/step - loss: 0.3457 - accuracy: 0.8765 - val_loss: 0.7710 - val_accuracy: 0.8290\n",
      "Epoch 2/200\n",
      "83104/83104 [==============================] - 5945s 72ms/step - loss: 0.2933 - accuracy: 0.8917 - val_loss: 0.5857 - val_accuracy: 0.8388\n",
      "Epoch 3/200\n",
      "83104/83104 [==============================] - 5946s 72ms/step - loss: 0.2913 - accuracy: 0.8910 - val_loss: 0.6854 - val_accuracy: 0.8320\n",
      "Epoch 4/200\n",
      "83104/83104 [==============================] - 5957s 72ms/step - loss: 0.2801 - accuracy: 0.8942 - val_loss: 1.2329 - val_accuracy: 0.8005\n",
      "Epoch 5/200\n",
      "83104/83104 [==============================] - 5953s 72ms/step - loss: 0.2472 - accuracy: 0.9065 - val_loss: 1.4598 - val_accuracy: 0.7858\n",
      "Epoch 6/200\n",
      "83104/83104 [==============================] - 5956s 72ms/step - loss: 0.2490 - accuracy: 0.9048 - val_loss: 1.3215 - val_accuracy: 0.7972\n",
      "Epoch 7/200\n",
      "83104/83104 [==============================] - 5962s 72ms/step - loss: 0.2421 - accuracy: 0.9070 - val_loss: 1.1494 - val_accuracy: 0.8091\n",
      "Epoch 8/200\n",
      "83104/83104 [==============================] - 5958s 72ms/step - loss: 0.2343 - accuracy: 0.9099 - val_loss: 1.5118 - val_accuracy: 0.7926\n",
      "Epoch 9/200\n",
      "83104/83104 [==============================] - 5970s 72ms/step - loss: 0.2093 - accuracy: 0.9196 - val_loss: 1.8135 - val_accuracy: 0.7716\n",
      "Epoch 10/200\n",
      "83104/83104 [==============================] - 5962s 72ms/step - loss: 0.2347 - accuracy: 0.9091 - val_loss: 1.4931 - val_accuracy: 0.7930\n",
      "Epoch 11/200\n",
      "83104/83104 [==============================] - 5953s 72ms/step - loss: 0.2147 - accuracy: 0.9167 - val_loss: 1.9391 - val_accuracy: 0.7660\n",
      "Epoch 12/200\n",
      "83104/83104 [==============================] - 5971s 72ms/step - loss: 0.2319 - accuracy: 0.9102 - val_loss: 1.6637 - val_accuracy: 0.7854\n"
     ]
    }
   ],
   "source": [
    "#황성현 \n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2P_NOAUG%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2p_16batch_nadam_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2p_16batch_nadam_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "lr_callback=keras.callbacks.ReduceLROnPlateau(patience=4, factor=0.5)\n",
    "history2=smv2_p_noaug.fit(train_set, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=200,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb,lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5ffa7f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 112, 112, 32)\n",
      "IRB2 : batch_input_shape = (None, 112, 112, 16)\n",
      "IRB3 : batch_input_shape = (None, 56, 56, 32)\n",
      "IRB4 : batch_input_shape = (None, 28, 28, 64)\n",
      "IRB5 : batch_input_shape = (None, 14, 14, 64)\n",
      "IRB6 : batch_input_shape = (None, 7, 7, 128)\n"
     ]
    }
   ],
   "source": [
    "smv2p_test=keras.models.load_model(\"smv2p_noaug_nadam_best.h5\",\n",
    "                                 custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "50b48e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10250/10250 [==============================] - 150s 14ms/step - loss: 0.3443 - accuracy: 0.8724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3443429172039032, 0.8724329471588135]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2p_test.evaluate(valid_set,\n",
    "                    steps=int(valid_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3fafd406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "IRB1 : batch_input_shape = (None, 112, 112, 32)\n",
      "IRB2 : batch_input_shape = (None, 112, 112, 16)\n",
      "IRB3 : batch_input_shape = (None, 56, 56, 32)\n",
      "IRB4 : batch_input_shape = (None, 28, 28, 64)\n",
      "IRB5 : batch_input_shape = (None, 14, 14, 64)\n",
      "IRB6 : batch_input_shape = (None, 7, 7, 128)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    smv2p_test=keras.models.load_model(\"smv2p_16batch_nadam_best.h5\",\n",
    "                                 custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "83b3e0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10250/10250 [==============================] - 151s 15ms/step - loss: 0.5826 - accuracy: 0.8386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.582583487033844, 0.838554859161377]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2p_test.evaluate(valid_set,\n",
    "                    steps=int(valid_size / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514c5a6e",
   "metadata": {},
   "source": [
    "# SMV2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aacddc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "IRB1 : batch_input_shape = (None, 112, 112, 32)\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "IRB2 : batch_input_shape = (None, 112, 112, 16)\n",
      "IRB3 : batch_input_shape = (None, 56, 56, 24)\n",
      "IRB4 : batch_input_shape = (None, 28, 28, 48)\n",
      "IRB5 : batch_input_shape = (None, 14, 14, 64)\n",
      "IRB6 : batch_input_shape = (None, 7, 7, 128)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 112, 112, 32)      896       \n",
      "_________________________________________________________________\n",
      "IRB1 (Inveted_Residual_Block (None, 112, 112, 16)      2288      \n",
      "_________________________________________________________________\n",
      "IRB2 (Inveted_Residual_Block (None, 56, 56, 24)        8272      \n",
      "_________________________________________________________________\n",
      "IRB3 (Inveted_Residual_Block (None, 28, 28, 48)        39936     \n",
      "_________________________________________________________________\n",
      "IRB4 (Inveted_Residual_Block (None, 14, 14, 64)        107328    \n",
      "_________________________________________________________________\n",
      "IRB5 (Inveted_Residual_Block (None, 7, 7, 128)         108416    \n",
      "_________________________________________________________________\n",
      "IRB6 (Inveted_Residual_Block (None, 7, 7, 1024)        1200640   \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 62)                63550     \n",
      "=================================================================\n",
      "Total params: 1,535,434\n",
      "Trainable params: 1,521,092\n",
      "Non-trainable params: 14,342\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#황성현\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    n_classes=62\n",
    "    smv2_b=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[224,224,3]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=24,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=48,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_b.summary()\n",
    "    smv2_b.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                   optimizer=\"nadam\",\n",
    "                   metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4012c9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2B%Y%m%d-%H%M%S\")\n",
    "# Clear out prior logging data.\n",
    "\n",
    "logdir = \"logs/image/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Define the basic TensorBoard callback.\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n",
    "\n",
    "def log_confusion_matrix(epoch, logs):\n",
    "    # Use the model to predict the values from the validation dataset.\n",
    "    test_pred_raw = model.predict()\n",
    "    test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "    # Calculate the confusion matrix.\n",
    "    cm = sklearn.metrics.confusion_matrix(test_labels, test_pred)\n",
    "    # Log the confusion matrix as an image summary.\n",
    "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "\n",
    "# Define the per-epoch callback.\n",
    "cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8ea8d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "INFO:tensorflow:batch_all_reduce: 116 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 116 all-reduces with algorithm = nccl, num_packs = 1\n",
      "41552/41552 [==============================] - 4266s 102ms/step - loss: 0.3992 - accuracy: 0.8621 - val_loss: 7.4812 - val_accuracy: 0.1981\n",
      "Epoch 2/300\n",
      "41552/41552 [==============================] - 4227s 102ms/step - loss: 0.3081 - accuracy: 0.8866 - val_loss: 1.8316 - val_accuracy: 0.6874\n",
      "Epoch 3/300\n",
      "41552/41552 [==============================] - 4222s 102ms/step - loss: 0.3090 - accuracy: 0.8856 - val_loss: 3.8341 - val_accuracy: 0.5182\n",
      "Epoch 4/300\n",
      "41552/41552 [==============================] - 4217s 101ms/step - loss: 0.3035 - accuracy: 0.8874 - val_loss: 3.2887 - val_accuracy: 0.5845\n",
      "Epoch 5/300\n",
      "41552/41552 [==============================] - 4226s 102ms/step - loss: 0.2921 - accuracy: 0.8913 - val_loss: 5.4356 - val_accuracy: 0.5173\n",
      "Epoch 6/300\n",
      "41552/41552 [==============================] - 4228s 102ms/step - loss: 0.2970 - accuracy: 0.8890 - val_loss: 2.8855 - val_accuracy: 0.6289\n",
      "Epoch 7/300\n",
      "41552/41552 [==============================] - 4222s 102ms/step - loss: 0.2937 - accuracy: 0.8905 - val_loss: 2.1772 - val_accuracy: 0.6685\n",
      "Epoch 8/300\n",
      "41552/41552 [==============================] - 4217s 101ms/step - loss: 0.3093 - accuracy: 0.8843 - val_loss: 3.0126 - val_accuracy: 0.5973\n",
      "Epoch 9/300\n",
      "41552/41552 [==============================] - 4221s 102ms/step - loss: 0.2854 - accuracy: 0.8941 - val_loss: 5.2476 - val_accuracy: 0.5035\n",
      "Epoch 10/300\n",
      "41552/41552 [==============================] - 4227s 102ms/step - loss: 0.3269 - accuracy: 0.8779 - val_loss: 5.6291 - val_accuracy: 0.4854\n",
      "Epoch 11/300\n",
      "41552/41552 [==============================] - 4228s 102ms/step - loss: 0.3032 - accuracy: 0.8862 - val_loss: 3.7807 - val_accuracy: 0.5489\n",
      "Epoch 12/300\n",
      "41552/41552 [==============================] - 4262s 103ms/step - loss: 0.3362 - accuracy: 0.8747 - val_loss: 2.5757 - val_accuracy: 0.6517\n"
     ]
    }
   ],
   "source": [
    "#황성현 \n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2B%Y%m%d-%H%M%S\")\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2b_nadam_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2b_nadam_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "#cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "\n",
    "history=smv2_b.fit(train_set, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f95cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775ec666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
