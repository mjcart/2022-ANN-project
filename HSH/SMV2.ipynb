{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version:  0.23.1\n",
      "TF version:  2.3.1\n",
      "GPU installed:  True\n",
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "print(\"sklearn version: \", sklearn.__version__)\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(\"TF version: \", tf.__version__)\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "# GPU test\n",
    "print(\"GPU installed: \",tf.test.is_built_with_gpu_support())\n",
    "\n",
    "# To prevent \"CUDNN_STATUS_ALLOC_FAILED\" error with GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "    \n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"cnn\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "    \n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")    \n",
    "\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "# You can find lists of datasets at https://www.tensorflow.org/datasets/catalog/overview\n",
    "dataset, info = tfds.load(\"tf_flowers\", as_supervised=True, with_info=True)\n",
    "# Information of dataset split (train/validation/test)\n",
    "info.splits\n",
    "# Information of train dataset\n",
    "info.splits[\"train\"]\n",
    "# Name of each class\n",
    "class_names = info.features[\"label\"].names\n",
    "n_classes = info.features[\"label\"].num_classes\n",
    "print(n_classes)\n",
    "dataset_size = info.splits[\"train\"].num_examples\n",
    "# Split dataset using split method\n",
    "test_set_raw, valid_set_raw, train_set_raw = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:10%]\", \"train[10%:25%]\", \"train[25%:]\"],\n",
    "    as_supervised=True)\n",
    "from functools import partial\n",
    "\n",
    "# Define preprocess functions\n",
    "def central_crop(image):\n",
    "    shape = tf.shape(image)\n",
    "    min_dim = tf.reduce_min([shape[0], shape[1]])\n",
    "    top_crop = (shape[0] - min_dim) // 4\n",
    "    bottom_crop = shape[0] - top_crop\n",
    "    left_crop = (shape[1] - min_dim) // 4\n",
    "    right_crop = shape[1] - left_crop\n",
    "    return image[top_crop:bottom_crop, left_crop:right_crop]\n",
    "\n",
    "def random_crop(image):\n",
    "    shape = tf.shape(image)\n",
    "    min_dim = tf.reduce_min([shape[0], shape[1]]) * 90 // 100\n",
    "    return tf.image.random_crop(image, [min_dim, min_dim, 3])\n",
    "\n",
    "# Select central crop or randomized crop\n",
    "def preprocess(image, label, randomize=False):\n",
    "    if randomize:\n",
    "        cropped_image = random_crop(image)\n",
    "        cropped_image = tf.image.random_flip_left_right(cropped_image)\n",
    "    else:\n",
    "        cropped_image = central_crop(image)\n",
    "    resized_image = tf.image.resize(cropped_image, [224, 224])\n",
    "    final_image = keras.applications.mobilenet.preprocess_input(resized_image)\n",
    "    return final_image, label\n",
    "\n",
    "# Define Train, validation and test datasets\n",
    "batch_size = 16\n",
    "train_set = train_set_raw.shuffle(1000).repeat()\n",
    "train_set = train_set.map(partial(preprocess, randomize=True)).batch(batch_size).prefetch(1)\n",
    "valid_set = valid_set_raw.map(preprocess).batch(batch_size).prefetch(1)\n",
    "test_set = test_set_raw.map(preprocess).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28, 1) (55000,)\n"
     ]
    }
   ],
   "source": [
    "# Load Fashion MNIST dataset and split it to train, valid and test data\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
    "# Normalizing data\n",
    "X_mean = X_train.mean(axis=0, keepdims=True)\n",
    "X_std = X_train.std(axis=0, keepdims=True) + 1e-7\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_valid = (X_valid - X_mean) / X_std\n",
    "X_test = (X_test - X_mean) / X_std\n",
    "\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_valid = X_valid[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "n_classes=10\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_smv2(X_train,y_train):\n",
    "    for i in range(10):\n",
    "        temp=lambda :tf.constant(tf.image.resize(X_train[(i)*100:(i+1)*100],[224,224]))\n",
    "        yield temp,y_train[(i)*100:(i+1)*100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMV2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inveted_Residual_Block(keras.layers.Layer):\n",
    "    def __init__(self,c,s=1,t=1,n=1,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.layers.ReLU(max_value=6)\n",
    "        self.main_layers = [\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=c*t,kernel_size=1,strides=1,padding=\"SAME\",activation=self.activation),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.DepthwiseConv2D(kernel_size=3,strides=1,padding=\"SAME\",activation=self.activation),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=c,kernel_size=1,strides=1,padding=\"SAME\",activation=self.activation),\n",
    "            ]\n",
    "        self.strides_layers=[\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=c*t,kernel_size=1,strides=1,padding=\"SAME\",activation=self.activation),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.DepthwiseConv2D(kernel_size=3,strides=s,padding=\"SAME\",activation=self.activation),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=c,kernel_size=1,strides=1,padding=\"SAME\",activation=self.activation),\n",
    "        ]\n",
    "        self.s=s\n",
    "        self.t=t\n",
    "        self.c=c\n",
    "        self.n=n\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        \n",
    "        for n in range(0,self.n):\n",
    "            if n == 0:\n",
    "                for layer in self.strides_layers:\n",
    "                    Z = layer(Z)\n",
    "            else:\n",
    "                skip_Z = Z\n",
    "                for layer in self.main_layers:\n",
    "                    Z = layer(Z)\n",
    "                \n",
    "                Z += skip_Z\n",
    "    \n",
    "        return Z\n",
    "    \n",
    "    def get_config(self):\n",
    "        base=super().get_config()\n",
    "        return{**base,\"s\":self.s,\"t\":self.t,\"c\":self.c,\"n\":self.n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "smv2_l=keras.models.Sequential([\n",
    "    keras.layers.BatchNormalization(input_shape=[224,224,3]),\n",
    "    keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "    Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "    Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "    Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "    Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "    Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "    Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "    keras.layers.ReLU(max_value=6),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 112, 112, 32)      896       \n",
      "_________________________________________________________________\n",
      "IRB1 (Inveted_Residual_Block (None, 112, 112, 16)      1216      \n",
      "_________________________________________________________________\n",
      "IRB2 (Inveted_Residual_Block (None, 56, 56, 16)        6688      \n",
      "_________________________________________________________________\n",
      "IRB3 (Inveted_Residual_Block (None, 28, 28, 32)        38656     \n",
      "_________________________________________________________________\n",
      "IRB4 (Inveted_Residual_Block (None, 14, 14, 64)        134656    \n",
      "_________________________________________________________________\n",
      "IRB5 (Inveted_Residual_Block (None, 7, 7, 128)         216448    \n",
      "_________________________________________________________________\n",
      "IRB6 (Inveted_Residual_Block (None, 7, 7, 1024)        9594368   \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 10,002,161\n",
      "Trainable params: 9,955,723\n",
      "Non-trainable params: 46,438\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "smv2_l.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 1.5512 - accuracy: 0.3779 - val_loss: 1.7621 - val_accuracy: 0.1654\n",
      "Epoch 2/10\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 1.3904 - accuracy: 0.4415 - val_loss: 1.7141 - val_accuracy: 0.2390\n",
      "Epoch 3/10\n",
      "172/172 [==============================] - 16s 92ms/step - loss: 1.2982 - accuracy: 0.4964 - val_loss: 2.8134 - val_accuracy: 0.2390\n",
      "Epoch 4/10\n",
      "172/172 [==============================] - 16s 93ms/step - loss: 1.2171 - accuracy: 0.5302 - val_loss: 1.2407 - val_accuracy: 0.5092\n",
      "Epoch 5/10\n",
      "172/172 [==============================] - 16s 96ms/step - loss: 1.1591 - accuracy: 0.5425 - val_loss: 1.2270 - val_accuracy: 0.5772\n",
      "Epoch 6/10\n",
      "172/172 [==============================] - 16s 93ms/step - loss: 1.0863 - accuracy: 0.5879 - val_loss: 1.1859 - val_accuracy: 0.5423\n",
      "Epoch 7/10\n",
      "172/172 [==============================] - 16s 96ms/step - loss: 1.0530 - accuracy: 0.5981 - val_loss: 0.9143 - val_accuracy: 0.6654\n",
      "Epoch 8/10\n",
      "172/172 [==============================] - 16s 93ms/step - loss: 0.9888 - accuracy: 0.6294 - val_loss: 1.0542 - val_accuracy: 0.6195\n",
      "Epoch 9/10\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.9336 - accuracy: 0.6526 - val_loss: 0.8107 - val_accuracy: 0.7132\n",
      "Epoch 10/10\n",
      "172/172 [==============================] - 16s 95ms/step - loss: 0.9826 - accuracy: 0.6366 - val_loss: 0.7902 - val_accuracy: 0.7261\n"
     ]
    }
   ],
   "source": [
    "check_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam2.h5\",save_best_only=True)\n",
    "history=smv2_l.fit(train_set,\n",
    "                    steps_per_epoch=int(0.75 * dataset_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(0.15 * dataset_size / batch_size),\n",
    "                    epochs=10,callbacks=[check_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMV2P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "smv2_p=keras.models.Sequential([\n",
    "    keras.layers.BatchNormalization(input_shape=[224,224,3]),\n",
    "    keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "    Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "    Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "    Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB3\"),\n",
    "    Inveted_Residual_Block(t=8,c=128,n=2,s=2,name=\"IRB4\"),\n",
    "    Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "    Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "    keras.layers.ReLU(max_value=6),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_304 (Bat (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_201 (Conv2D)          (None, 112, 112, 32)      896       \n",
      "_________________________________________________________________\n",
      "IRB1 (Inveted_Residual_Block (None, 112, 112, 16)      1216      \n",
      "_________________________________________________________________\n",
      "IRB2 (Inveted_Residual_Block (None, 56, 56, 16)        6688      \n",
      "_________________________________________________________________\n",
      "IRB3 (Inveted_Residual_Block (None, 28, 28, 64)        126400    \n",
      "_________________________________________________________________\n",
      "IRB4 (Inveted_Residual_Block (None, 14, 14, 128)       498688    \n",
      "_________________________________________________________________\n",
      "IRB5 (Inveted_Residual_Block (None, 7, 7, 128)         282240    \n",
      "_________________________________________________________________\n",
      "IRB6 (Inveted_Residual_Block (None, 7, 7, 1024)        9594368   \n",
      "_________________________________________________________________\n",
      "re_lu_60 (ReLU)              (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_341 (Bat (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 10,519,729\n",
      "Trainable params: 10,466,763\n",
      "Non-trainable params: 52,966\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "smv2_p.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "smv2_p.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "  2/172 [..............................] - ETA: 13s - loss: 5.0833 - accuracy: 0.2188WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0263s vs `on_train_batch_end` time: 0.0631s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0263s vs `on_train_batch_end` time: 0.0631s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 17s 98ms/step - loss: 1.9443 - accuracy: 0.3550 - val_loss: 1.9443 - val_accuracy: 0.2390\n",
      "Epoch 2/300\n",
      "172/172 [==============================] - 16s 93ms/step - loss: 1.3599 - accuracy: 0.4568 - val_loss: 1.7358 - val_accuracy: 0.2390\n",
      "Epoch 3/300\n",
      "172/172 [==============================] - 16s 92ms/step - loss: 1.2830 - accuracy: 0.5025 - val_loss: 2.4508 - val_accuracy: 0.2390\n",
      "Epoch 4/300\n",
      "172/172 [==============================] - 16s 92ms/step - loss: 1.2118 - accuracy: 0.5247 - val_loss: 2.8804 - val_accuracy: 0.2831\n",
      "Epoch 5/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.1444 - accuracy: 0.5552 - val_loss: 1.1505 - val_accuracy: 0.5882\n",
      "Epoch 6/300\n",
      "172/172 [==============================] - 16s 91ms/step - loss: 1.0970 - accuracy: 0.5799 - val_loss: 1.2076 - val_accuracy: 0.5882\n",
      "Epoch 7/300\n",
      "172/172 [==============================] - 16s 94ms/step - loss: 1.0259 - accuracy: 0.6072 - val_loss: 1.0767 - val_accuracy: 0.6287\n",
      "Epoch 8/300\n",
      "172/172 [==============================] - 16s 91ms/step - loss: 1.0304 - accuracy: 0.6057 - val_loss: 1.4119 - val_accuracy: 0.5496\n",
      "Epoch 9/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 1.0002 - accuracy: 0.6228 - val_loss: 1.0480 - val_accuracy: 0.6176\n",
      "Epoch 10/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9666 - accuracy: 0.6428 - val_loss: 0.9606 - val_accuracy: 0.6489\n",
      "Epoch 11/300\n",
      "172/172 [==============================] - 16s 93ms/step - loss: 0.9570 - accuracy: 0.6439 - val_loss: 0.9483 - val_accuracy: 0.6434\n",
      "Epoch 12/300\n",
      "172/172 [==============================] - 16s 91ms/step - loss: 0.8977 - accuracy: 0.6646 - val_loss: 0.9574 - val_accuracy: 0.6728\n",
      "Epoch 13/300\n",
      "172/172 [==============================] - 16s 90ms/step - loss: 0.9124 - accuracy: 0.6642 - val_loss: 1.0322 - val_accuracy: 0.6434\n",
      "Epoch 14/300\n",
      "172/172 [==============================] - 16s 93ms/step - loss: 0.8675 - accuracy: 0.6708 - val_loss: 0.8027 - val_accuracy: 0.7390\n",
      "Epoch 15/300\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 0.8496 - accuracy: 0.6886 - val_loss: 0.7974 - val_accuracy: 0.7188\n",
      "Epoch 16/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.8517 - accuracy: 0.6875 - val_loss: 0.8636 - val_accuracy: 0.6801\n",
      "Epoch 17/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.8242 - accuracy: 0.7013 - val_loss: 0.8090 - val_accuracy: 0.7169\n",
      "Epoch 18/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.8208 - accuracy: 0.6890 - val_loss: 0.9352 - val_accuracy: 0.6985\n",
      "Epoch 19/300\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 0.7884 - accuracy: 0.7089 - val_loss: 0.7889 - val_accuracy: 0.7261\n",
      "Epoch 20/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.7958 - accuracy: 0.7104 - val_loss: 0.8059 - val_accuracy: 0.7243\n",
      "Epoch 21/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.7455 - accuracy: 0.7195 - val_loss: 1.1047 - val_accuracy: 0.6360\n",
      "Epoch 22/300\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 0.7491 - accuracy: 0.7227 - val_loss: 0.7364 - val_accuracy: 0.7537\n",
      "Epoch 23/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.7305 - accuracy: 0.7297 - val_loss: 1.0629 - val_accuracy: 0.6085\n",
      "Epoch 24/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.7077 - accuracy: 0.7326 - val_loss: 0.8058 - val_accuracy: 0.7096\n",
      "Epoch 25/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.7016 - accuracy: 0.7391 - val_loss: 0.8625 - val_accuracy: 0.7316\n",
      "Epoch 26/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.6714 - accuracy: 0.7569 - val_loss: 0.7916 - val_accuracy: 0.7059\n",
      "Epoch 27/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.6646 - accuracy: 0.7551 - val_loss: 0.8274 - val_accuracy: 0.7482\n",
      "Epoch 28/300\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 0.6633 - accuracy: 0.7594 - val_loss: 0.7262 - val_accuracy: 0.7353\n",
      "Epoch 29/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.6568 - accuracy: 0.7649 - val_loss: 0.8014 - val_accuracy: 0.6912\n",
      "Epoch 30/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.6266 - accuracy: 0.7613 - val_loss: 0.7579 - val_accuracy: 0.7408\n",
      "Epoch 31/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.6315 - accuracy: 0.7693 - val_loss: 0.7541 - val_accuracy: 0.7555\n",
      "Epoch 32/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.6294 - accuracy: 0.7660 - val_loss: 0.7339 - val_accuracy: 0.7316\n",
      "Epoch 33/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.6072 - accuracy: 0.7740 - val_loss: 0.7356 - val_accuracy: 0.7298\n",
      "Epoch 34/300\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 0.6015 - accuracy: 0.7805 - val_loss: 0.6024 - val_accuracy: 0.7904\n",
      "Epoch 35/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.5778 - accuracy: 0.7932 - val_loss: 0.6508 - val_accuracy: 0.7868\n",
      "Epoch 36/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.6104 - accuracy: 0.7805 - val_loss: 0.6413 - val_accuracy: 0.7831\n",
      "Epoch 37/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.5878 - accuracy: 0.7889 - val_loss: 0.6941 - val_accuracy: 0.7629\n",
      "Epoch 38/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.5692 - accuracy: 0.7998 - val_loss: 0.6776 - val_accuracy: 0.7721\n",
      "Epoch 39/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.5333 - accuracy: 0.8049 - val_loss: 1.0375 - val_accuracy: 0.6489\n",
      "Epoch 40/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.5224 - accuracy: 0.8070 - val_loss: 0.7073 - val_accuracy: 0.7610\n",
      "Epoch 41/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.5532 - accuracy: 0.8052 - val_loss: 0.9089 - val_accuracy: 0.7224\n",
      "Epoch 42/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.5552 - accuracy: 0.7903 - val_loss: 0.6852 - val_accuracy: 0.7500\n",
      "Epoch 43/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.4878 - accuracy: 0.8132 - val_loss: 0.6073 - val_accuracy: 0.7978\n",
      "Epoch 44/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.5017 - accuracy: 0.8219 - val_loss: 0.6150 - val_accuracy: 0.7739\n",
      "Epoch 45/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.4830 - accuracy: 0.8187 - val_loss: 0.8560 - val_accuracy: 0.7390\n",
      "Epoch 46/300\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 0.5017 - accuracy: 0.8132 - val_loss: 0.5955 - val_accuracy: 0.7831\n",
      "Epoch 47/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.4678 - accuracy: 0.8263 - val_loss: 0.7605 - val_accuracy: 0.7518\n",
      "Epoch 48/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.4888 - accuracy: 0.8321 - val_loss: 0.6997 - val_accuracy: 0.7610\n",
      "Epoch 49/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.4581 - accuracy: 0.8307 - val_loss: 0.6227 - val_accuracy: 0.7886\n",
      "Epoch 50/300\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 0.4677 - accuracy: 0.8289 - val_loss: 0.5945 - val_accuracy: 0.7904\n",
      "Epoch 51/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.4496 - accuracy: 0.8390 - val_loss: 0.7865 - val_accuracy: 0.7757\n",
      "Epoch 52/300\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 0.4647 - accuracy: 0.8321 - val_loss: 0.5606 - val_accuracy: 0.8033\n",
      "Epoch 53/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.4327 - accuracy: 0.8452 - val_loss: 1.0402 - val_accuracy: 0.6728\n",
      "Epoch 54/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.4266 - accuracy: 0.8496 - val_loss: 0.8393 - val_accuracy: 0.7077\n",
      "Epoch 55/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.4049 - accuracy: 0.8514 - val_loss: 0.6073 - val_accuracy: 0.8199\n",
      "Epoch 56/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.3987 - accuracy: 0.8586 - val_loss: 1.0142 - val_accuracy: 0.7096\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 17s 96ms/step - loss: 0.3884 - accuracy: 0.8616 - val_loss: 0.7683 - val_accuracy: 0.7721\n",
      "Epoch 58/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.4141 - accuracy: 0.8434 - val_loss: 0.5866 - val_accuracy: 0.7886\n",
      "Epoch 59/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.3941 - accuracy: 0.8517 - val_loss: 0.8264 - val_accuracy: 0.7647\n",
      "Epoch 60/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.3795 - accuracy: 0.8688 - val_loss: 0.7539 - val_accuracy: 0.7371\n",
      "Epoch 61/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.3894 - accuracy: 0.8594 - val_loss: 0.5924 - val_accuracy: 0.8254\n",
      "Epoch 62/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.4004 - accuracy: 0.8586 - val_loss: 0.6451 - val_accuracy: 0.7757\n",
      "Epoch 63/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.3963 - accuracy: 0.8590 - val_loss: 0.6711 - val_accuracy: 0.7776\n",
      "Epoch 64/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.3657 - accuracy: 0.8612 - val_loss: 0.7093 - val_accuracy: 0.7684\n",
      "Epoch 65/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.3552 - accuracy: 0.8645 - val_loss: 0.7293 - val_accuracy: 0.7831\n",
      "Epoch 66/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.3645 - accuracy: 0.8637 - val_loss: 0.6704 - val_accuracy: 0.7794\n",
      "Epoch 67/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.3566 - accuracy: 0.8750 - val_loss: 0.7044 - val_accuracy: 0.7904\n",
      "Epoch 68/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.3500 - accuracy: 0.8706 - val_loss: 0.7167 - val_accuracy: 0.7721\n",
      "Epoch 69/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.3842 - accuracy: 0.8554 - val_loss: 0.5675 - val_accuracy: 0.8180\n",
      "Epoch 70/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.3611 - accuracy: 0.8674 - val_loss: 0.6111 - val_accuracy: 0.7960\n",
      "Epoch 71/300\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 0.3418 - accuracy: 0.8714 - val_loss: 0.5315 - val_accuracy: 0.8272\n",
      "Epoch 72/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.3736 - accuracy: 0.8641 - val_loss: 0.7279 - val_accuracy: 0.7518\n",
      "Epoch 73/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.3553 - accuracy: 0.8648 - val_loss: 0.7000 - val_accuracy: 0.7886\n",
      "Epoch 74/300\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 0.3331 - accuracy: 0.8834 - val_loss: 0.5284 - val_accuracy: 0.7978\n",
      "Epoch 75/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.3455 - accuracy: 0.8732 - val_loss: 0.5829 - val_accuracy: 0.8033\n",
      "Epoch 76/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.3180 - accuracy: 0.8790 - val_loss: 0.5758 - val_accuracy: 0.8217\n",
      "Epoch 77/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.3644 - accuracy: 0.8645 - val_loss: 0.7513 - val_accuracy: 0.7684\n",
      "Epoch 78/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.3225 - accuracy: 0.8779 - val_loss: 0.5854 - val_accuracy: 0.7978\n",
      "Epoch 79/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.3250 - accuracy: 0.8844 - val_loss: 0.5650 - val_accuracy: 0.8143\n",
      "Epoch 80/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.3227 - accuracy: 0.8859 - val_loss: 0.5934 - val_accuracy: 0.7960\n",
      "Epoch 81/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.3057 - accuracy: 0.8841 - val_loss: 0.6477 - val_accuracy: 0.8143\n",
      "Epoch 82/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.3512 - accuracy: 0.8772 - val_loss: 0.6033 - val_accuracy: 0.8051\n",
      "Epoch 83/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.3171 - accuracy: 0.8808 - val_loss: 0.5683 - val_accuracy: 0.8272\n",
      "Epoch 84/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2784 - accuracy: 0.9026 - val_loss: 0.6069 - val_accuracy: 0.7996\n",
      "Epoch 85/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.3037 - accuracy: 0.8899 - val_loss: 0.7861 - val_accuracy: 0.7555\n",
      "Epoch 86/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.3206 - accuracy: 0.8823 - val_loss: 0.6727 - val_accuracy: 0.8051\n",
      "Epoch 87/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.3229 - accuracy: 0.8823 - val_loss: 0.6810 - val_accuracy: 0.7923\n",
      "Epoch 88/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.3174 - accuracy: 0.8834 - val_loss: 0.7467 - val_accuracy: 0.7923\n",
      "Epoch 89/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.3064 - accuracy: 0.8870 - val_loss: 0.5345 - val_accuracy: 0.8290\n",
      "Epoch 90/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2937 - accuracy: 0.8906 - val_loss: 0.6281 - val_accuracy: 0.8254\n",
      "Epoch 91/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2978 - accuracy: 0.8946 - val_loss: 0.6066 - val_accuracy: 0.8143\n",
      "Epoch 92/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.3085 - accuracy: 0.8895 - val_loss: 0.6157 - val_accuracy: 0.8162\n",
      "Epoch 93/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2797 - accuracy: 0.8943 - val_loss: 0.6591 - val_accuracy: 0.8107\n",
      "Epoch 94/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.3076 - accuracy: 0.8917 - val_loss: 0.5639 - val_accuracy: 0.8272\n",
      "Epoch 95/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2727 - accuracy: 0.9008 - val_loss: 0.6461 - val_accuracy: 0.8015\n",
      "Epoch 96/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2994 - accuracy: 0.8910 - val_loss: 0.6349 - val_accuracy: 0.7941\n",
      "Epoch 97/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2598 - accuracy: 0.9066 - val_loss: 0.6157 - val_accuracy: 0.8088\n",
      "Epoch 98/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2778 - accuracy: 0.8932 - val_loss: 0.6929 - val_accuracy: 0.8051\n",
      "Epoch 99/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2875 - accuracy: 0.9008 - val_loss: 0.6051 - val_accuracy: 0.8199\n",
      "Epoch 100/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2945 - accuracy: 0.8950 - val_loss: 0.5851 - val_accuracy: 0.8382\n",
      "Epoch 101/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2804 - accuracy: 0.8972 - val_loss: 0.7247 - val_accuracy: 0.7812\n",
      "Epoch 102/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.3064 - accuracy: 0.8921 - val_loss: 0.5831 - val_accuracy: 0.8235\n",
      "Epoch 103/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2612 - accuracy: 0.9037 - val_loss: 0.6930 - val_accuracy: 0.7923\n",
      "Epoch 104/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2632 - accuracy: 0.9044 - val_loss: 0.7719 - val_accuracy: 0.7960\n",
      "Epoch 105/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2335 - accuracy: 0.9182 - val_loss: 0.7630 - val_accuracy: 0.7665\n",
      "Epoch 106/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2591 - accuracy: 0.9008 - val_loss: 0.6118 - val_accuracy: 0.8051\n",
      "Epoch 107/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2910 - accuracy: 0.8986 - val_loss: 0.5898 - val_accuracy: 0.8107\n",
      "Epoch 108/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2456 - accuracy: 0.9102 - val_loss: 0.5549 - val_accuracy: 0.8474\n",
      "Epoch 109/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2612 - accuracy: 0.9030 - val_loss: 0.6533 - val_accuracy: 0.8272\n",
      "Epoch 110/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2590 - accuracy: 0.9084 - val_loss: 0.5695 - val_accuracy: 0.8272\n",
      "Epoch 111/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2526 - accuracy: 0.9055 - val_loss: 0.6925 - val_accuracy: 0.8107\n",
      "Epoch 112/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2768 - accuracy: 0.9012 - val_loss: 0.6682 - val_accuracy: 0.8051\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 16s 96ms/step - loss: 0.2520 - accuracy: 0.9088 - val_loss: 0.5643 - val_accuracy: 0.8217\n",
      "Epoch 114/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2398 - accuracy: 0.9182 - val_loss: 0.6026 - val_accuracy: 0.8143\n",
      "Epoch 115/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2427 - accuracy: 0.9135 - val_loss: 0.6663 - val_accuracy: 0.8051\n",
      "Epoch 116/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2361 - accuracy: 0.9157 - val_loss: 0.7070 - val_accuracy: 0.8199\n",
      "Epoch 117/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2287 - accuracy: 0.9146 - val_loss: 0.6729 - val_accuracy: 0.7923\n",
      "Epoch 118/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2385 - accuracy: 0.9088 - val_loss: 0.6157 - val_accuracy: 0.8199\n",
      "Epoch 119/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2634 - accuracy: 0.9070 - val_loss: 0.5803 - val_accuracy: 0.8235\n",
      "Epoch 120/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2388 - accuracy: 0.9182 - val_loss: 0.7012 - val_accuracy: 0.7941\n",
      "Epoch 121/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2553 - accuracy: 0.9062 - val_loss: 0.6341 - val_accuracy: 0.8290\n",
      "Epoch 122/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2210 - accuracy: 0.9262 - val_loss: 0.5584 - val_accuracy: 0.8235\n",
      "Epoch 123/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2203 - accuracy: 0.9168 - val_loss: 0.6548 - val_accuracy: 0.8199\n",
      "Epoch 124/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2598 - accuracy: 0.9044 - val_loss: 0.6897 - val_accuracy: 0.7923\n",
      "Epoch 125/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2676 - accuracy: 0.9077 - val_loss: 0.6590 - val_accuracy: 0.8051\n",
      "Epoch 126/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2312 - accuracy: 0.9157 - val_loss: 0.5787 - val_accuracy: 0.8162\n",
      "Epoch 127/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2319 - accuracy: 0.9146 - val_loss: 0.6063 - val_accuracy: 0.8217\n",
      "Epoch 128/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2398 - accuracy: 0.9146 - val_loss: 0.5747 - val_accuracy: 0.8382\n",
      "Epoch 129/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2171 - accuracy: 0.9190 - val_loss: 0.5587 - val_accuracy: 0.8438\n",
      "Epoch 130/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2069 - accuracy: 0.9226 - val_loss: 0.5396 - val_accuracy: 0.8456\n",
      "Epoch 131/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2017 - accuracy: 0.9255 - val_loss: 0.5982 - val_accuracy: 0.8088\n",
      "Epoch 132/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2425 - accuracy: 0.9146 - val_loss: 0.6508 - val_accuracy: 0.8217\n",
      "Epoch 133/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2462 - accuracy: 0.9110 - val_loss: 0.5903 - val_accuracy: 0.8033\n",
      "Epoch 134/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2194 - accuracy: 0.9277 - val_loss: 0.6157 - val_accuracy: 0.8070\n",
      "Epoch 135/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2262 - accuracy: 0.9193 - val_loss: 0.6410 - val_accuracy: 0.8346\n",
      "Epoch 136/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2230 - accuracy: 0.9208 - val_loss: 0.7164 - val_accuracy: 0.8162\n",
      "Epoch 137/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2399 - accuracy: 0.9121 - val_loss: 0.7112 - val_accuracy: 0.7978\n",
      "Epoch 138/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2148 - accuracy: 0.9233 - val_loss: 0.6543 - val_accuracy: 0.8051\n",
      "Epoch 139/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2075 - accuracy: 0.9266 - val_loss: 0.5846 - val_accuracy: 0.8180\n",
      "Epoch 140/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2514 - accuracy: 0.9073 - val_loss: 0.6413 - val_accuracy: 0.8180\n",
      "Epoch 141/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2227 - accuracy: 0.9201 - val_loss: 0.8029 - val_accuracy: 0.7941\n",
      "Epoch 142/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2322 - accuracy: 0.9142 - val_loss: 0.6681 - val_accuracy: 0.8199\n",
      "Epoch 143/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2206 - accuracy: 0.9172 - val_loss: 0.6736 - val_accuracy: 0.8070\n",
      "Epoch 144/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2087 - accuracy: 0.9266 - val_loss: 0.6653 - val_accuracy: 0.7941\n",
      "Epoch 145/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1860 - accuracy: 0.9310 - val_loss: 0.6046 - val_accuracy: 0.8162\n",
      "Epoch 146/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1873 - accuracy: 0.9346 - val_loss: 0.6368 - val_accuracy: 0.8033\n",
      "Epoch 147/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2030 - accuracy: 0.9255 - val_loss: 0.6367 - val_accuracy: 0.8254\n",
      "Epoch 148/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2404 - accuracy: 0.9150 - val_loss: 0.7901 - val_accuracy: 0.7978\n",
      "Epoch 149/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2559 - accuracy: 0.9113 - val_loss: 0.6735 - val_accuracy: 0.7941\n",
      "Epoch 150/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2160 - accuracy: 0.9204 - val_loss: 0.6727 - val_accuracy: 0.8493\n",
      "Epoch 151/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2251 - accuracy: 0.9233 - val_loss: 0.7871 - val_accuracy: 0.7868\n",
      "Epoch 152/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2310 - accuracy: 0.9172 - val_loss: 0.6104 - val_accuracy: 0.8180\n",
      "Epoch 153/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2250 - accuracy: 0.9172 - val_loss: 0.6267 - val_accuracy: 0.8217\n",
      "Epoch 154/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2152 - accuracy: 0.9241 - val_loss: 0.5584 - val_accuracy: 0.8217\n",
      "Epoch 155/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1992 - accuracy: 0.9288 - val_loss: 0.6267 - val_accuracy: 0.7960\n",
      "Epoch 156/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2159 - accuracy: 0.9270 - val_loss: 0.6783 - val_accuracy: 0.8088\n",
      "Epoch 157/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2086 - accuracy: 0.9262 - val_loss: 0.6026 - val_accuracy: 0.8217\n",
      "Epoch 158/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2313 - accuracy: 0.9157 - val_loss: 0.7274 - val_accuracy: 0.7831\n",
      "Epoch 159/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2016 - accuracy: 0.9270 - val_loss: 0.6760 - val_accuracy: 0.8199\n",
      "Epoch 160/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1974 - accuracy: 0.9281 - val_loss: 0.6663 - val_accuracy: 0.8107\n",
      "Epoch 161/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1975 - accuracy: 0.9277 - val_loss: 0.7379 - val_accuracy: 0.7960\n",
      "Epoch 162/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2076 - accuracy: 0.9251 - val_loss: 0.6479 - val_accuracy: 0.8346\n",
      "Epoch 163/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2185 - accuracy: 0.9179 - val_loss: 0.7152 - val_accuracy: 0.7978\n",
      "Epoch 164/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2536 - accuracy: 0.9092 - val_loss: 0.6286 - val_accuracy: 0.8070\n",
      "Epoch 165/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1949 - accuracy: 0.9266 - val_loss: 0.6541 - val_accuracy: 0.8107\n",
      "Epoch 166/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2168 - accuracy: 0.9175 - val_loss: 0.7137 - val_accuracy: 0.8217\n",
      "Epoch 167/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2190 - accuracy: 0.9204 - val_loss: 0.6066 - val_accuracy: 0.8217\n",
      "Epoch 168/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2356 - accuracy: 0.9146 - val_loss: 0.7870 - val_accuracy: 0.7904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2216 - accuracy: 0.9219 - val_loss: 0.7463 - val_accuracy: 0.8015\n",
      "Epoch 170/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1906 - accuracy: 0.9331 - val_loss: 0.7281 - val_accuracy: 0.8051\n",
      "Epoch 171/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2017 - accuracy: 0.9248 - val_loss: 0.7066 - val_accuracy: 0.8272\n",
      "Epoch 172/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2003 - accuracy: 0.9270 - val_loss: 0.5965 - val_accuracy: 0.8217\n",
      "Epoch 173/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1816 - accuracy: 0.9368 - val_loss: 0.6860 - val_accuracy: 0.8235\n",
      "Epoch 174/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2034 - accuracy: 0.9320 - val_loss: 0.6723 - val_accuracy: 0.8143\n",
      "Epoch 175/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2000 - accuracy: 0.9299 - val_loss: 0.8019 - val_accuracy: 0.7776\n",
      "Epoch 176/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2356 - accuracy: 0.9135 - val_loss: 0.6505 - val_accuracy: 0.8033\n",
      "Epoch 177/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2225 - accuracy: 0.9197 - val_loss: 0.6971 - val_accuracy: 0.8327\n",
      "Epoch 178/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2135 - accuracy: 0.9266 - val_loss: 0.8067 - val_accuracy: 0.7941\n",
      "Epoch 179/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2756 - accuracy: 0.9033 - val_loss: 0.6346 - val_accuracy: 0.7996\n",
      "Epoch 180/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2396 - accuracy: 0.9150 - val_loss: 0.7961 - val_accuracy: 0.7996\n",
      "Epoch 181/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2124 - accuracy: 0.9248 - val_loss: 0.6492 - val_accuracy: 0.7996\n",
      "Epoch 182/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1743 - accuracy: 0.9379 - val_loss: 0.6090 - val_accuracy: 0.8180\n",
      "Epoch 183/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1769 - accuracy: 0.9386 - val_loss: 0.6093 - val_accuracy: 0.8364\n",
      "Epoch 184/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1907 - accuracy: 0.9353 - val_loss: 0.6724 - val_accuracy: 0.7978\n",
      "Epoch 185/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1952 - accuracy: 0.9310 - val_loss: 0.6801 - val_accuracy: 0.8107\n",
      "Epoch 186/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1984 - accuracy: 0.9295 - val_loss: 0.7272 - val_accuracy: 0.7978\n",
      "Epoch 187/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2180 - accuracy: 0.9197 - val_loss: 0.6077 - val_accuracy: 0.8199\n",
      "Epoch 188/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2068 - accuracy: 0.9310 - val_loss: 0.7658 - val_accuracy: 0.8070\n",
      "Epoch 189/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2027 - accuracy: 0.9281 - val_loss: 0.5853 - val_accuracy: 0.8346\n",
      "Epoch 190/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1975 - accuracy: 0.9288 - val_loss: 0.8254 - val_accuracy: 0.7886\n",
      "Epoch 191/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1899 - accuracy: 0.9393 - val_loss: 0.6462 - val_accuracy: 0.8051\n",
      "Epoch 192/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2002 - accuracy: 0.9302 - val_loss: 0.6952 - val_accuracy: 0.8033\n",
      "Epoch 193/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1844 - accuracy: 0.9350 - val_loss: 0.6563 - val_accuracy: 0.8254\n",
      "Epoch 194/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1831 - accuracy: 0.9350 - val_loss: 0.6822 - val_accuracy: 0.7886\n",
      "Epoch 195/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2230 - accuracy: 0.9168 - val_loss: 0.7461 - val_accuracy: 0.8088\n",
      "Epoch 196/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1851 - accuracy: 0.9379 - val_loss: 0.6563 - val_accuracy: 0.8217\n",
      "Epoch 197/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1841 - accuracy: 0.9313 - val_loss: 0.7644 - val_accuracy: 0.8143\n",
      "Epoch 198/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1798 - accuracy: 0.9350 - val_loss: 0.7942 - val_accuracy: 0.8070\n",
      "Epoch 199/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1870 - accuracy: 0.9317 - val_loss: 0.5986 - val_accuracy: 0.8327\n",
      "Epoch 200/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2098 - accuracy: 0.9270 - val_loss: 0.7516 - val_accuracy: 0.8309\n",
      "Epoch 201/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2048 - accuracy: 0.9259 - val_loss: 0.6053 - val_accuracy: 0.8235\n",
      "Epoch 202/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2097 - accuracy: 0.9270 - val_loss: 0.6277 - val_accuracy: 0.8180\n",
      "Epoch 203/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1964 - accuracy: 0.9270 - val_loss: 0.5918 - val_accuracy: 0.8162\n",
      "Epoch 204/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1828 - accuracy: 0.9339 - val_loss: 0.6935 - val_accuracy: 0.7996\n",
      "Epoch 205/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1953 - accuracy: 0.9306 - val_loss: 0.6603 - val_accuracy: 0.8290\n",
      "Epoch 206/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1911 - accuracy: 0.9306 - val_loss: 0.6555 - val_accuracy: 0.8143\n",
      "Epoch 207/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2100 - accuracy: 0.9295 - val_loss: 0.6340 - val_accuracy: 0.8125\n",
      "Epoch 208/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2025 - accuracy: 0.9299 - val_loss: 0.6562 - val_accuracy: 0.8107\n",
      "Epoch 209/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1973 - accuracy: 0.9241 - val_loss: 0.6806 - val_accuracy: 0.8235\n",
      "Epoch 210/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1857 - accuracy: 0.9375 - val_loss: 0.6669 - val_accuracy: 0.8033\n",
      "Epoch 211/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2008 - accuracy: 0.9222 - val_loss: 0.6165 - val_accuracy: 0.8217\n",
      "Epoch 212/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1956 - accuracy: 0.9288 - val_loss: 0.6607 - val_accuracy: 0.8162\n",
      "Epoch 213/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2225 - accuracy: 0.9157 - val_loss: 0.9110 - val_accuracy: 0.7390\n",
      "Epoch 214/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2023 - accuracy: 0.9230 - val_loss: 0.7373 - val_accuracy: 0.8070\n",
      "Epoch 215/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1949 - accuracy: 0.9273 - val_loss: 0.6033 - val_accuracy: 0.8217\n",
      "Epoch 216/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2269 - accuracy: 0.9233 - val_loss: 0.7779 - val_accuracy: 0.8088\n",
      "Epoch 217/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1853 - accuracy: 0.9382 - val_loss: 0.7697 - val_accuracy: 0.8051\n",
      "Epoch 218/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2027 - accuracy: 0.9233 - val_loss: 0.7723 - val_accuracy: 0.8015\n",
      "Epoch 219/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1885 - accuracy: 0.9317 - val_loss: 0.7942 - val_accuracy: 0.8199\n",
      "Epoch 220/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2241 - accuracy: 0.9193 - val_loss: 0.7798 - val_accuracy: 0.7923\n",
      "Epoch 221/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1880 - accuracy: 0.9331 - val_loss: 0.8364 - val_accuracy: 0.7868\n",
      "Epoch 222/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1964 - accuracy: 0.9291 - val_loss: 0.7920 - val_accuracy: 0.8015\n",
      "Epoch 223/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1905 - accuracy: 0.9346 - val_loss: 0.7504 - val_accuracy: 0.7978\n",
      "Epoch 224/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2005 - accuracy: 0.9201 - val_loss: 0.6844 - val_accuracy: 0.8199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1844 - accuracy: 0.9310 - val_loss: 0.7037 - val_accuracy: 0.7978\n",
      "Epoch 226/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1924 - accuracy: 0.9302 - val_loss: 0.6532 - val_accuracy: 0.8254\n",
      "Epoch 227/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1822 - accuracy: 0.9331 - val_loss: 0.8370 - val_accuracy: 0.7868\n",
      "Epoch 228/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2176 - accuracy: 0.9251 - val_loss: 0.7560 - val_accuracy: 0.7960\n",
      "Epoch 229/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1866 - accuracy: 0.9291 - val_loss: 0.7470 - val_accuracy: 0.8107\n",
      "Epoch 230/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1934 - accuracy: 0.9339 - val_loss: 0.7315 - val_accuracy: 0.8015\n",
      "Epoch 231/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2080 - accuracy: 0.9295 - val_loss: 0.5989 - val_accuracy: 0.8217\n",
      "Epoch 232/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2026 - accuracy: 0.9262 - val_loss: 0.6436 - val_accuracy: 0.8254\n",
      "Epoch 233/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1783 - accuracy: 0.9357 - val_loss: 0.6344 - val_accuracy: 0.8217\n",
      "Epoch 234/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1609 - accuracy: 0.9433 - val_loss: 0.7370 - val_accuracy: 0.8199\n",
      "Epoch 235/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1814 - accuracy: 0.9382 - val_loss: 0.7176 - val_accuracy: 0.8217\n",
      "Epoch 236/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1792 - accuracy: 0.9357 - val_loss: 0.6639 - val_accuracy: 0.8235\n",
      "Epoch 237/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1961 - accuracy: 0.9339 - val_loss: 0.6398 - val_accuracy: 0.8272\n",
      "Epoch 238/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1742 - accuracy: 0.9368 - val_loss: 0.6477 - val_accuracy: 0.8162\n",
      "Epoch 239/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1916 - accuracy: 0.9353 - val_loss: 0.5782 - val_accuracy: 0.8309\n",
      "Epoch 240/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1845 - accuracy: 0.9379 - val_loss: 0.7240 - val_accuracy: 0.8015\n",
      "Epoch 241/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2008 - accuracy: 0.9306 - val_loss: 0.8218 - val_accuracy: 0.7757\n",
      "Epoch 242/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1984 - accuracy: 0.9324 - val_loss: 0.6883 - val_accuracy: 0.8033\n",
      "Epoch 243/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1637 - accuracy: 0.9404 - val_loss: 0.6917 - val_accuracy: 0.8235\n",
      "Epoch 244/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1824 - accuracy: 0.9284 - val_loss: 0.7141 - val_accuracy: 0.8217\n",
      "Epoch 245/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1682 - accuracy: 0.9400 - val_loss: 0.6022 - val_accuracy: 0.8272\n",
      "Epoch 246/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1888 - accuracy: 0.9306 - val_loss: 0.7296 - val_accuracy: 0.8180\n",
      "Epoch 247/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1730 - accuracy: 0.9371 - val_loss: 0.7203 - val_accuracy: 0.8088\n",
      "Epoch 248/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1899 - accuracy: 0.9342 - val_loss: 0.9189 - val_accuracy: 0.7721\n",
      "Epoch 249/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1814 - accuracy: 0.9375 - val_loss: 0.7334 - val_accuracy: 0.8180\n",
      "Epoch 250/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2077 - accuracy: 0.9277 - val_loss: 0.6001 - val_accuracy: 0.8033\n",
      "Epoch 251/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2197 - accuracy: 0.9193 - val_loss: 0.6927 - val_accuracy: 0.8199\n",
      "Epoch 252/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1930 - accuracy: 0.9317 - val_loss: 0.6545 - val_accuracy: 0.8107\n",
      "Epoch 253/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1818 - accuracy: 0.9350 - val_loss: 0.6849 - val_accuracy: 0.8088\n",
      "Epoch 254/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2067 - accuracy: 0.9259 - val_loss: 0.7283 - val_accuracy: 0.8346\n",
      "Epoch 255/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1800 - accuracy: 0.9353 - val_loss: 0.6582 - val_accuracy: 0.8235\n",
      "Epoch 256/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2016 - accuracy: 0.9339 - val_loss: 0.7815 - val_accuracy: 0.7978\n",
      "Epoch 257/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1802 - accuracy: 0.9360 - val_loss: 0.7013 - val_accuracy: 0.7831\n",
      "Epoch 258/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1465 - accuracy: 0.9495 - val_loss: 0.6892 - val_accuracy: 0.8272\n",
      "Epoch 259/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1750 - accuracy: 0.9400 - val_loss: 0.6315 - val_accuracy: 0.8217\n",
      "Epoch 260/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1785 - accuracy: 0.9331 - val_loss: 0.6937 - val_accuracy: 0.7941\n",
      "Epoch 261/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1978 - accuracy: 0.9277 - val_loss: 0.7189 - val_accuracy: 0.8070\n",
      "Epoch 262/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1844 - accuracy: 0.9320 - val_loss: 0.6083 - val_accuracy: 0.8401\n",
      "Epoch 263/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1651 - accuracy: 0.9422 - val_loss: 0.6064 - val_accuracy: 0.8162\n",
      "Epoch 264/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1697 - accuracy: 0.9408 - val_loss: 0.7292 - val_accuracy: 0.7923\n",
      "Epoch 265/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1732 - accuracy: 0.9415 - val_loss: 0.5979 - val_accuracy: 0.8290\n",
      "Epoch 266/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1492 - accuracy: 0.9480 - val_loss: 0.7223 - val_accuracy: 0.8033\n",
      "Epoch 267/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1990 - accuracy: 0.9291 - val_loss: 0.7213 - val_accuracy: 0.8327\n",
      "Epoch 268/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1856 - accuracy: 0.9357 - val_loss: 0.7682 - val_accuracy: 0.7831\n",
      "Epoch 269/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2171 - accuracy: 0.9226 - val_loss: 0.6905 - val_accuracy: 0.8015\n",
      "Epoch 270/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1755 - accuracy: 0.9353 - val_loss: 0.6299 - val_accuracy: 0.8346\n",
      "Epoch 271/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1827 - accuracy: 0.9317 - val_loss: 0.6603 - val_accuracy: 0.8143\n",
      "Epoch 272/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2071 - accuracy: 0.9277 - val_loss: 0.6259 - val_accuracy: 0.8180\n",
      "Epoch 273/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1828 - accuracy: 0.9360 - val_loss: 0.6333 - val_accuracy: 0.8382\n",
      "Epoch 274/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1774 - accuracy: 0.9328 - val_loss: 0.6994 - val_accuracy: 0.8107\n",
      "Epoch 275/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1674 - accuracy: 0.9408 - val_loss: 0.6873 - val_accuracy: 0.8254\n",
      "Epoch 276/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.2080 - accuracy: 0.9302 - val_loss: 0.6992 - val_accuracy: 0.8125\n",
      "Epoch 277/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1976 - accuracy: 0.9291 - val_loss: 0.7022 - val_accuracy: 0.8254\n",
      "Epoch 278/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1722 - accuracy: 0.9339 - val_loss: 0.8133 - val_accuracy: 0.7941\n",
      "Epoch 279/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1611 - accuracy: 0.9430 - val_loss: 0.6904 - val_accuracy: 0.8254\n",
      "Epoch 280/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1776 - accuracy: 0.9342 - val_loss: 0.6590 - val_accuracy: 0.8346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1764 - accuracy: 0.9411 - val_loss: 0.6291 - val_accuracy: 0.8162\n",
      "Epoch 282/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1559 - accuracy: 0.9484 - val_loss: 0.7095 - val_accuracy: 0.8143\n",
      "Epoch 283/300\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.1618 - accuracy: 0.9400 - val_loss: 0.7685 - val_accuracy: 0.8125\n",
      "Epoch 284/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1837 - accuracy: 0.9328 - val_loss: 0.6538 - val_accuracy: 0.8235\n",
      "Epoch 285/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1534 - accuracy: 0.9433 - val_loss: 0.6417 - val_accuracy: 0.8125\n",
      "Epoch 286/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1856 - accuracy: 0.9339 - val_loss: 0.7332 - val_accuracy: 0.7886\n",
      "Epoch 287/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1983 - accuracy: 0.9302 - val_loss: 0.6964 - val_accuracy: 0.8199\n",
      "Epoch 288/300\n",
      "172/172 [==============================] - 16s 96ms/step - loss: 0.1838 - accuracy: 0.9328 - val_loss: 0.6572 - val_accuracy: 0.8180\n",
      "Epoch 289/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1640 - accuracy: 0.9386 - val_loss: 0.7250 - val_accuracy: 0.8033\n",
      "Epoch 290/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1878 - accuracy: 0.9350 - val_loss: 0.7310 - val_accuracy: 0.8180\n",
      "Epoch 291/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1906 - accuracy: 0.9299 - val_loss: 0.7051 - val_accuracy: 0.8217\n",
      "Epoch 292/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1881 - accuracy: 0.9306 - val_loss: 0.8607 - val_accuracy: 0.7610\n",
      "Epoch 293/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1924 - accuracy: 0.9364 - val_loss: 0.8015 - val_accuracy: 0.7960\n",
      "Epoch 294/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.2143 - accuracy: 0.9273 - val_loss: 0.7436 - val_accuracy: 0.8051\n",
      "Epoch 295/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1804 - accuracy: 0.9375 - val_loss: 0.6947 - val_accuracy: 0.8180\n",
      "Epoch 296/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1812 - accuracy: 0.9342 - val_loss: 0.6420 - val_accuracy: 0.8088\n",
      "Epoch 297/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1665 - accuracy: 0.9419 - val_loss: 0.6824 - val_accuracy: 0.8290\n",
      "Epoch 298/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1700 - accuracy: 0.9357 - val_loss: 0.8209 - val_accuracy: 0.7702\n",
      "Epoch 299/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1826 - accuracy: 0.9368 - val_loss: 0.6707 - val_accuracy: 0.8125\n",
      "Epoch 300/300\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.1872 - accuracy: 0.9324 - val_loss: 0.7304 - val_accuracy: 0.8107\n"
     ]
    }
   ],
   "source": [
    "check_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2p_nadam.h5\",save_best_only=True)\n",
    "history=smv2_p.fit(train_set,\n",
    "                    steps_per_epoch=int(0.75 * dataset_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(0.15 * dataset_size / batch_size),\n",
    "                    epochs=300,callbacks=[check_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4342 - accuracy: 0.2918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4341720938682556, 0.29178759455680847]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=keras.models.load_model(\"smv2l_nadam.h5\",custom_objects={\"Inveted_Residual_Block\" : Inveted_Residual_Block})\n",
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 23ms/step - loss: 1.1099 - accuracy: 0.3706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1099331378936768, 0.37057220935821533]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=keras.models.load_model(\"my_mobilenetv2_1.h5\",\n",
    "                               custom_objects={\"Inveted_Residual_Block\" : Inveted_Residual_Block})\n",
    "model2.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5485 - accuracy: 0.2779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5485105514526367, 0.2779291570186615]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3=keras.models.load_model(\"smv2p_nadam.h5\",\n",
    "                               custom_objects={\"Inveted_Residual_Block\" : Inveted_Residual_Block})\n",
    "model3.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 19ms/step - loss: 0.4999 - accuracy: 0.2585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4998670816421509, 0.25853991508483887]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 24ms/step - loss: 0.5297 - accuracy: 0.2468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5296900868415833, 0.24682395160198212]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
