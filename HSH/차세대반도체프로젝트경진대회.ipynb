{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c25bd3",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "061d4a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version:  0.24.2\n",
      "TF version:  2.8.0\n",
      "GPU installed:  True\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "print(\"sklearn version: \", sklearn.__version__)\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "print(\"TF version: \", tf.__version__)\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "# GPU test\n",
    "print(\"GPU installed: \",tf.test.is_built_with_gpu_support())\n",
    "\n",
    "# To prevent \"CUDNN_STATUS_ALLOC_FAILED\" error with GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "    \n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"cnn\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "    \n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")    \n",
    "\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aad9190",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c0a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이승훈\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "loaded_data=np.loadtxt('./datasets/Emnist/emnist-byclass-train.csv', delimiter=\",\",dtype='uint8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f7d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이승훈\n",
    "\n",
    "y_train_full,X_train_full=np.split(loaded_data,[1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ccd100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이승훈\n",
    "\n",
    "loaded_data=np.loadtxt('./datasets/Emnist/emnist-byclass-test.csv', delimiter=\",\",dtype='uint8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2abd71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이승훈\n",
    "\n",
    "y_test_full,X_test_full=np.split(loaded_data,[1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c29acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이승훈\n",
    "X_train, X_valid, y_train, y_valid=train_test_split(X_train_full, y_train_full, test_size=0.235, random_state=42)\n",
    "np.savetxt('./datasets/Emnist/train_data.csv',X_train,fmt='%d',delimiter=',')\n",
    "np.savetxt('./datasets/Emnist/valid_data.csv',X_valid,fmt='%d',delimiter=',')\n",
    "np.savetxt('./datasets/Emnist/train_label.csv',y_train,fmt='%d',delimiter=',')\n",
    "np.savetxt('./datasets/Emnist/valid_label.csv',y_valid,fmt='%d',delimiter=',')\n",
    "\n",
    "os.chdir('../') #원래 디렉토리로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "609516d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이승훈\n",
    "np.savetxt('./datasets/Emnist/test_data.csv',X_test_full,fmt='%d',delimiter=',')\n",
    "np.savetxt('./datasets/Emnist/test_label.csv',y_test_full,fmt='%d',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "264b075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#작성자 전민재\n",
    "import csv\n",
    "def load_Emist(exsitNumpy=False, needTranspose=True,make_train=True,make_valid=True,make_test=True):\n",
    "    if (exsitNumpy == False):\n",
    "        #\"./emnist-byclass-test.csv\"\n",
    "        #train-set\n",
    "        #\"공용/datasets/Emnist/\" 위치에 csv 저장 \n",
    "        csv_train_data_file = open(\"./datasets/Emnist/train_data.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "        csv_train_label_file = open(\"./datasets/Emnist/train_label.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "    \n",
    "        \n",
    "        f_train = csv.reader(csv_train_data_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "        l_train=csv.reader(csv_train_label_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "        #valid-set\n",
    "    \n",
    "        csv_valid_data_file = open(\"./datasets/Emnist/valid_data.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "        csv_valid_label_file = open(\"./datasets/Emnist/valid_label.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "        \n",
    "        f_valid = csv.reader(csv_valid_data_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "        l_valid = csv.reader(csv_valid_label_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "        \n",
    "        \n",
    "        #test-set\n",
    "    \n",
    "        csv_test_data_file = open(\"./datasets/Emnist/test_data.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "        csv_test_label_file = open(\"./datasets/Emnist/test_label.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "        \n",
    "        f_test = csv.reader(csv_test_data_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "        l_test = csv.reader(csv_test_label_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "        \n",
    "        \n",
    "        X_train=[]\n",
    "        y_train=[]\n",
    "        X_valid=[]\n",
    "        y_valid=[]\n",
    "        X_test=[]\n",
    "        y_test=[]\n",
    "        if make_train:\n",
    "            for i, row in enumerate(f_train):\n",
    "                #행마다 int로 형변환\n",
    "                for idx, char in enumerate(row):\n",
    "                    row[idx]=int(char)\n",
    "                #train\n",
    "                #data 추가    \n",
    "                X_train.append(row)\n",
    "            for i, row in enumerate(l_train):\n",
    "\n",
    "                #train\n",
    "                #label 추가\n",
    "                y_train.append(int(row[0]))\n",
    "            \n",
    "            \n",
    "        if make_valid:\n",
    "            for i, row in enumerate(f_valid):\n",
    "                #행마다 int로 형변환\n",
    "                for idx, char in enumerate(row):\n",
    "                    row[idx]=int(char)\n",
    "                #valid\n",
    "                #data 추가    \n",
    "                X_valid.append(row)\n",
    "\n",
    "\n",
    "            for i, row in enumerate(l_valid):\n",
    "\n",
    "                #valid\n",
    "                #label 추가\n",
    "                y_valid.append(int(row[0]))\n",
    "                \n",
    "        if make_test:\n",
    "            for i, row in enumerate(f_test):\n",
    "                #행마다 int로 형변환\n",
    "                for idx, char in enumerate(row):\n",
    "                    row[idx]=int(char)\n",
    "                #valid\n",
    "                #data 추가    \n",
    "                X_test.append(row)\n",
    "\n",
    "\n",
    "            for i, row in enumerate(l_test):\n",
    "\n",
    "                #valid\n",
    "                #label 추가\n",
    "                y_test.append(int(row[0]))\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "        #train\n",
    "        X_train=np.array(X_train,dtype=np.uint8)\n",
    "        X_train=X_train.reshape(-1,28,28)\n",
    "        #valid\n",
    "        X_valid=np.array(X_valid,dtype=np.uint8)\n",
    "        X_valid=X_valid.reshape(-1,28,28)\n",
    "        #test\n",
    "        X_test=np.array(X_test,dtype=np.uint8)\n",
    "        X_test=X_test.reshape(-1,28,28)\n",
    "        \n",
    "        \n",
    "        csv_train_data_file.close()\n",
    "        csv_train_label_file.close()\n",
    "        csv_valid_data_file.close()\n",
    "        csv_valid_label_file.close()\n",
    "        csv_test_data_file.close()\n",
    "        csv_test_label_file.close()\n",
    "        #kaggle dataset이 시계반대방향으로 90도 회전 되있고 상하 반전 되어있음\n",
    "        def rotate_90(m):\n",
    "            N = len(m)\n",
    "            ret = [[0] * N for _ in range(N)]\n",
    "\n",
    "            for r in range(N):\n",
    "                for c in range(N):\n",
    "                    ret[c][N-1-r] = m[r][c]\n",
    "            return np.array(ret,dtype=np.uint8)\n",
    "\n",
    "        def vreflect(m):\n",
    "            N = len(m)\n",
    "            ret = [[0] * N for _ in range(N)]\n",
    "\n",
    "            for r in range(N):\n",
    "                for c in range(N):\n",
    "                    ret[r][c] = m[r][N-1-c]\n",
    "            return np.array(ret,dtype=np.uint8)\n",
    "        \n",
    "        if needTranspose == True:\n",
    "            if make_train:\n",
    "                #train\n",
    "                #회전\n",
    "                for idx,i in enumerate(X_train):\n",
    "                    X_train[idx]=rotate_90(i)\n",
    "                #상하반전\n",
    "                for idx,i in enumerate(X_train):\n",
    "                    X_train[idx]=vreflect(i)\n",
    "                np.save('./X_train',X_train)\n",
    "                np.save('./y_train',y_train)\n",
    "                \n",
    "                \n",
    "            if make_valid:\n",
    "                #valid\n",
    "                #회전\n",
    "                for idx,i in enumerate(X_valid):\n",
    "                    X_valid[idx]=rotate_90(i)\n",
    "                #상하반전\n",
    "                for idx,i in enumerate(X_valid):\n",
    "                    X_valid[idx]=vreflect(i)\n",
    "                np.save('./X_valid',X_valid)\n",
    "                np.save('./y_valid',y_valid)\n",
    "            if make_test:\n",
    "\n",
    "                #test\n",
    "                #회전\n",
    "                for idx,i in enumerate(X_test):\n",
    "                    X_test[idx]=rotate_90(i)\n",
    "                #상하반전\n",
    "                for idx,i in enumerate(X_test):\n",
    "                    X_test[idx]=vreflect(i)\n",
    "                    \n",
    "                np.save('./X_test',X_test)\n",
    "                np.save('./y_test',y_test)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "   \n",
    "    X_train=np.load('./X_train.npy')\n",
    "    y_train=np.load('./y_train.npy')\n",
    "    X_valid=np.load('./X_valid.npy')\n",
    "    y_valid=np.load('./y_valid.npy')\n",
    "    X_test=np.load('./X_test.npy')\n",
    "    y_test=np.load('./y_test.npy')\n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bae2929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((533917, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현\n",
    "#npy 파일이 존재할 경우 exsitNumpy = True, 업으면 False\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = load_Emist(exsitNumpy=False,make_train=False,make_valid=False,make_test=False)\n",
    "X_train.shape,X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "093d8d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#작성자 전민재\n",
    "import csv\n",
    "def load_estela_Emist(file_path=None,exsitNumpy=False, needTranspose=False):\n",
    "    if (exsitNumpy == False):\n",
    "        #\"./emnist-byclass-test.csv\"\n",
    "        #train-set\n",
    "        #\"공용/datasets/Emnist/\" 위치에 csv 저장 \n",
    "        if file_path is None:\n",
    "            csv_estela_data_file = open(\"./datasets/Emnist/estela_data.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "            csv_estela_label_file = open(\"./datasets/Emnist/estela_label.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "        else:\n",
    "            csv_estela_data_file = open(file_path, \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "            csv_estela_label_file = open(file_path, \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "        \n",
    "        \n",
    "        f_estela = csv.reader(csv_estela_data_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "        l_estela=csv.reader(csv_estela_label_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "\n",
    "        X_estela=[]\n",
    "        y_estela=[]\n",
    "        \n",
    "        for i, row in enumerate(f_estela):\n",
    "                #행마다 int로 형변환\n",
    "                for idx, char in enumerate(row):\n",
    "                    row[idx]=int(char)\n",
    "                #train\n",
    "                #data 추가    \n",
    "                X_estela.append(row)\n",
    "        for i, row in enumerate(l_estela):\n",
    "\n",
    "                #train\n",
    "                #label 추가\n",
    "                y_estela.append(int(row[0]))\n",
    "        \n",
    "\n",
    "        \n",
    "        X_estela=np.array(X_estela,dtype=np.uint8)\n",
    "        X_estela=X_estela.reshape(-1,28,28)\n",
    "        \n",
    "        \n",
    "        \n",
    "        csv_estela_data_file.close()\n",
    "        csv_estela_label_file.close()\n",
    "        \n",
    "        #kaggle dataset이 시계반대방향으로 90도 회전 되있고 상하 반전 되어있음\n",
    "        def rotate_90(m):\n",
    "            N = len(m)\n",
    "            ret = [[0] * N for _ in range(N)]\n",
    "\n",
    "            for r in range(N):\n",
    "                for c in range(N):\n",
    "                    ret[c][N-1-r] = m[r][c]\n",
    "            return np.array(ret,dtype=np.uint8)\n",
    "\n",
    "        def vreflect(m):\n",
    "            N = len(m)\n",
    "            ret = [[0] * N for _ in range(N)]\n",
    "\n",
    "            for r in range(N):\n",
    "                for c in range(N):\n",
    "                    ret[r][c] = m[r][N-1-c]\n",
    "            return np.array(ret,dtype=np.uint8)\n",
    "        \n",
    "        if needTranspose == True:\n",
    "                \n",
    "                #회전\n",
    "                for idx,i in enumerate(X_estela):\n",
    "                    X_estela[idx]=rotate_90(i)\n",
    "                #상하반전\n",
    "                for idx,i in enumerate(X_estela):\n",
    "                    X_estela[idx]=vreflect(i)\n",
    "        np.save('./X_estela',X_estela)\n",
    "        np.save('./y_estela',y_estela)       \n",
    "                \n",
    "              \n",
    "        \n",
    "        \n",
    "        \n",
    "    X_estela=np.load('./X_estela.npy')\n",
    "    y_estela=np.load('./y_estela.npy')\n",
    "    \n",
    "    return X_estela, y_estela\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20154658",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './datasets/Emnist/estela_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7436/1718162838.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_estela\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_estela\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_estela_Emist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexsitNumpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_estela\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_estela\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7436/3976344469.py\u001b[0m in \u001b[0;36mload_estela_Emist\u001b[1;34m(file_path, exsitNumpy, needTranspose)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m#\"공용/datasets/Emnist/\" 위치에 csv 저장\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mcsv_estela_data_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./datasets/Emnist/estela_data.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ms932\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;31m#리스트 형식\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mcsv_estela_label_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./datasets/Emnist/estela_label.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ms932\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;31m#리스트 형식\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './datasets/Emnist/estela_data.csv'"
     ]
    }
   ],
   "source": [
    "X_estela, y_estela = load_estela_Emist(exsitNumpy=False)\n",
    "X_estela.shape, y_estela.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a66674a",
   "metadata": {},
   "source": [
    "# [224,224,3] tensoeflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "656adca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_set():\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = load_Emist(exsitNumpy=False,make_train=False,make_valid=False,make_test=False)\n",
    "    # multiple emnist letters \n",
    "    times_count=[]\n",
    "    X_train_letters=[]\n",
    "    y_train_letters=[]\n",
    "    for i in range (10,62):\n",
    "        X_train_letters.append(X_train[np.where(y_train==i)])\n",
    "        y_train_letters.append(y_train[np.where(y_train==i)])\n",
    "        times_count.append(int(30000/len(X_train_letters[i-10])))\n",
    "    for i in range (10,62):\n",
    "        for k in range(times_count[i-10]):\n",
    "            X_train = np.append(X_train,X_train_letters[i-10],axis=0)\n",
    "            y_train = np.append(y_train, y_train_letters[i-10],axis=0)\n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11aec677",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = make_data_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bfa5470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1951793, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6c34959",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26467\n",
      "29283\n",
      "26254\n",
      "26927\n",
      "25681\n",
      "23910\n",
      "26090\n",
      "27335\n",
      "25918\n",
      "25879\n",
      "34433\n",
      "32483\n",
      "30888\n",
      "31644\n",
      "30152\n",
      "35330\n",
      "31360\n",
      "30901\n",
      "36504\n",
      "31680\n",
      "30448\n",
      "31184\n",
      "34510\n",
      "31255\n",
      "38166\n",
      "31530\n",
      "30345\n",
      "31408\n",
      "31850\n",
      "37395\n",
      "38588\n",
      "32094\n",
      "32382\n",
      "31965\n",
      "32589\n",
      "30510\n",
      "30744\n",
      "31760\n",
      "30156\n",
      "31284\n",
      "37706\n",
      "31376\n",
      "31647\n",
      "33350\n",
      "31755\n",
      "30828\n",
      "30688\n",
      "35178\n",
      "30225\n",
      "35332\n",
      "31260\n",
      "31025\n",
      "30160\n",
      "32484\n",
      "31515\n",
      "41688\n",
      "32040\n",
      "31038\n",
      "31035\n",
      "30100\n",
      "30821\n",
      "31260\n"
     ]
    }
   ],
   "source": [
    "# multiple emnist letters \n",
    "times_count=[]\n",
    "X_train_letters=[]\n",
    "for i in range (0,62):\n",
    "    X_train_letters.append(X_train[np.where(y_train==i)])\n",
    "    print(len(X_train_letters[i]))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ddf70e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "#이승훈\n",
    "import cv2 as cv\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "ids=323445\n",
    "X_new=X_train[ids]\n",
    "y_new=y_train[ids]\n",
    "c=X_new.reshape(28,28)\n",
    "\n",
    "\n",
    "plt.imshow(c, cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6185d32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size_row = 3\n",
    "kernel_size_col = 2\n",
    "kernel = np.ones((kernel_size_row, kernel_size_col), np.uint8)\n",
    "\n",
    "erosion_image = cv.erode(X_new, kernel, iterations=1)  #// make erosion image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51a5277b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "kernel_size_row = 3\n",
    "kernel_size_col = 1\n",
    "kernel = np.ones((kernel_size_row, kernel_size_col), np.uint8)\n",
    "\n",
    "erosion_image = cv.erode(X_new, kernel, iterations=1)  #// make erosion image\n",
    "c=erosion_image.reshape(28,28)\n",
    "\n",
    "\n",
    "plt.imshow(c, cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4547afdd",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49ea9a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1951793"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현\n",
    "#data, batch size 성정\n",
    "train_size=len(X_train)\n",
    "valid_size=len(X_valid)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb196c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1951793, 784), (164015, 784))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현\n",
    "X_train=np.reshape(X_train,[-1,784])\n",
    "X_valid=np.reshape(X_valid,[-1,784])\n",
    "X_train.shape,X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f8c165c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1951793, 1), (164015, 1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현\n",
    "y_train=np.reshape(y_train,[-1,1])\n",
    "y_valid=np.reshape(y_valid,[-1,1])\n",
    "\n",
    "y_train.shape,y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52542ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_inputs = 784\n"
     ]
    }
   ],
   "source": [
    "n_inputs = X_train.shape[-1]\n",
    "print(\"n_inputs =\",n_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58fc22e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "def save_to_multiple_csv_files(data, name_prefix, rewrite, header=None, n_parts=10):\n",
    "    \n",
    "    Emnist_dir = os.path.join(\"../공용/datasets\", \"Emnist\")\n",
    "    os.makedirs(Emnist_dir, exist_ok=True)\n",
    "    path_format = os.path.join(Emnist_dir, \"my_{}_{:02d}.csv\")\n",
    "\n",
    "    filepaths = []\n",
    "    m = len(data)\n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        filepaths.append(part_csv)\n",
    "        if rewrite:\n",
    "            \n",
    "            try:\n",
    "                with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
    "                    if header is not None:\n",
    "                        f.write(header)\n",
    "                        f.write(\"\\n\")\n",
    "                    for row_idx in row_indices:\n",
    "                        f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                        f.write(\"\\n\")\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            try:\n",
    "                with open(part_csv, \"xt\", encoding=\"utf-8\") as f:\n",
    "                    if header is not None:\n",
    "                        f.write(header)\n",
    "                        f.write(\"\\n\")\n",
    "                    for row_idx in row_indices:\n",
    "                        f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                        f.write(\"\\n\")\n",
    "            except:\n",
    "                continue\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6576a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full=np.append(X_train,y_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a8dcd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1951793, 785)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a726e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "418d2d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_full=np.append(X_valid,y_valid,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a2a0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "train_filepaths = save_to_multiple_csv_files(train_full, \"train\", n_parts=20,rewrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7584e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "\n",
    "valid_filepaths = save_to_multiple_csv_files(valid_full, \"valid\", n_parts=20,rewrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b0fcde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "\n",
    "def dataaugmentation(X):\n",
    "    datagen=ImageDataGenerator(rotation_range=40,width_shift_range = 0.2, \n",
    "        height_shift_range = 0.2)\n",
    "    #영어 부분 2배 생성\n",
    "    #차원변환 \n",
    "    X=tf.reshape(X,[28,28,1])\n",
    "\n",
    "    #새로운 데이터 생성\n",
    "    angle=(random.random()%1)*np.pi/3-np.pi/6\n",
    "    image_result =tfa.image.rotate(X, tf.constant(angle))#rotate -pi/8~ pi/8\n",
    "    \n",
    "    shift=(random.random()%1)*3 - 1.5\n",
    "    image_result=tfa.image.translate(image_result,[tf.constant(shift),tf.constant(shift)])\n",
    "    \n",
    "    shear_x=(random.random()%1)*np.pi/5-np.pi/10\n",
    "    \n",
    "    #image_result=tfa.image.shear_x(image_result,shear_x,replace=255)\n",
    "    #image_result=np.ndarray(image_result)\n",
    "    #image_result = tf.keras.preprocessing.image.random_shear(image_result,0.2)\n",
    "    \n",
    "    \n",
    "    kernel_size_row = random.randint(2, 3)\n",
    "    kernel_size_col = random.randint(2, 3)\n",
    "    kernel = np.ones((kernel_size_row, kernel_size_col,1), np.float32)\n",
    "\n",
    "    #image_result = cv.erode(image_result, kernel, iterations=1)  #// make erosion image\n",
    "    image_result=tf.reshape(image_result,[1,28,28,1])\n",
    "    image_result = tf.nn.erosion2d(image_result, kernel, strides=(1, 1, 1, 1), padding=\"SAME\", \n",
    "                                   data_format=\"NHWC\", dilations=(1, 1, 1, 1))\n",
    "    image_result=tf.reshape(image_result,[28,28,1])\n",
    "    print(image_result.shape)\n",
    "    image_result=tfa.image.gaussian_filter2d(image_result)\n",
    "    \n",
    "    return image_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc19f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "@tf.function\n",
    "def preprocess_mobilenet_v2(line,randomize=False,visualize=False):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    x=tf.reshape(x,[28,28,1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    augment_image = x\n",
    "    if y > 9 and randomize:\n",
    "        augment_image = dataaugmentation(x)\n",
    "        \n",
    "        \n",
    "    resized_image = tf.image.resize_with_pad(augment_image, 32,32)\n",
    "    final_image = resized_image\n",
    "    if visualize:\n",
    "        final_image = keras.applications.mobilenet_v2.preprocess_input(resized_image)\n",
    "    \n",
    "    return final_image, y\n",
    "\n",
    "@tf.function\n",
    "def preprocess_resnet50(line,randomize=False):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    x=tf.reshape(x,[28,28,1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    augment_image = x\n",
    "    if y > 9 and randomize:\n",
    "        augment_image = dataaugmentation(x)\n",
    "        \n",
    "        \n",
    "    resized_image = tf.image.resize_with_pad(augment_image, [32,32])\n",
    "    if resized_image.shape[2] == 1:\n",
    "        temp=tf.concat([resized_image,resized_image],2)\n",
    "        resized_image=tf.concat([temp,resized_image],2)\n",
    "    final_image = keras.applications.resnet50.preprocess_input(resized_image)\n",
    "    \n",
    "    return final_image, y\n",
    "\n",
    "@tf.function\n",
    "def preprocess_vgg16(line,randomize=False):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    x=tf.reshape(x,[28,28,1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    augment_image = x\n",
    "    if y > 9 and randomize:\n",
    "        augment_image = dataaugmentation(x)\n",
    "        \n",
    "        \n",
    "    resized_image = tf.image.resize_with_pad(augment_image, [32,32])\n",
    "    if resized_image.shape[2] == 1:\n",
    "        temp=tf.concat([resized_image,resized_image],2)\n",
    "        resized_image=tf.concat([temp,resized_image],2)\n",
    "    final_image = keras.applications.vgg16.preprocess_input(resized_image)\n",
    "    \n",
    "    return final_image, y\n",
    "\n",
    "@tf.function\n",
    "def preprocess_renet(line,randomize=False):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    x=tf.reshape(x,[28,28,1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    augment_image = x\n",
    "    if y > 9 and randomize:\n",
    "        augment_image = dataaugmentation(x)\n",
    "        \n",
    "   \n",
    "    return augment_image, y\n",
    "\n",
    "@tf.function\n",
    "def preprocess_xception(line,randomize=False):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    x=tf.reshape(x,[28,28,1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    augment_image = x\n",
    "    if y > 9 and randomize:\n",
    "        augment_image = dataaugmentation(x)\n",
    "        \n",
    "        \n",
    "    resized_image = tf.image.resize_with_pad(augment_image, [32,32])\n",
    "    if resized_image.shape[2] == 1:\n",
    "        temp=tf.concat([resized_image,resized_image],2)\n",
    "        resized_image=tf.concat([temp,resized_image],2)\n",
    "    final_image = keras.applications.xception.preprocess_input(resized_image)\n",
    "    \n",
    "    return final_image, y\n",
    "\n",
    "@tf.function\n",
    "def preprocess_inception_v3(line,randomize=False):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    x=tf.reshape(x,[28,28,1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    augment_image = x\n",
    "    if y > 9 and randomize:\n",
    "        augment_image = dataaugmentation(x)\n",
    "        \n",
    "        \n",
    "    resized_image = tf.image.resize_with_pad(augment_image, [32,32])\n",
    "    if resized_image.shape[2] == 1:\n",
    "        temp=tf.concat([resized_image,resized_image],2)\n",
    "        resized_image=tf.concat([temp,resized_image],2)\n",
    "    final_image = keras.applications.inception_v3.preprocess_input(resized_image)\n",
    "    \n",
    "    return final_image, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acd61bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "from enum import Enum\n",
    "class eModelName(Enum):\n",
    "    mobilenet_v2 = 0,\n",
    "    resnet50 = 1,\n",
    "    vgg16 = 3,\n",
    "    renet = 4,\n",
    "    xception = 5,\n",
    "    inception_v3 = 6\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5359b35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "from functools import partial\n",
    "def csv_reader_dataset(filepaths, model_name, repeat=1, n_readers=5,\n",
    "                       n_read_threads=None, shuffle_buffer_size=60000,\n",
    "                       n_parse_threads=5, batch_size=32,randomize=True, visualize=False):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    if model_name == eModelName.mobilenet_v2:\n",
    "        dataset = dataset.map(partial(preprocess_mobilenet_v2,randomize=randomize,visualize=visualize), \n",
    "                              num_parallel_calls=n_parse_threads)\n",
    "        print(model_name.name)\n",
    "    elif model_name == eModelName.resnet50:\n",
    "        dataset = dataset.map(partial(preprocess_resnet50,randomize=randomize), num_parallel_calls=n_parse_threads)\n",
    "        print(model_name.name)\n",
    "    elif model_name == eModelName.vgg16:\n",
    "        dataset = dataset.map(partial(preprocess_vgg16,randomize=randomize), num_parallel_calls=n_parse_threads)\n",
    "        print(model_name.name)\n",
    "    elif model_name == eModelName.renet:\n",
    "        dataset = dataset.map(partial(preprocess_renet,randomize=randomize), num_parallel_calls=n_parse_threads)\n",
    "        print(model_name.name)\n",
    "    elif model_name == eModelName.xception:\n",
    "        dataset = dataset.map(partial(preprocess_xception,randomize=randomize), num_parallel_calls=n_parse_threads)\n",
    "        print(model_name.name)\n",
    "    elif model_name == eModelName.inception_v3:\n",
    "        dataset = dataset.map(partial(preprocess_inception_v3,randomize=randomize), num_parallel_calls=n_parse_threads)\n",
    "        print(model_name.name)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe30ef1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n",
      "mobilenet_v2\n",
      "(28, 28, 1)\n",
      "mobilenet_v2\n",
      "(28, 28, 1)\n",
      "mobilenet_v2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset element_spec=(TensorSpec(shape=(None, 32, 32, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>,\n",
       " <PrefetchDataset element_spec=(TensorSpec(shape=(None, 32, 32, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>,\n",
       " <PrefetchDataset element_spec=(TensorSpec(shape=(None, 32, 32, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현\n",
    "#csv_reader_dataset의 파라미터 model_name에 eModelNAme class의 맴버 변수 중 사용할 모델 입력\n",
    "#ex) model_name = eModelName.inception_v3, model_name = eModelName.renet \n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "batch_size=64\n",
    "train_set_aug = csv_reader_dataset(train_filepaths, model_name = eModelName.mobilenet_v2, batch_size=batch_size, repeat=None)\n",
    "train_set_vis = csv_reader_dataset(train_filepaths, model_name = eModelName.mobilenet_v2, batch_size=batch_size, repeat=None,\n",
    "                                     visualize=True)\n",
    "valid_set = csv_reader_dataset(valid_filepaths, model_name = eModelName.mobilenet_v2, \n",
    "                               batch_size=batch_size, repeat=None, randomize = False)\n",
    "train_set_aug,valid_set,train_set_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1911bdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image):\n",
    "    plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def plot_color_image(image):\n",
    "    plt.imshow(image, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b2c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for image_features in train_set_vis.unbatch().take(train_size):\n",
    "    x,y=image_features\n",
    "    print(y)\n",
    "    plot_image(x/255)\n",
    "    plt.show()\n",
    "    if count>train_size:\n",
    "        break\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59bf126",
   "metadata": {},
   "source": [
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a248b1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6dbdfb",
   "metadata": {},
   "source": [
    "# SMV2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ab46622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "class Inveted_Residual_Block(keras.layers.Layer):\n",
    "    def __init__(self,c,s=1,t=1,n=1,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.layers.ReLU(max_value=6)\n",
    "        self.main_layers = [\n",
    "            \n",
    "            ]\n",
    "        self.strides_layers=[\n",
    "           ]\n",
    "        self.s=s\n",
    "        self.t=t\n",
    "        self.c=c\n",
    "        self.n=n\n",
    "        \n",
    "    def build(self,batch_input_shape):\n",
    "        #print(self.name,\": batch_input_shape =\",batch_input_shape)\n",
    "        \n",
    "        self.main_layers = [\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=batch_input_shape[-1]*self.t, kernel_size=1,strides=1, \n",
    "                                padding=\"SAME\", activation=self.activation),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.DepthwiseConv2D(kernel_size=3, strides=1,padding=\"SAME\", activation=self.activation),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=self.c,kernel_size=1, strides=1,padding=\"SAME\",activation=None),\n",
    "            ]\n",
    "        self.strides_layers=[\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=batch_input_shape[-1]*self.t, kernel_size=1,strides=1,\n",
    "                                padding=\"SAME\", activation=self.activation),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.DepthwiseConv2D(kernel_size=3, strides=self.s,padding=\"SAME\",activation=self.activation),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=self.c, kernel_size=1,strides=1,padding=\"SAME\",activation=None),\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        \n",
    "        for n in range(0,self.n):\n",
    "            if n == 0:\n",
    "                for layer in self.strides_layers:\n",
    "                    Z = layer(Z)\n",
    "            else:\n",
    "                skip_Z = Z\n",
    "                for layer in self.main_layers:\n",
    "                    Z = layer(Z)\n",
    "                \n",
    "                Z += skip_Z\n",
    "    \n",
    "        return Z\n",
    "    \n",
    "    def get_config(self):\n",
    "        base=super().get_config()\n",
    "        return{**base,\"s\":self.s,\"t\":self.t,\"c\":self.c,\"n\":self.n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab0065d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_2 (Batc  (None, 32, 32, 1)        4         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 32)        320       \n",
      "                                                                 \n",
      " IRB1 (Inveted_Residual_Bloc  (None, 16, 16, 16)       2288      \n",
      " k)                                                              \n",
      "                                                                 \n",
      " IRB2 (Inveted_Residual_Bloc  (None, 8, 8, 16)         6688      \n",
      " k)                                                              \n",
      "                                                                 \n",
      " IRB3 (Inveted_Residual_Bloc  (None, 4, 4, 32)         19456     \n",
      " k)                                                              \n",
      "                                                                 \n",
      " IRB4 (Inveted_Residual_Bloc  (None, 2, 2, 64)         67584     \n",
      " k)                                                              \n",
      "                                                                 \n",
      " IRB5 (Inveted_Residual_Bloc  (None, 1, 1, 128)        108416    \n",
      " k)                                                              \n",
      "                                                                 \n",
      " IRB6 (Inveted_Residual_Bloc  (None, 1, 1, 1024)       1200640   \n",
      " k)                                                              \n",
      "                                                                 \n",
      " re_lu_13 (ReLU)             (None, 1, 1, 1024)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1024)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 62)                63550     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,473,042\n",
      "Trainable params: 1,460,336\n",
      "Non-trainable params: 12,706\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#황성현\n",
    "n_classes=62\n",
    "smv2_l=keras.models.Sequential([\n",
    "    keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "    keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "    Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "    Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "    Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "    Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "    Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "    Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "    keras.layers.ReLU(max_value=6),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "])\n",
    "smv2_l.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a055f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "smv2_l.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                   optimizer=keras.optimizers.Nadam(learning_rate=0.002),\n",
    "                   metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "711927c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/SMV2L20220721-143955\n",
      "Epoch 1/300\n",
      "30496/30496 [==============================] - 1942s 64ms/step - loss: 0.5239 - accuracy: 0.7763 - val_loss: 3.8427 - val_accuracy: 0.5317\n",
      "Epoch 2/300\n",
      "30496/30496 [==============================] - 1934s 63ms/step - loss: 0.4098 - accuracy: 0.8136 - val_loss: 1.6019 - val_accuracy: 0.6614\n",
      "Epoch 3/300\n",
      "30496/30496 [==============================] - 1938s 64ms/step - loss: 0.3862 - accuracy: 0.8234 - val_loss: 4.8639 - val_accuracy: 0.5036\n",
      "Epoch 4/300\n",
      "30496/30496 [==============================] - 1959s 64ms/step - loss: 0.3737 - accuracy: 0.8280 - val_loss: 6.0835 - val_accuracy: 0.4944\n",
      "Epoch 5/300\n",
      "30496/30496 [==============================] - 1955s 64ms/step - loss: 0.3659 - accuracy: 0.8319 - val_loss: 6.2358 - val_accuracy: 0.4983\n",
      "Epoch 6/300\n",
      "30496/30496 [==============================] - 1958s 64ms/step - loss: 0.3599 - accuracy: 0.8349 - val_loss: 6.1326 - val_accuracy: 0.4992\n",
      "Epoch 7/300\n",
      "30496/30496 [==============================] - 1941s 64ms/step - loss: 0.3593 - accuracy: 0.8356 - val_loss: 6.2993 - val_accuracy: 0.4963\n",
      "Epoch 8/300\n",
      "30496/30496 [==============================] - 1946s 64ms/step - loss: 0.3571 - accuracy: 0.8367 - val_loss: 5.2921 - val_accuracy: 0.5008\n",
      "Epoch 9/300\n",
      "30496/30496 [==============================] - 1943s 64ms/step - loss: 0.3580 - accuracy: 0.8368 - val_loss: 7.4521 - val_accuracy: 0.4926\n",
      "Epoch 10/300\n",
      "30496/30496 [==============================] - 1944s 64ms/step - loss: 0.3590 - accuracy: 0.8365 - val_loss: 7.5438 - val_accuracy: 0.4933\n",
      "Epoch 11/300\n",
      "30496/30496 [==============================] - 1941s 64ms/step - loss: 0.3616 - accuracy: 0.8354 - val_loss: 5.5110 - val_accuracy: 0.5090\n",
      "Epoch 12/300\n",
      "30496/30496 [==============================] - 1946s 64ms/step - loss: 0.3643 - accuracy: 0.8343 - val_loss: 7.1639 - val_accuracy: 0.4958\n"
     ]
    }
   ],
   "source": [
    "#황성현\n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_last.h5\",save_best_only=True)\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_best.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_l.fit(train_set_aug, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_last_cb,check_best_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa49e8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 112, 112, 32)\n",
      "IRB2 : batch_input_shape = (None, 112, 112, 16)\n",
      "IRB3 : batch_input_shape = (None, 56, 56, 16)\n",
      "IRB4 : batch_input_shape = (None, 28, 28, 32)\n",
      "IRB5 : batch_input_shape = (None, 14, 14, 64)\n",
      "IRB6 : batch_input_shape = (None, 7, 7, 128)\n"
     ]
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_nadam_last.h5a\",custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "696ed3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14f52a96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "41552/41552 [==============================] - 8762s 211ms/step - loss: 0.3231 - accuracy: 0.8801 - val_loss: 1.0675 - val_accuracy: 0.7649\n",
      "Epoch 2/300\n",
      "41552/41552 [==============================] - 8739s 210ms/step - loss: 0.2940 - accuracy: 0.8895 - val_loss: 11.2437 - val_accuracy: 0.1270\n",
      "Epoch 3/300\n",
      "41552/41552 [==============================] - 8779s 211ms/step - loss: 0.3131 - accuracy: 0.8817 - val_loss: 1.6895 - val_accuracy: 0.7141 accuracy\n",
      "Epoch 4/300\n",
      "41552/41552 [==============================] - 8815s 212ms/step - loss: 0.3288 - accuracy: 0.8782 - val_loss: 4.8713 - val_accuracy: 0.3668\n",
      "Epoch 5/300\n",
      "41552/41552 [==============================] - 8759s 211ms/step - loss: 0.3198 - accuracy: 0.8804 - val_loss: 1.4416 - val_accuracy: 0.7255los\n",
      "Epoch 6/300\n",
      "41552/41552 [==============================] - 8648s 208ms/step - loss: 1.6377 - accuracy: 0.5769 - val_loss: 98.7684 - val_accuracy: 0.0070\n",
      "Epoch 7/300\n",
      "41552/41552 [==============================] - 8648s 208ms/step - loss: 3.8695 - accuracy: 0.0604 - val_loss: 41.4147 - val_accuracy: 0.0201\n",
      "Epoch 8/300\n",
      "41552/41552 [==============================] - 8653s 208ms/step - loss: 3.8593 - accuracy: 0.0611 - val_loss: 5.2386 - val_accuracy: 0.0071\n",
      "Epoch 9/300\n",
      "41552/41552 [==============================] - 8761s 211ms/step - loss: 3.8256 - accuracy: 0.0591 - val_loss: 30.9823 - val_accuracy: 0.0499\n",
      "Epoch 10/300\n",
      "41552/41552 [==============================] - 8610s 207ms/step - loss: 3.8618 - accuracy: 0.0583 - val_loss: 4.0457 - val_accuracy: 0.0360\n",
      "Epoch 11/300\n",
      "41552/41552 [==============================] - 8702s 209ms/step - loss: 3.8083 - accuracy: 0.0589 - val_loss: 8.1110 - val_accuracy: 0.0034\n"
     ]
    }
   ],
   "source": [
    "#황성현\n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L%Y%m%d-%H%M%S\")\n",
    "logs=\"logs/SMV2L20220525-150153\"\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_last.h5\",save_best_only=True)\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_best2.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_l.fit(train_set, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_last_cb,check_best_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7a7c0c",
   "metadata": {},
   "source": [
    "# SMV2P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e896dfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'strategy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7436/2102819137.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#황성현\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mn_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m62\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     smv2_p=keras.models.Sequential([\n\u001b[0;32m      5\u001b[0m         \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'strategy' is not defined"
     ]
    }
   ],
   "source": [
    "#황성현\n",
    "with strategy.scope():\n",
    "    n_classes=62\n",
    "    smv2_p=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=32,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_p.summary()\n",
    "    smv2_p.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                   optimizer=keras.optimizers.Nadam(learning_rate=0.002),\n",
    "                   metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1dc93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 \n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2P%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2p_nadam_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2p_nadam_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_p.fit(train_set_aug, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac956cb1",
   "metadata": {},
   "source": [
    "train SMV2P log in SMV2P&SMV2B.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e221c85",
   "metadata": {},
   "source": [
    "# SMV2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbe4db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "\n",
    "with strategy.scope():\n",
    "    n_classes=62\n",
    "    smv2_b=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=24,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=48,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_b.summary()\n",
    "    smv2_b.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                   optimizer=\"nadam\",\n",
    "                   metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ece3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 \n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2B%Y%m%d-%H%M%S\")\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2b_nadam_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2b_nadam_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "#cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "\n",
    "history=smv2_b.fit(train_set_aug, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4960928d",
   "metadata": {},
   "source": [
    "train SMV2B log in SMV2P&SMV2B.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ace1afc",
   "metadata": {},
   "source": [
    "# Select the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff156d",
   "metadata": {},
   "source": [
    "# SMV2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de5832e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 112, 112, 32)\n",
      "IRB2 : batch_input_shape = (None, 112, 112, 16)\n",
      "IRB3 : batch_input_shape = (None, 56, 56, 16)\n",
      "IRB4 : batch_input_shape = (None, 28, 28, 32)\n",
      "IRB5 : batch_input_shape = (None, 14, 14, 64)\n",
      "IRB6 : batch_input_shape = (None, 7, 7, 128)\n"
     ]
    }
   ],
   "source": [
    "#황성현 \n",
    "smv2l=keras.models.load_model(\"smv2l_nadam_last.h5\",custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52326618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5125/5125 [==============================] - 136s 26ms/step - loss: 1.0651 - accuracy: 0.7656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.065091848373413, 0.7656341195106506]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현 \n",
    "smv2l.evaluate(valid_set,steps=int(valid_size / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0826be",
   "metadata": {},
   "source": [
    "# SMV2P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4473204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 112, 112, 32)\n",
      "IRB2 : batch_input_shape = (None, 112, 112, 16)\n",
      "IRB3 : batch_input_shape = (None, 56, 56, 32)\n",
      "IRB4 : batch_input_shape = (None, 28, 28, 64)\n",
      "IRB5 : batch_input_shape = (None, 14, 14, 64)\n",
      "IRB6 : batch_input_shape = (None, 7, 7, 128)\n"
     ]
    }
   ],
   "source": [
    "#황성현 \n",
    "smv2p=keras.models.load_model(\"smv2p_nadam_best.h5\",custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53598402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5125/5125 [==============================] - 149s 28ms/step - loss: 1.3054 - accuracy: 0.7546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.305375337600708, 0.7546097636222839]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현 \n",
    "smv2p.evaluate(valid_set,steps=int(valid_size / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4f9866",
   "metadata": {},
   "source": [
    "# SMV2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e37bae2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 112, 112, 32)\n",
      "IRB2 : batch_input_shape = (None, 112, 112, 16)\n",
      "IRB3 : batch_input_shape = (None, 56, 56, 24)\n",
      "IRB4 : batch_input_shape = (None, 28, 28, 48)\n",
      "IRB5 : batch_input_shape = (None, 14, 14, 64)\n",
      "IRB6 : batch_input_shape = (None, 7, 7, 128)\n"
     ]
    }
   ],
   "source": [
    "#황성현 \n",
    "mv2b=keras.models.load_model(\"smv2b_nadam_best.h5\",custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f4819bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5125/5125 [==============================] - 158s 30ms/step - loss: 1.8271 - accuracy: 0.6875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.827067255973816, 0.6874512434005737]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현 \n",
    "smv2b.evaluate(valid_set,steps=int(valid_size / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bae7880",
   "metadata": {},
   "source": [
    "# Fine Tune the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957ad3ae",
   "metadata": {},
   "source": [
    "# Batch size up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f45034d",
   "metadata": {},
   "source": [
    "# Batch 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c7e302",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #황성현\n",
    "    #multygpu\n",
    "    n_classes=62\n",
    "    smv2_p=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0bde72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#천문성\n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_BATCH64_%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "batch_size=64\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_batch64_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_batch64_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_l.fit(X_train_resize,y_train, batch_size = batch_size,\n",
    "                    validation_data=(X_valid_resize,y_valid),                   \n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6334dc5",
   "metadata": {},
   "source": [
    "train logs in SMV2L_batch_up.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d54c8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 41s 7ms/step - loss: 0.3501 - accuracy: 0.8714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3500642478466034, 0.8713958859443665]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_nadam_batch64_best.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243636e7",
   "metadata": {},
   "source": [
    "# Batch 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ecc048",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_classes=62\n",
    "smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "smv2_l.summary()\n",
    "smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778fd64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#천문성\n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_BATCH128_%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "batch_size=128\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_batch128_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_batch128_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_l.fit(X_train_resize,y_train, batch_size = batch_size,\n",
    "                    validation_data=(X_valid_resize,y_valid),                   \n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0183de8",
   "metadata": {},
   "source": [
    "train logs in SMV2L_batch_up.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1af0561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 36s 7ms/step - loss: 0.3537 - accuracy: 0.8674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35373783111572266, 0.8674450516700745]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_nadam_batch128_best.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8c3807",
   "metadata": {},
   "source": [
    "# Batch size up & Learning rateup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd5c266",
   "metadata": {},
   "source": [
    "# smv2l when batch_size=64, lr=0.002 by minsung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c84178dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_9 (Batch (None, 32, 32, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 32)        320       \n",
      "_________________________________________________________________\n",
      "IRB1 (Inveted_Residual_Block (None, 16, 16, 16)        2288      \n",
      "_________________________________________________________________\n",
      "IRB2 (Inveted_Residual_Block (None, 8, 8, 16)          6688      \n",
      "_________________________________________________________________\n",
      "IRB3 (Inveted_Residual_Block (None, 4, 4, 32)          19456     \n",
      "_________________________________________________________________\n",
      "IRB4 (Inveted_Residual_Block (None, 2, 2, 64)          67584     \n",
      "_________________________________________________________________\n",
      "IRB5 (Inveted_Residual_Block (None, 1, 1, 128)         108416    \n",
      "_________________________________________________________________\n",
      "IRB6 (Inveted_Residual_Block (None, 1, 1, 1024)        1200640   \n",
      "_________________________________________________________________\n",
      "re_lu_34 (ReLU)              (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 62)                63550     \n",
      "=================================================================\n",
      "Total params: 1,473,042\n",
      "Trainable params: 1,460,336\n",
      "Non-trainable params: 12,706\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#황성현\n",
    "n_classes=62\n",
    "smv2_l=keras.models.Sequential([\n",
    "    keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "    keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "    Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "    Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "    Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "    Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "    Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "    Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "    keras.layers.ReLU(max_value=6),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "])\n",
    "smv2_l.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab004a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Nadam(learning_rate=0.002)\n",
    "batch_size=64\n",
    "smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536d88cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#황성현 \n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_batch_64_lr_002%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "\n",
    "check_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"SMV2L_batch_64_lr_002.h5\",save_best_only=True)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_l.fit(X_train_resize,y_train, batch_size = batch_size,\n",
    "                    validation_data=(X_valid_resize,y_valid),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_cb, earlystop_cb])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adb7c0e",
   "metadata": {},
   "source": [
    "train logs in np_batch_lr_up_tunining.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c18dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "smv2_l=keras.models.load_model(\"SMV2L_batch_64_lr_002.h5\",\n",
    "                              custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9977cf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5126/5126 [==============================] - 37s 7ms/step - loss: 0.3861 - accuracy: 0.8584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38609299063682556, 0.8584336638450623]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5505d01a",
   "metadata": {},
   "source": [
    "# smv2l when batch_size=256, lr=0.008 by minsung, seounghyun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a489d7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_11 (Batc (None, 32, 32, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 32)        320       \n",
      "_________________________________________________________________\n",
      "IRB1 (Inveted_Residual_Block (None, 16, 16, 16)        2288      \n",
      "_________________________________________________________________\n",
      "IRB2 (Inveted_Residual_Block (None, 8, 8, 16)          6688      \n",
      "_________________________________________________________________\n",
      "IRB3 (Inveted_Residual_Block (None, 4, 4, 32)          19456     \n",
      "_________________________________________________________________\n",
      "IRB4 (Inveted_Residual_Block (None, 2, 2, 64)          67584     \n",
      "_________________________________________________________________\n",
      "IRB5 (Inveted_Residual_Block (None, 1, 1, 128)         108416    \n",
      "_________________________________________________________________\n",
      "IRB6 (Inveted_Residual_Block (None, 1, 1, 1024)        1200640   \n",
      "_________________________________________________________________\n",
      "re_lu_53 (ReLU)              (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 62)                63550     \n",
      "=================================================================\n",
      "Total params: 1,473,042\n",
      "Trainable params: 1,460,336\n",
      "Non-trainable params: 12,706\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#황성현\n",
    "n_classes=62\n",
    "smv2_l=keras.models.Sequential([\n",
    "    keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "    keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "    Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "    Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "    Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "    Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "    Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "    Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "    keras.layers.ReLU(max_value=6),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "])\n",
    "smv2_l.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1887691",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Nadam(learning_rate=0.008)\n",
    "batch_size=256\n",
    "smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43868cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 \n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_batch_256_lr_008%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "\n",
    "check_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"SMV2L_batch_256_lr_008.h5\",save_best_only=True)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_l.fit(X_train_resize,y_train, batch_size = batch_size,\n",
    "                    validation_data=(X_valid_resize,y_valid),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc1efb1",
   "metadata": {},
   "source": [
    "train logs in np_batch_lr_up_tunining.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c8590b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n"
     ]
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"SMV2L_batch_256_lr_008.h5\",\n",
    "                              custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "448f0db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5126/5126 [==============================] - 34s 6ms/step - loss: 0.4856 - accuracy: 0.8300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4856473207473755, 0.8299667835235596]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c61eaa",
   "metadata": {},
   "source": [
    "valid loss is not good. but in train logs, this model arrived 80% accuracy fastly, so we decided use this with learning rate schedular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8da0bff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_13 (Batc (None, 32, 32, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 32)        320       \n",
      "_________________________________________________________________\n",
      "IRB1 (Inveted_Residual_Block (None, 16, 16, 16)        2288      \n",
      "_________________________________________________________________\n",
      "IRB2 (Inveted_Residual_Block (None, 8, 8, 16)          6688      \n",
      "_________________________________________________________________\n",
      "IRB3 (Inveted_Residual_Block (None, 4, 4, 32)          19456     \n",
      "_________________________________________________________________\n",
      "IRB4 (Inveted_Residual_Block (None, 2, 2, 64)          67584     \n",
      "_________________________________________________________________\n",
      "IRB5 (Inveted_Residual_Block (None, 1, 1, 128)         108416    \n",
      "_________________________________________________________________\n",
      "IRB6 (Inveted_Residual_Block (None, 1, 1, 1024)        1200640   \n",
      "_________________________________________________________________\n",
      "re_lu_66 (ReLU)              (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 62)                63550     \n",
      "=================================================================\n",
      "Total params: 1,473,042\n",
      "Trainable params: 1,460,336\n",
      "Non-trainable params: 12,706\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#황성현\n",
    "n_classes=62\n",
    "smv2_l=keras.models.Sequential([\n",
    "    keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "    keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "    Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "    Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "    Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "    Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "    Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "    Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "    keras.layers.ReLU(max_value=6),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "])\n",
    "smv2_l.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b6c4899",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Nadam(learning_rate=0.008)\n",
    "batch_size=256\n",
    "smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0eda21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 \n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_batch_256_lr_008_sch_exp%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 2:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "check_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"SMV2L_batch_256_lr_008_sch_exp.h5\",save_best_only=True)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_l.fit(X_train_resize,y_train, batch_size = batch_size,\n",
    "                    validation_data=(X_valid_resize,y_valid),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_cb, earlystop_cb,lr_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1de370",
   "metadata": {},
   "source": [
    "train logs in np_batch_lr_up_tunining.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0c87e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n"
     ]
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"SMV2L_batch_256_lr_008_sch_exp.h5\",\n",
    "                              custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8634ea54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641/641 [==============================] - 5s 8ms/step - loss: 0.3488 - accuracy: 0.8723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34879040718078613, 0.872304379940033]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l.evaluate(X_valid_resize,y_valid,batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceabf5f",
   "metadata": {},
   "source": [
    "it arrived 87% accuracy faster than 32 batch size, 0.001 learning rate. So we try to finetune with batch size up learning rate up "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bde21c3",
   "metadata": {},
   "source": [
    "# Optimizer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81d3aaa",
   "metadata": {},
   "source": [
    "finetuning - optimizer logs in np_SMV2_optimizer.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2941ae78",
   "metadata": {},
   "source": [
    "nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c709d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "#multygpu\n",
    "with strategy.scope():\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                   optimizer=keras.optimizers.Nadam(learning_rate=0.002),\n",
    "                   metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe6ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_NP%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_np_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_np_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "lr_callback=keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.5)\n",
    "history=smv2_l.fit(train_set_aug, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb])"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "d8210f2c",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "best log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893345d9",
   "metadata": {},
   "source": [
    "adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ab2383",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                   optimizer=keras.optimizers.Adam(learning_rate=0.002),\n",
    "                   metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e4bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_ADAM%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_adam_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_adam_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "lr_callback=keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.4)\n",
    "history=smv2_l.fit(train_set_aug, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8c4f9117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 28s 5ms/step - loss: 0.3377 - accuracy: 0.8751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3376833498477936, 0.875054121017456]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_adam_np_best.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74272bcd",
   "metadata": {},
   "source": [
    "rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "#multygpu\n",
    "with strategy.scope():\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                   optimizer=keras.optimizers.RMSprop(learning_rate=0.002),\n",
    "                   metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c5cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "from datetime import datetime\n",
    "batch_size=32\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_RMSPROP%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_rmsprop_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_rmsprop_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "lr_callback=keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.4)\n",
    "history=smv2_l.fit(train_set_aug, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "52545804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 29s 6ms/step - loss: 0.3403 - accuracy: 0.8740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3402675986289978, 0.874029815196991]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_rmsprop_np_best.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5ddf8d",
   "metadata": {},
   "source": [
    "neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20ed283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "#multygpu\n",
    "with strategy.scope():\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                   optimizer=keras.optimizers.SGD(learning_rate=0.02,momentum=0.9,nesterov=True)\n",
    "                   ,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90e99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "from datetime import datetime\n",
    "batch_size=32\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_NAG%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nag_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nag_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "lr_callback=keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.4)\n",
    "history=smv2_l.fit(train_set_aug, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "46af46e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 40s 8ms/step - loss: 869.7309 - accuracy: 0.0043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[869.7308959960938, 0.004267902113497257]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_nag_np_best.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4001779",
   "metadata": {},
   "source": [
    "Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7abd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "#multygpu\n",
    "with strategy.scope():\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                   optimizer=keras.optimizers.SGD(learning_rate=0.02,momentum=0.9)\n",
    "                   ,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15093ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "from datetime import datetime\n",
    "batch_size=32\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2P_NP_MOMENTUM%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_momentum_np_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_momentum_np_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "lr_callback=keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.4)\n",
    "history=smv2_l.fit(train_set_aug, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e52c8b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 28s 5ms/step - loss: 0.3524 - accuracy: 0.8695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35244783759117126, 0.8694936633110046]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_momentum_np_best.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b486da62",
   "metadata": {},
   "source": [
    "adam is best!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6323b83a",
   "metadata": {},
   "source": [
    "smv2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccfef53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f733914c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf076b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3298f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762d5e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b74cee1",
   "metadata": {},
   "source": [
    "# augmentation + learning rate schedular + adam + batchup learningrate up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61969288",
   "metadata": {},
   "source": [
    "ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eaebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #전민재\n",
    "    #multygpu\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.006)\n",
    "    batch_size=256\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 \n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_lrsch_plat_aug_adam_%Y%m%d-%H%M%S\")\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=3, min_lr=0.000001)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_best_lrsch_plat_aug_adam.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_last_lrsch_plat_aug_adam.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_l.fit(X_train_aug,y_train_aug,\n",
    "                   validation_data=(X_valid_final,y_valid),batch_size = batch_size, \n",
    "                   epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb,reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f765502",
   "metadata": {},
   "source": [
    "train logs in smv2l_adam_best_lrsch_plat_aug.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bee523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      " 521/5126 [==>...........................] - ETA: 42s - loss: 0.3466 - accuracy: 0.8706"
     ]
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_nadam_best_lrsch_plat_aug_adam.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3d134c",
   "metadata": {},
   "source": [
    "change batch_size 128, learning rate 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9143354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #황성현\n",
    "    #multygpu\n",
    "\n",
    "\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.003)\n",
    "    batch_size=128\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a34c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 \n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_lrsch_plat_aug128%Y%m%d-%H%M%S\")\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=3, min_lr=0.000001)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_best_lrsch_plat_aug128.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_last_lrsch_plat_aug128.h5\",save_best_only=True)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_l.fit(X_train_aug,y_train_aug,\n",
    "                   validation_data=(X_valid_final,y_valid),batch_size = batch_size, \n",
    "                   epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb,reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdc4ba9",
   "metadata": {},
   "source": [
    "train logs in smv2l_adam_lrsch_plat_aug_128.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34919ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 39s 8ms/step - loss: 0.3390 - accuracy: 0.8745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3389529585838318, 0.8744931817054749]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_adam_lrsch_plat_aug128.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac1af70",
   "metadata": {},
   "source": [
    "Onecycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "155c4985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전민재\n",
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "            rate = max(rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.lr, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30bd1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #황성현 전민재\n",
    "    #multygpu\n",
    "\n",
    "\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "    batch_size=128\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd1161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 전민재\n",
    "from datetime import datetime\n",
    "K = keras.backend\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_lrsch_onecycle_aug128%Y%m%d-%H%M%S\")\n",
    "epochs=50\n",
    "onecycle = OneCycleScheduler(len(X_train) // batch_size * epochs, max_rate=0.003)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_adam_best_lrsch_onecycle_aug128.h5\",save_best_only=True)\n",
    "\n",
    "history=smv2_l.fit(X_train_aug,y_train_aug,\n",
    "                   validation_data=(X_valid_final,y_valid),batch_size = batch_size, \n",
    "                   epochs=epochs,callbacks=[tboard_callback, check_best_cb,onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb8888a",
   "metadata": {},
   "source": [
    "train logs in smv2l_adam_lrsch_onecycle_aug_128.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ac6bdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 40s 8ms/step - loss: 0.3331 - accuracy: 0.8774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33308178186416626, 0.8774136304855347]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_adam_lrsch_onecycle_aug128.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764fa276",
   "metadata": {},
   "source": [
    "# Drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea6b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #황성현 전민재\n",
    "    #multygpu\n",
    "\n",
    "\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "    batch_size=128\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d303adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 전민재\n",
    "from datetime import datetime\n",
    "K = keras.backend\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_lrsch_onecycle_aug_dropout_128%Y%m%d-%H%M%S\")\n",
    "onecycle = OneCycleScheduler(len(X_train) // batch_size * 50, max_rate=0.003)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_adam_best_lrsch_onecycle_aug_dropout_128.h5\",save_best_only=True)\n",
    "\n",
    "history=smv2_l.fit(X_train_aug,y_train_aug,\n",
    "                   validation_data=(X_valid_final,y_valid),batch_size = batch_size, \n",
    "                   epochs=50,callbacks=[tboard_callback, check_best_cb,onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c86bd91",
   "metadata": {},
   "source": [
    "train logs in smv2l_adam_lrsch_onecycle_aug_dropout128.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0470d8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 40s 8ms/step - loss: 0.3265 - accuracy: 0.8785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3265077769756317, 0.8784623146057129]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_adam_lrsch_onecycle_aug_dropout_128.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aadf5d",
   "metadata": {},
   "source": [
    "change epochs 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1f0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #황성현 전민재\n",
    "    #multygpu\n",
    "\n",
    "\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "    batch_size=128\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b573fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 전민재\n",
    "from datetime import datetime\n",
    "K = keras.backend\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_lrsch_onecycle_aug_dropout_128_epoch40%Y%m%d-%H%M%S\")\n",
    "epochs=40\n",
    "onecycle = OneCycleScheduler(len(X_train) // batch_size * epochs, max_rate=0.003)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_adam_best_lrsch_onecycle_aug_dropout_128_epoch40.h5\",save_best_only=True)\n",
    "\n",
    "history=smv2_l.fit(X_train_aug,y_train_aug,\n",
    "                   validation_data=(X_valid_final,y_valid),batch_size = batch_size,\n",
    "                   epochs=epochs,callbacks=[tboard_callback, check_best_cb,onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed90f23",
   "metadata": {},
   "source": [
    "train logs in smv2l_adam_lrsch_onecycle_aug_dropout128_epoch40.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58ba0cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 39s 8ms/step - loss: 0.3291 - accuracy: 0.8782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3291375935077667, 0.8781574964523315]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_adam_lrsch_onecycle_aug_dropout_128_epoch40.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f3d49d",
   "metadata": {},
   "source": [
    "At seleting model step, we see that smv2l,much simple than smv2p, is better than smv2p. So, how about making more simple model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8116db",
   "metadata": {},
   "source": [
    "# IRB6 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0ea8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_1 (Batc  (None, 32, 32, 1)        4         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 32)        320       \n",
      "                                                                 \n",
      " IRB1 (Inveted_Residual_Bloc  (None, 16, 16, 16)       2288      \n",
      " k)                                                              \n",
      "                                                                 \n",
      " IRB2 (Inveted_Residual_Bloc  (None, 8, 8, 16)         6688      \n",
      " k)                                                              \n",
      "                                                                 \n",
      " IRB3 (Inveted_Residual_Bloc  (None, 4, 4, 32)         19456     \n",
      " k)                                                              \n",
      "                                                                 \n",
      " IRB4 (Inveted_Residual_Bloc  (None, 2, 2, 64)         67584     \n",
      " k)                                                              \n",
      "                                                                 \n",
      " IRB5 (Inveted_Residual_Bloc  (None, 1, 1, 128)        108416    \n",
      " k)                                                              \n",
      "                                                                 \n",
      " IRB6 (Inveted_Residual_Bloc  (None, 1, 1, 512)        675840    \n",
      " k)                                                              \n",
      "                                                                 \n",
      " re_lu_6 (ReLU)              (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                31806     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 914,450\n",
      "Trainable params: 902,768\n",
      "Non-trainable params: 11,682\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "    #황성현 전민재 IRB6512\n",
    "    #multygpu\n",
    "\n",
    "\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=512,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "    batch_size=128\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cba4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 전민재\n",
    "from datetime import datetime\n",
    "K = keras.backend\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_lrsch_onecycle_aug_dropout_128_he_irb6_512%Y%m%d-%H%M%S\")\n",
    "onecycle = OneCycleScheduler(len(X_train) // batch_size * 50, max_rate=0.003)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_adam_best_lrsch_onecycle_aug_dropout_128_he_irb6_512.h5\",save_best_only=True)\n",
    "\n",
    "history=smv2_l.fit(X_train,y_train,\n",
    "                   validation_data=(X_valid_resize,y_valid),batch_size = batch_size, \n",
    "                   epochs=50,callbacks=[tboard_callback, check_best_cb,onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4bc1fa",
   "metadata": {},
   "source": [
    "train logs in smv2l_adam_lrsch_onecycle_aug_dropout128_he_irb6_512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45162586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-12 03:37:19.865088: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5126/5126 [==============================] - 67s 12ms/step - loss: 0.3281 - accuracy: 0.8778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.328132301568985, 0.8778160810470581]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_adam_lrsch_onecycle_aug_dropout_128_he_irb6_512.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa1acfc",
   "metadata": {},
   "source": [
    "change epochs to 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b8b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #황성현 전민재 IRB6512\n",
    "    #multygpu\n",
    "\n",
    "\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=512,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "    batch_size=128\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79ca606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 전민재\n",
    "from datetime import datetime\n",
    "K = keras.backend\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_lrsch_onecycle_aug_dropout_128_he_irb6_512_epoch40%Y%m%d-%H%M%S\")\n",
    "onecycle = OneCycleScheduler(len(X_train) // batch_size * 30, max_rate=0.003)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_adam_best_lrsch_onecycle_aug_dropout_128_he_irb6_512_epoch40.h5\",save_best_only=True)\n",
    "\n",
    "history=smv2_l.fit(X_train,y_train,\n",
    "                   validation_data=(X_valid_resize,y_valid),batch_size = batch_size,\n",
    "                   epochs=30,callbacks=[tboard_callback, check_best_cb,onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017edbc1",
   "metadata": {},
   "source": [
    "train logs in smv2l_adam_lrsch_onecycle_aug_dropout128_he_irb6_512_epoch30.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5e7b4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 61s 12ms/step - loss: 0.3266 - accuracy: 0.8783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3266333043575287, 0.878279447555542]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_adam_lrsch_onecycle_aug_dropout_128_he_irb6_512_epoch30.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9e3fde",
   "metadata": {},
   "source": [
    "change epochs to 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17094b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #황성현 전민재 IRB6512\n",
    "    #multygpu\n",
    "\n",
    "\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=512,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "    batch_size=128\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a490dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 전민재\n",
    "from datetime import datetime\n",
    "K = keras.backend\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_lrsch_onecycle_aug_dropout_128_he_irb6_512_epoch40%Y%m%d-%H%M%S\")\n",
    "onecycle = OneCycleScheduler(len(X_train) // batch_size * 40, max_rate=0.003)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_adam_best_lrsch_onecycle_aug_dropout_128_he_irb6_512_epoch40.h5\",save_best_only=True)\n",
    "\n",
    "history=smv2_l.fit(X_train,y_train,\n",
    "                   validation_data=(X_valid_resize,y_valid),batch_size = batch_size, \n",
    "                   epochs=40,callbacks=[tboard_callback, check_best_cb,onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830da52c",
   "metadata": {},
   "source": [
    "train logs in smv2l_adam_lrsch_onecycle_aug_dropout128_he_irb6_512_epoch40.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "672fc607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 61s 12ms/step - loss: 0.3293 - accuracy: 0.8785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3292776644229889, 0.8784501552581787]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_adam_lrsch_onecycle_aug_dropout_128_he_irb6_512_epoch40.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7135ff29",
   "metadata": {},
   "source": [
    "change epochs to 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233c206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #황성현 전민재 IRB6512\n",
    "    #multygpu\n",
    "\n",
    "\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=512,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "    batch_size=128\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5325a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 전민재\n",
    "from datetime import datetime\n",
    "K = keras.backend\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_lrsch_onecycle_aug_dropout_128_he_irb6_512_epoch70%Y%m%d-%H%M%S\")\n",
    "onecycle = OneCycleScheduler(len(X_train) // batch_size * 70, max_rate=0.003)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_adam_best_lrsch_onecycle_aug_dropout_128_he_irb6_512_epoch70.h5\",save_best_only=True)\n",
    "\n",
    "history=smv2_l.fit(X_train,y_train,\n",
    "                   validation_data=(X_valid_resize,y_valid),batch_size = batch_size, \n",
    "                   epochs=70,callbacks=[tboard_callback, check_best_cb,onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1492abe3",
   "metadata": {},
   "source": [
    "train logs in smv2l_adam_lrsch_onecycle_aug_dropout128_he_irb6_512_epoch70.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c82080",
   "metadata": {},
   "source": [
    "# 이거실행 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4918864a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at smv2l_adam_lrsch_onecycle_aug_dropout_128_he_irb6_512_epoch70.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14307/4222598604.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m smv2_l=keras.models.load_model(\"smv2l_adam_lrsch_onecycle_aug_dropout_128_he_irb6_512_epoch70.h5\",\n\u001b[0m\u001b[1;32m      2\u001b[0m                              custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n\u001b[1;32m      3\u001b[0m \u001b[0msmv2_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid_resize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'No file or directory found at {filepath_str}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at smv2l_adam_lrsch_onecycle_aug_dropout_128_he_irb6_512_epoch70.h5"
     ]
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_adam_lrsch_onecycle_aug_dropout_128_he_irb6_512_epoch70.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)\n",
    "#smv2l_adam_lrsch_onecycle_aug_dropout128_he_irb6_512_epoch70.ipynb 참조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f994bb1",
   "metadata": {},
   "source": [
    "40 epochs is best!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daed644",
   "metadata": {},
   "source": [
    "# SMV2SL + preprocess input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36356b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #황성현 전민재 IRB6512, maxlr 0.002\n",
    "    #multygpu\n",
    "\n",
    "\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=2,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=4,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=4,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=4,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=4,c=512,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "    batch_size=128\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbf4d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 전민재\n",
    "from datetime import datetime\n",
    "K = keras.backend\n",
    "epochs=40\n",
    "logs = \"logs/\" + datetime.now().strftime(\"smv2l_adam_best_lrsch_onecycle_aug_dropout_128_he_irb6_512_t4_epoch40%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "onecycle = OneCycleScheduler(len(X_train_resize) // batch_size * epochs, max_rate=0.003)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_adam_best_lrsch_onecycle_aug_dropout_128_he_irb6_512_t4_epoch40.h5\",save_best_only=True)\n",
    "\n",
    "history=smv2_l.fit(X_train_aug,y_train_aug,\n",
    "                   validation_data=(X_valid_final,y_valid),batch_size = batch_size, \n",
    "                   epochs=epochs,callbacks=[tboard_callback, check_best_cb,onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4fb314",
   "metadata": {},
   "source": [
    "train logs in smv2sl_adam_lrsch_onecycle_aug_dropout_epoch40.lpynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "257bffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 39s 7ms/step - loss: 0.3349 - accuracy: 0.8773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3349411189556122, 0.8773038983345032]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_adam_best_lrsch_onecycle_aug_dropout_128_he_irb6_512_t4_epoch40.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_final,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca52e4f",
   "metadata": {},
   "source": [
    "# SMV2SL + preprocess input + 1x1 conv2d linear activation + Swap BN and Activation positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f98dd402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 \n",
    "class Inveted_Residual_Block2(keras.layers.Layer):\n",
    "    def __init__(self,c,s=1,t=1,n=1,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.layers.ReLU(max_value=6)\n",
    "        self.main_layers = [\n",
    "            \n",
    "            ]\n",
    "        self.strides_layers=[\n",
    "           ]\n",
    "        self.s=s\n",
    "        self.t=t\n",
    "        self.c=c\n",
    "        self.n=n\n",
    "        \n",
    "    def build(self,batch_input_shape):\n",
    "        print(self.name,\": batch_input_shape =\",batch_input_shape)\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        self.main_layers = [\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=batch_input_shape[-1]*self.t, kernel_size=1,strides=1, kernel_initializer=initializer,\n",
    "                                padding=\"SAME\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            keras.layers.DepthwiseConv2D(kernel_size=3, strides=1,padding=\"SAME\",kernel_initializer=initializer),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            keras.layers.Conv2D(filters=self.c,kernel_size=1, strides=1,padding=\"SAME\",kernel_initializer=initializer),\n",
    "            ]\n",
    "        self.strides_layers=[\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=batch_input_shape[-1]*self.t, kernel_size=1,strides=1,kernel_initializer=initializer,\n",
    "                                padding=\"SAME\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            keras.layers.DepthwiseConv2D(kernel_size=3, strides=self.s,padding=\"SAME\",kernel_initializer=initializer),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            keras.layers.Conv2D(filters=self.c, kernel_size=1,strides=1,padding=\"SAME\",kernel_initializer=initializer),\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        \n",
    "        for n in range(0,self.n):\n",
    "            if n == 0:\n",
    "                for layer in self.strides_layers:\n",
    "                    Z = layer(Z)\n",
    "            else:\n",
    "                skip_Z = Z\n",
    "                for layer in self.main_layers:\n",
    "                    Z = layer(Z)\n",
    "                \n",
    "                Z += skip_Z\n",
    "    \n",
    "        return Z\n",
    "    \n",
    "    def get_config(self):\n",
    "        base=super().get_config()\n",
    "        return{**base,\"s\":self.s,\"t\":self.t,\"c\":self.c,\"n\":self.n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c6931263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_6 (Batc  (None, 32, 32, 1)        4         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 32)        320       \n",
      "                                                                 \n",
      " IRB1 (Inveted_Residual_Bloc  (None, 16, 16, 16)       2288      \n",
      " k2)                                                             \n",
      "                                                                 \n",
      " IRB2 (Inveted_Residual_Bloc  (None, 8, 8, 16)         3424      \n",
      " k2)                                                             \n",
      "                                                                 \n",
      " IRB3 (Inveted_Residual_Bloc  (None, 4, 4, 32)         9856      \n",
      " k2)                                                             \n",
      "                                                                 \n",
      " IRB4 (Inveted_Residual_Bloc  (None, 2, 2, 64)         34048     \n",
      " k2)                                                             \n",
      "                                                                 \n",
      " IRB5 (Inveted_Residual_Bloc  (None, 1, 1, 128)        54400     \n",
      " k2)                                                             \n",
      "                                                                 \n",
      " IRB6 (Inveted_Residual_Bloc  (None, 1, 1, 512)        338432    \n",
      " k2)                                                             \n",
      "                                                                 \n",
      " re_lu_27 (ReLU)             (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 62)                31806     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 476,626\n",
      "Trainable params: 469,808\n",
      "Non-trainable params: 6,818\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "    #이승훈 황성현\n",
    "    #SMV2SL\n",
    "\n",
    "n_classes=62\n",
    "smv2_SL=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block2(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block2(t=2,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block2(t=4,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block2(t=4,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block2(t=4,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block2(t=4,c=512,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    \n",
    "smv2_SL.summary()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.003)\n",
    "batch_size=128\n",
    "smv2_SL.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c8597d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_v2\n",
      "mobilenet_v2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset element_spec=(TensorSpec(shape=(None, 32, 32, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>,\n",
       " <PrefetchDataset element_spec=(TensorSpec(shape=(None, 32, 32, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현\n",
    "#csv_reader_dataset의 파라미터 model_name에 eModelNAme class의 맴버 변수 중 사용할 모델 입력\n",
    "#ex) model_name = eModelName.inception_v3, model_name = eModelName.renet \n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "train_set = csv_reader_dataset(train_filepaths, model_name = eModelName.mobilenet_v2, batch_size=batch_size, repeat=None)\n",
    "valid_set = csv_reader_dataset(valid_filepaths, model_name = eModelName.mobilenet_v2, \n",
    "                               batch_size=batch_size, repeat=None, randomize = False)\n",
    "train_set,valid_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5bdd88c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전민재\n",
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "            rate = max(rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.lr, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755752b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/SMV2SL_adam_best_lrsch_onecycle_aug_epoch4020220711-160257\n",
      "Epoch 1/1000\n",
      "15248/15248 [==============================] - 604s 39ms/step - loss: 0.3691 - accuracy: 0.8846 - val_loss: 3.4463 - val_accuracy: 0.5712\n",
      "Epoch 2/1000\n",
      "15248/15248 [==============================] - 611s 40ms/step - loss: 0.2071 - accuracy: 0.9299 - val_loss: 7.4130 - val_accuracy: 0.5045\n",
      "Epoch 3/1000\n",
      "15248/15248 [==============================] - 621s 41ms/step - loss: 0.1593 - accuracy: 0.9480 - val_loss: 5.9690 - val_accuracy: 0.5216\n",
      "Epoch 4/1000\n",
      "15248/15248 [==============================] - 630s 41ms/step - loss: 0.1595 - accuracy: 0.9424 - val_loss: 5.2438 - val_accuracy: 0.5243\n",
      "Epoch 5/1000\n",
      "15248/15248 [==============================] - 642s 42ms/step - loss: 0.1794 - accuracy: 0.9341 - val_loss: 4.3847 - val_accuracy: 0.5469\n",
      "Epoch 6/1000\n",
      "15248/15248 [==============================] - 642s 42ms/step - loss: 0.1746 - accuracy: 0.9351 - val_loss: 4.4242 - val_accuracy: 0.5376\n",
      "Epoch 7/1000\n",
      "15248/15248 [==============================] - 615s 40ms/step - loss: 0.1482 - accuracy: 0.9499 - val_loss: 5.4675 - val_accuracy: 0.5152\n",
      "Epoch 8/1000\n",
      "15248/15248 [==============================] - 601s 39ms/step - loss: 0.1563 - accuracy: 0.9439 - val_loss: 4.7900 - val_accuracy: 0.5218\n",
      "Epoch 9/1000\n",
      "15248/15248 [==============================] - 600s 39ms/step - loss: 0.1552 - accuracy: 0.9446 - val_loss: 5.1917 - val_accuracy: 0.5224\n",
      "Epoch 10/1000\n",
      "15248/15248 [==============================] - 598s 39ms/step - loss: 0.1314 - accuracy: 0.9538 - val_loss: 4.2594 - val_accuracy: 0.5453\n",
      "Epoch 11/1000\n",
      "15248/15248 [==============================] - 601s 39ms/step - loss: 0.1663 - accuracy: 0.9392 - val_loss: 4.9746 - val_accuracy: 0.5356\n",
      "Epoch 12/1000\n",
      "15248/15248 [==============================] - 597s 39ms/step - loss: 0.1526 - accuracy: 0.9440 - val_loss: 5.6081 - val_accuracy: 0.5117\n",
      "Epoch 13/1000\n",
      "15248/15248 [==============================] - 597s 39ms/step - loss: 0.1629 - accuracy: 0.9374 - val_loss: 4.9447 - val_accuracy: 0.5216\n",
      "Epoch 14/1000\n",
      "15248/15248 [==============================] - 596s 39ms/step - loss: 0.1309 - accuracy: 0.9536 - val_loss: 3.7640 - val_accuracy: 0.5711\n",
      "Epoch 15/1000\n",
      "15248/15248 [==============================] - 598s 39ms/step - loss: 0.1256 - accuracy: 0.9563 - val_loss: 4.4868 - val_accuracy: 0.5329\n",
      "Epoch 16/1000\n",
      "15248/15248 [==============================] - 601s 39ms/step - loss: 0.1085 - accuracy: 0.9634 - val_loss: 4.4688 - val_accuracy: 0.5356\n",
      "Epoch 17/1000\n",
      "15248/15248 [==============================] - 599s 39ms/step - loss: 0.1136 - accuracy: 0.9615 - val_loss: 4.8848 - val_accuracy: 0.5287\n",
      "Epoch 18/1000\n",
      "15248/15248 [==============================] - 593s 39ms/step - loss: 0.1154 - accuracy: 0.9598 - val_loss: 4.1639 - val_accuracy: 0.5407\n",
      "Epoch 19/1000\n",
      "15248/15248 [==============================] - 601s 39ms/step - loss: 0.1178 - accuracy: 0.9583 - val_loss: 4.0468 - val_accuracy: 0.5372\n",
      "Epoch 20/1000\n",
      "15248/15248 [==============================] - 605s 40ms/step - loss: 0.1264 - accuracy: 0.9544 - val_loss: 2.4999 - val_accuracy: 0.5886\n",
      "Epoch 21/1000\n",
      "15248/15248 [==============================] - 594s 39ms/step - loss: 0.1041 - accuracy: 0.9613 - val_loss: 4.1836 - val_accuracy: 0.5348\n",
      "Epoch 22/1000\n",
      "15248/15248 [==============================] - 596s 39ms/step - loss: 0.1548 - accuracy: 0.9393 - val_loss: 3.5565 - val_accuracy: 0.5561\n",
      "Epoch 23/1000\n",
      "15248/15248 [==============================] - 600s 39ms/step - loss: 0.1019 - accuracy: 0.9648 - val_loss: 5.0855 - val_accuracy: 0.5120\n",
      "Epoch 24/1000\n",
      "15248/15248 [==============================] - 600s 39ms/step - loss: 0.1139 - accuracy: 0.9596 - val_loss: 4.1689 - val_accuracy: 0.5405\n",
      "Epoch 25/1000\n",
      "15248/15248 [==============================] - 598s 39ms/step - loss: 0.1299 - accuracy: 0.9534 - val_loss: 3.8653 - val_accuracy: 0.5488\n",
      "Epoch 26/1000\n",
      "15248/15248 [==============================] - 600s 39ms/step - loss: 0.1164 - accuracy: 0.9604 - val_loss: 3.7699 - val_accuracy: 0.5633\n",
      "Epoch 27/1000\n",
      "15248/15248 [==============================] - 602s 39ms/step - loss: 0.1111 - accuracy: 0.9624 - val_loss: 3.9085 - val_accuracy: 0.5446\n",
      "Epoch 28/1000\n",
      "15248/15248 [==============================] - 596s 39ms/step - loss: 0.1002 - accuracy: 0.9645 - val_loss: 4.7153 - val_accuracy: 0.5197\n",
      "Epoch 29/1000\n",
      "15248/15248 [==============================] - 602s 39ms/step - loss: 0.1079 - accuracy: 0.9630 - val_loss: 4.2177 - val_accuracy: 0.5460\n",
      "Epoch 30/1000\n",
      "15248/15248 [==============================] - 600s 39ms/step - loss: 0.1492 - accuracy: 0.9408 - val_loss: 3.8332 - val_accuracy: 0.5609\n",
      "Epoch 31/1000\n",
      "15248/15248 [==============================] - 597s 39ms/step - loss: 0.1090 - accuracy: 0.9611 - val_loss: 3.3116 - val_accuracy: 0.5795\n",
      "Epoch 32/1000\n",
      "15248/15248 [==============================] - 602s 39ms/step - loss: 0.1143 - accuracy: 0.9609 - val_loss: 4.6997 - val_accuracy: 0.5255\n",
      "Epoch 33/1000\n",
      "15248/15248 [==============================] - 596s 39ms/step - loss: 0.1126 - accuracy: 0.9606 - val_loss: 3.1488 - val_accuracy: 0.5741\n",
      "Epoch 34/1000\n",
      "15248/15248 [==============================] - 598s 39ms/step - loss: 0.1167 - accuracy: 0.9556 - val_loss: 2.5609 - val_accuracy: 0.6028\n",
      "Epoch 35/1000\n",
      "15248/15248 [==============================] - 595s 39ms/step - loss: 0.1251 - accuracy: 0.9526 - val_loss: 4.7051 - val_accuracy: 0.5228\n",
      "Epoch 36/1000\n",
      "15248/15248 [==============================] - 604s 40ms/step - loss: 0.1050 - accuracy: 0.9635 - val_loss: 5.0368 - val_accuracy: 0.5205\n",
      "Epoch 37/1000\n",
      "15248/15248 [==============================] - 603s 40ms/step - loss: 0.1342 - accuracy: 0.9505 - val_loss: 4.2068 - val_accuracy: 0.5494\n",
      "Epoch 38/1000\n",
      "15248/15248 [==============================] - 602s 39ms/step - loss: 0.1209 - accuracy: 0.9559 - val_loss: 4.9531 - val_accuracy: 0.5267\n",
      "Epoch 39/1000\n",
      "15248/15248 [==============================] - 588s 39ms/step - loss: 0.1064 - accuracy: 0.9626 - val_loss: 3.8631 - val_accuracy: 0.5443\n",
      "Epoch 40/1000\n",
      "15248/15248 [==============================] - 604s 40ms/step - loss: 0.0938 - accuracy: 0.9684 - val_loss: 3.6953 - val_accuracy: 0.5577\n",
      "Epoch 41/1000\n",
      "15248/15248 [==============================] - 599s 39ms/step - loss: 0.0964 - accuracy: 0.9674 - val_loss: 3.9845 - val_accuracy: 0.5503\n",
      "Epoch 42/1000\n",
      "15248/15248 [==============================] - 599s 39ms/step - loss: 0.1206 - accuracy: 0.9552 - val_loss: 3.7103 - val_accuracy: 0.5590\n",
      "Epoch 43/1000\n",
      "15248/15248 [==============================] - 597s 39ms/step - loss: 0.1198 - accuracy: 0.9559 - val_loss: 4.2166 - val_accuracy: 0.5438\n",
      "Epoch 44/1000\n",
      "15248/15248 [==============================] - 599s 39ms/step - loss: 0.1134 - accuracy: 0.9573 - val_loss: 4.1097 - val_accuracy: 0.5458\n",
      "Epoch 45/1000\n",
      "15248/15248 [==============================] - 596s 39ms/step - loss: 0.1128 - accuracy: 0.9566 - val_loss: 3.5552 - val_accuracy: 0.5742\n",
      "Epoch 46/1000\n",
      "15248/15248 [==============================] - 592s 39ms/step - loss: 0.1249 - accuracy: 0.9525 - val_loss: 4.3704 - val_accuracy: 0.5455\n",
      "Epoch 47/1000\n",
      "  916/15248 [>.............................] - ETA: 8:31 - loss: 0.0989 - accuracy: 0.9642"
     ]
    }
   ],
   "source": [
    "#황성현 전민재\n",
    "from datetime import datetime\n",
    "K = keras.backend\n",
    "epochs=1000\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2SL_adam_best_lrsch_onecycle_aug_epoch40%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "onecycle = OneCycleScheduler(train_size // batch_size * epochs, max_rate=0.003)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"SMV2SL_adam_best_lrsch_onecycle_aug_epoch40.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"SMV2SL_adam_last_lrsch_onecycle_aug_epoch40.h5\",save_best_only=False)\n",
    "\n",
    "history=smv2_SL.fit(train_set, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=epochs,callbacks=[ check_last_cb,check_best_cb,onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbc5e41",
   "metadata": {},
   "source": [
    "train logs in SMV2SL.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fba70b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 38s 7ms/step - loss: 0.3275 - accuracy: 0.8801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32748278975486755, 0.8801146149635315]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"SMV2SL_adam_best_lrsch_onecycle_aug_epoch40.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block2})\n",
    "smv2_l.evaluate(X_valid_final,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f084e22e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f4d542",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #황성현 전민재 IRB61024, maxlr 0.003\n",
    "    #multygpu\n",
    "\n",
    "\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=2,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=4,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=4,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=4,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=4,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "    batch_size=32\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfeb36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 전민재\n",
    "from datetime import datetime\n",
    "K = keras.backend\n",
    "epochs=40                                 \n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_lrsch_onecycle001_dropout_128_he_irb6_1024_epoch40%Y%m%d-%H%M%S\")\n",
    "onecycle = OneCycleScheduler(len(X_train_resize) // batch_size * epochs, max_rate=0.001,start_rate=0.0003)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2sl_adam_lrsch_onecycle_batch32_lr0.001_epoch40.h5\",save_best_only=True)\n",
    "\n",
    "history=smv2_l.fit(X_train,y_train,\n",
    "                   validation_data=(X_valid_final,y_valid),batch_size = batch_size, \n",
    "                   epochs=epochs,callbacks=[tboard_callback, check_best_cb,onecycle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "176a6178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 40s 8ms/step - loss: 0.3219 - accuracy: 0.8802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32189807295799255, 0.8801512122154236]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2sl_adam_lrsch_onecycle_batch32_lr0.001_epoch40.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block2})\n",
    "smv2_l.evaluate(X_valid_final,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee96116",
   "metadata": {},
   "source": [
    "smv2sl_adam_lrsch_onecycle_batch32_lr0.001_epoch40 is best model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1171dc8",
   "metadata": {},
   "source": [
    "# lerning curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d06c765",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24269347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-64c013d611cbb496\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-64c013d611cbb496\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/SMV2L_lrsch_onecycle001_dropout_128_he_irb6_1024_epoch40"
   ]
  },
  {
   "attachments": {
    "6a03aaca-b747-4a66-956c-bf061f7c2def.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAADvCAYAAABLwefzAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAFOXSURBVHhe7Z0JeFTl1cdPdrKSAAGSEEACKAEEBFdQAorQCopbQVSwCi5FRfvVbl+tS9sPrFZosRUXEEQFBBWFCogtKJsoIDvIEmLCEhKy7/t3/+feN7kZZiaTZLYk5/c888zc2e7MnZn/nP31qdEgD7Jy5Uo6deoU/frXvzauEQRBaDn4GueCIAhCE6gV0ZycHPrTn/5E/fr1oyFDhtCiRYuovLycb4O1+PTTT9fePnz4cFqzZg1VV1fz7VVVVfTxxx/TjTfeSH379qVp06bRwYMH+TZQWlpKCxYsoKuvvppv/8UvfkFnzpwxbiXKy8ujOXPm8H5xwv7wnPYw77NXr1507733OrxPe4/FcXjwwQfpxIkTvA3wep566ikqKSmpPRawnO+66y6+P5531qxZtccO+8X+FXhuHBO8Dhw77LuyspJefvll+stf/lL7XtPT0+mOO+6gPXv28LYgCN4PiyjEYfbs2RQSEkLff/89rV+/nr777jv69NNP+U5g//79NG7cONq7dy89++yz9Ne//pX27dvHt+F+K1asoIULF9KRI0fonnvuod/+9rd08uRJQrRg8eLFfP1nn33GgnLttdfy/oqLi/nxX3/9NYvdN998Q3PnzqW3336bXXx7fPnll/TRRx/RkiVLWPBuu+02FqX8/PwG97lhwwZ+vW+99RYdP36cpk6dyn8Q58+fN57dPrt27aLRo0fz4319femPf/wjPz/28/nnn9NXX31FmzZt4vumpqby8cIxwet5//33ed/btm1jEcfxvHDhAt8Xt0dHR9Oll17K24IgeD8sosnJyfTjjz+yRdauXTvq0qUL/exnP6OdO3dSWVkZ33Hs2LF05ZVXUlBQEF/+6U9/ykIB0Vq9ejU9+uij1LNnT/Lz86MxY8bwfSFWsDI3b95MU6ZM4ecNDAykiRMnsugUFBTwc+O5kpKS+LkHDRpEoaGhlJWVxbfZYsSIEfTmm29St27dWMiuuOIKfi0ZGRl294nn/e9//8tWJKxQvN5Ro0bxdlFRkfHs9sHrxTGIioqisLAw+tvf/kZ33303P1dMTAxbowcOHOD77t69m3r06EEjR47k23GMfvnLX7KlCrHs0KEDHT58mK3R7du30/XXX8/vXxCElgGLaGFhIVue1113HQsLTg899BC7nMplN+Pj40O9e/fm2/Hj9/f3p/j4eONWYrHA7XheWIWwcDt27GjcShQeHs6CDYEDuD+eszHgeWGxwoLF67355ptrLTp7++zUqRO/7u7duxu3EIssRBDP4wjm1wsBhyUMaxbuOp4D7rwC+4qNjaXg4GDjGuLXDBGGWEI0YYnDCoaYDhs2zLiXIAgtARZRWID4YcNNhVWqTvPmzav341dApCAcsMIgKBCKtLQ041Y95qhuh9jAhTZblrDCEPeDyDaVd999l4UH1i5e6xdffMECCeztE9dD9OFmK/B6EZrIzs7mbfxx4D06wunTpzmeO3PmTHbH8VpglSuwr7Nnz3LIRAGr/9ixY3z5mmuu4cchhNK5c2e2WgVBaDmwiCYkJFBkZCTH6+BiQ1QgSnDTlSW6Y8cO+uGHH/g2uKiI6cE9joiIYFcZ1ldKSgrfvnHjRrZsYW21b9+eXfUPPviARQ/JKiRnkLiCFddUVOIGYgfxg/uOJA+wt0/8KSCeuWrVKhY8vF7EV//v//6PKioq2CrFn8q3337LoQzcB0k0W+APBI8DuD/ceLx3xdChQ1k0ESfFvnCMkJQ6d+4c3w6LGMKJWDBel7U/LUEQvBdWMbi6SKwglnjDDTfQgAEDaN26dSySSujgrkMocRsy0Y899hgNHjyYb0NSZ9KkSewuI0O9bNkyts4gzrAKH3jgAb7+1ltv5ZgnxBjJFrjcTQXZbsQwYUHDFYeFCfGEkDW0T4g7Xu+MGTP4Pp988gmLKMILcLFx/Xvvvce34TFdu3Y19noxiHE+/PDD9Mwzz7BgQqgR64TlCdGESOLY4pjg+XDcfv7zn7MbDyDaEHzEUtXxFASh5eBQsT2sOE8UxKMCwBxfVMBdbk3F+bBSERf9/e9/z+ERQRBaDl4toq0dWKtIhr300ktsTSODLwhCy6LpQUmh2SCZhKoClGehZEsQhJaHx3vnBUEQWjJiiQqCIDQDEVFBEIRm0GpEFEkalCOZB4cIgiC4GhZRCBCmFKFXXhAEQXAccecFQRCagS9aJdFphJFxGNeGmlB02qAFFLMvMVQDHUqqDx3n2Mb1eJx6DDqFUEeKXnZL0JOPziHLuZ4opscEpJ/85CfczfPqq6/WtnNiP5jbievN80tRTIDCdDzG8rXhNozHw/0xSQlj8vBebIGxf+hcwtAQPB9eJ8BjMPMTz4P9qxF69vaN96IsebNlj/DCk08+ySe8H9z/73//O78+83MDHBccHzy3ej247fHHH699bkyqQtfT0aNHeVsQBM/ii3FuEEyIHFoTUfQNEbjsssu4Bx4/VrRWKkFCBxF6vTE7E2KAnnuAfvPnnnuO+7/NYNDH0qVL6V//+hc/F54frZGq3xzPiXmkW7Zs4T51dO+g1x3DT7Bf7AfzN9HrjnmjGHTy+uuvc685ng9C98Ybb/DzYKAJWjcxog9iiv5/DP+wBu6P4SDYD/YLMcfz5Obm8jASvCbsE5fx3iCq9vZtD/TJP/LII/wngZZUtNZCFPHc6FDCHw/e82uvvcYtoHhu7AP7wiwDFOFDvCHieA3orzdPoRIEwXNYdefxI8XQjAkTJvBIuz/84Q88aAO96rCWcD16vjE16ZJLLjEeRdx3HhAQYGzpYDAzrEgIB54LI/Yw4FnN7sTj1XPdcsstLCwYGoIp75hLCpHBzNDx48eziB46dIguv/xy7k9HX/+dd97JVh4uYwYAitbxfPhzgPipeaiWqHF2GB4Nyw/PDysRQoX9wBJEPzue64knnqDbb7/d7r7tgT8kWLvYH3r3IaDoncf1+FPCscV7RvcSBjXj+bAP/EnhuODPBNOiMNsAg1FQnN+cuQOCIDgPq79+THvHABJYn7DS0JYIIDwY2twY4J5jWAieE8+FE9x/ZcE2lsbu3xZwkzGPFMNAYPnBalWvydYkJWfsW7n4aoSfGpuHPx9YxtaAmGO4Cv5g8FoxPk8QBO+gnogqtxTCBysOlh3EBj9cAOsHk5lgWcL9hOVkXsYD1qVy0xX9+/fnJTAwHg5WHiwuuOi4DPB49Vz//ve/eeISXHJMTkI4Aa8J7vDatWtZPLB/WLKYyoQYKZbjeOWVV9iaawy4P6xUTJYHEDYVm8RrwJ8I9ovXhmVPEPKwt2/MTsVtuB7vRcV9LcE+cFxxLM3HD68DIv6f//yHnwMCi5grXgMEFtP3MUMVlnFcXBw/RhAEz8MiCssLsTi42hgLN3DgQHYZIVpwWeGGIlYIsZg8eTK7+mokHq4HEKQXXniBY5pmMELvd7/7HY+agwhhaQyA5wQQJAgE3Fu4vIj/QShUYgb7wdIdOOH14PmQWEGSBu4wZoHC3bYMIzQE5qDi/eI9YIQd9gVLEHFViCjG+2GfuIzk23333Wd33whFYKYprn/++edZKK2hlglRxw/3y8zM5PeMBJJ6DlzGvhDKAImJiSy6CCfIzFFB8B4a3TsPKwkCiBMeirmhmIOJGGJjQUYbMVEkm1wFBBBiCWvYDJJoiDW2FGDB4lhPnz5dkkqC4EXYz4hYAaVQyJbDzYYViUSHObnkbSDBhMy6iseqU0sSUIBwAyxYewOiBUFwP40W0Ztuuokz7nBHsa4QLCNkkgXXAYsdFRJYvRRuvyAI3oOMwhMEQWgGjbZEBUEQhDpERAVBEJqBiKggCEIzEBEVBEFoBiKigiAIzUBEVBAEoRmIiAqCIDQDEVFBEIRmICIqCILQDNpMxxLeJsbKmcHEJky+xzId7gKj9TBmD1OZ+vTpY1zrejBlC4OdMUnLnWBCFYiOjuZzd4HWZEzAwkhHdyHH2PV48hij1d0abbrtEwKqxsu5C8xqxVxQDEDBmD13gf1ihKG75xxgfizAjFh3guE4WMbGWUO8HUGOsetx6TGurNB2UEQUdvHAeBxjW8dX3HlBEIT8LE0pU4lyMjRzt8S40jFERAVBaLtAMM+dIsrTRLS6iig4jMjP+jI9thARFQSh7QHX/cJZoow0/XJFGdHR74i+eI9oxd/08wvWl/ixRERUEIS2BQQTrntJoaaAfkTlpURL/kT0+TtE331BtOtLonWLiWY/SHRsj/Eg24iICoLQdoBwZpzWXfegEKIu3Ym++ZwoP9u4gwncZ8NSY8M2IqKCILQNivJ1Fx7iGBpB1LkbkX8A0cn9xh2skHxAd/ftICIqCELrB9n37HT9cvuORB1Ma5U1lI0vt3+7iKggCK2b7PN69h1APCM0ETUTYKdZICCQKESzWu0gIioIQuukulp334vyNKXzI+oUq7vxCsRHFz2nCewF4worDLrBuGAbEVFBEFofnIH/sS4Dj/gnakAVB7YR/ek+/bxdKFHP/sYNJnoPJpr4mLFhG4+LaHFxMS1fvpzmzZtH27dv1/48tH8PC9CZunv3bpo/fz4tXLiQ0tON2IYG1r/fvHkzP/7999+n/Px84xZBENokSCAhA4+EUKDmqiMDb3bZV7+uW6AQ2ITLiZ55g2jW34l+/RbRA38kmvoHol/+k2jmK5rl2t54kG08KqIYxrFkyRIaOXIkzZo1iyorK2njxo3GrXVs2bKFkpOTeZ37SZMmce+56hdetWoV+fr68uNHjx5NCxYsYGEWBKENkpupJ5BUBr5LDz0DDyCa//wfoq8+0rdhZT7+al2SKeYS3X0fkkQU73hvvkdF9MyZMzx5JiYmhnx8fGjo0KGUmprKk1rMYFoMBBJiGRYWRiNGjKCUlBQqKSmhoqIiGjZsGD8ez4OJTBgsIghCGwIeLNz3ghx9G8JozsCf2Ke77ziH+/4rzfoceadxY/PwqIhmZWVRp06djC3txWgimZeXx+JoJjY2lie3ADXSDoKJ6TEYw4VJTACuPS6bn1MQhFYO4p/ofy/XzmF1dtWsT3MCacO7ugWq3Pc/vk8UZ32U3snsEjp+oZgqqx0fbudREYXoBQcHG1s6iIlaTueDFbpjxw522adPn84jqbp3787W5+23306vv/46/eY3v6GHHnqIrdTIyItHWQmC0ApB/DNdM7BqO5A0AVXxT7j1EM/1moiCsVN19z04jHJLK+lcfhml5ZXSMU00n/jsBwp/bhP1/us26vvKdgp59r/0pHadI3h0nujOnTv5HLM1ASxQJI9mzJhBUVFRfB1Ys2YNbw8fPpwqKipo6dKllJSURD179uT46LXXXkuXXXYZD1letGgR3XvvvdSxY/1aMLzNPXsu7oNF+KBXr17GluvB68friI+PZwvbXSD+jDgy9utOcnJ098r8ebqDtLQ0/rMNDAw0rnE9coxdj/kYBxZmk1+Znv+obBdGFaF1xlOnw1uo694N5FdeQlWB7Shl9IN0rmMvKiiv1k41VGVSvQ2pZbTkiPU8yrR+IfT04FA+xtAca3hURA8dOsQJowkTJvA2RHTZsmU0efJkCgnR/lWM61asWMEJJWW1Hj9+nAfCQlQ/++wzmjZtGl8PkOH38/OrFWZ7yFBm16MSgDIw2HW0uWOccooujdL0Ae47ypcio+vcd1ify17WY58a5f2H09lbnqRcCqQqk4seHOBHke38yd/Xh366eC/tPm29qic6NJAynr2Bj7Gt4+tRdz4uLo5H/ePfBWAEv7+/fz0XH9tINJmTTQUFBfzvB7GEyKrHA8RU3blcgSAIbqK6mnyKCygo+2ydgKL+Uwno1x8TvfJobfKoeOoLdPiWX1FWdQALaKCfL8W3b0cDu4ZRYudQio0Ios5hgZScZbutM7OonHJKvLh3HrHLIUOG0OzZs7lUCTWg48aN41jnwYMHeTsgIIDGjBlDc+fOpbVr17K7vnXrVo59RkREcGZ+zpw5vG7Ra6+9xsmqgQMHGnsQBKHFg4QQWjfPnSKfnPPkg0w86j9RkoT4p4p9fvIv/b4DrqOqP7xHx7pezuIZ2S6A+mmiCfGEaEJMc0sqacnuc3T70n0NimSAr32Z9Io1lpBMQqywIQsS1igsU1iglqA2FG4FMvyOIu686xF33vW0ymOMoSBIGkEUkTQyKKvxobTsPOo9eJh+G6xPlThC6dKUX1NV/+s4WVRcUcVu+6WdQshPc9tBSk4J/X1bGi3efZaFtCH6dwmlg09f673uvALC54gLjvtYE1CAGGpjBFQQBC8EXUawOjFxHj3vEFBYnYh7apZnTed4qgoO19s14borAb3yZi5dsiWgEM+frzxMl7y0jeZtTWUBHdkrit65O5FW3WfbiHp6RA/jkm1EdQRB8Dxw0TGuDvWeamAIRtbBZUfZUngU14D6nkum+M/m6W2bcONjE4hm/o0tUJQupeSUsoDCZYeAooRJiSesTzBtaAyd+s1w2vzwUHpgaCzdOaAzbdIu3zOoK8dKL4sOpYmJ0fTx/ZfTQ1c2XEHjFe68pxB33vWIO+96WvwxLsytWygOIFGEcXWaaEIQqzR9rTp5gEq+/FDzxw/r9wkKoeDx08hv2E0U5O/DogkBzSouJz8fH+oSFkS/33CiVjgBxPP5m3pRz6j6temO4PXuvCAIbQy47bA8z5zUlylWxfLoNurQlVIKqmj3mXw6suk/dGzu/9LJt1+hsympdDYomo4kjqWzM+bSyZ7Xaq57ER1IL+T7KgFddSCDEuduv8jyXHx3/yYJaEOIiAqC4FTsJmyQMDIy7bXWJ2KemPWJcqWAIMooLKes774mevtZCl6/iMIzkik8yI9ikn5CHWf+iQKGjqSYTpGcdQ8P8mfhBGuPXKDb3t1Pf9l0qjbm6UrxVIiICoLgNOB+n8wuvlhIkUmHcKqEEYDb3jlej3kasz6zdm2ltL89wwmjnnnJlBjpR30nP0R9Zy+h2Fvvpa6aeHYO8aOQAD86nVdKy/am09Nrj9FNb++h579MptTcEhoUE84xTsQ8XSmeChFRQRCcxo85pXyeookZdwghYYTp8jjBhceAECSM4nrrU5aCDJE7sY+y5v+WUj5YwBZqz/aB1HHy4/qwkKvG8l2QYX9mfTLduPIcRb2wmZLe3M3CuTk5h0W7fTt/zrbvnXU1JWlWqLsQERUEwSmczS9jSxRAQHMyM3XrE1aoas9Eth1JI1WOiAz7ouco619/oJRTp1lUe/70Dur43KJa8fz0cCYXxSPD/to3Z+lMoW7lwl1/7qZe9Mn9g9htz30+ibPt7kZEVBAEJqu4QrcemwDE81yB3pqdEO5Hl9bkUKfyXD3mCVcd0+VRpqRQPe5/uo+KD+yklCDNKr32Fur81EvU8aY72LL8+7ZUFs6J7+6j1Yc0Qda4b3Bn+uS2rlQz5yZ215Ftn9g/2i1uuy1ERAVBoIKyKnaXD5wv5FKhctQVNQLlxvcJKKXIvDMUVlNG5T5+9KN/B6rqEKO78QBWKeZ7YkDytxuomPzp2IBbiGb8WRPPiRTfpQO750P+sZOeWnOMX1OPqHY0d3xfynkuid6a2Jf6dTCey0sQERWEFkJTrURHUFYk9oFSIZQNOSqmcOMxGLl/TRZFlGnWJ9CszlMBnelCdSCdxXObxdPoMsq64qd0ZMbrVDVuGnWMiuBsOwrjR725m8UTCSK46im/GUFPjehOkcH+/DhvQ0RUEFoIEDW75UNNBFZoQVkllwphUEfHEN3SM4upinVaApH1LcimftUXqF2NkThCxj0ymuI76OMsM/Z+RwUvP6GLJ8Q04XI699i/KGX0dE4yYX97zxbSJX/dyrWdSBAh1okEEVx1b6fNdCzhbWJZETMY4oyuJazL5C4wtg8TpxITE6lPnz7Gta4Hw1swdjAhwfqyCK4C4w0B1tJyJ1iXq1u3bm4di4hjjHXDXDXk+1Cm7jL3igqkYP86+6e5x/hkThkVlVdTl7AA6hKqW3vlVTV0vqiCckrqxDM00JeiQ/wpIkifX3Hq2FGKCQmkcH+9TrM6JIKqwqJqk0Z+eZlUtGYJXThzDtM8qV90MBXcNJVORibUPm9hRTW9tecCrTupz/O8tlso/WNsN4qPsD7o2dXH2BY4xgMGDDC26iOWqCA4EVfZJBA1uNo4JeeUU0ll42KWtijUxBMC6uvrQ52C64b7BPr5sJBd1qkdddKEE7fjfim55ZSWmU9VF9IpJD+TgqorOPZZHtWVqkxZ99CtH1PHd35PPU5/T8GB/pR71QQ6cPeLdDCsFx25UEqrj+XSz9ek0h0rk1lAIcwvjoyhT+7uZVNAFd5m90nvvPTOuxTpnXcOyJwjTgiXu0r7yWIyEYZloGe8OccYE4/gyseEB/GQYltAvItyc6hdcS4F1ughBbxX39gEiujajdprFilzYh+Vv/cSBeZl8Ob5fkm0/5qplFLqx7HTNUcucIumAq47ypKQZXck5unJ77H0zgtCCwZCByB0GPEGUTuZZRS0NxFzLLRLmA3rz5iu5HcumSKKLrCAVvv5U5Z/BO317UIF7TroAmrUe2I4MgR0n09nGhUwhbomX0M3f3CMHv74CBfGKwFFPzuSRqjtnDehr9cmjRxBRFQQWgAlFbr7rmZk4hzJHliSTRVSlZHHtHc1tLge6HPHWu6qxx0DQjp01azPXtQxpislRAVSz3aauKus+4FtlEdB9LT/jTTrsv+hmt6DuCAepxsuiaKb+3SkhXclcqkS+tlbQtLIEUREBcHLgUiq7DgGcUDwzEJ6Mre80UKqrFCEAy6yQmF95mbqfe5o1cSAEGTczesZaUT9uJ+CX5tVW7K0xG8g9Qx6jAZNnsaF8ObTV48MpQ0PDaEHh8W2aKvTGiKiguBBHBG/YsMKxcQiBYS0d8dgdsVLtdvPFmpi1wgwvAMgPFDPCq3QrNNMTTwL9GWYuc8dA0JUjzvAQnCa2x634U1e86ikc0+aEHY/PeB/C00b3tcjrZeeRERUEDyEcscbQsVDwwLrL40DK7JvtF6LaS5FaggkqbBvPF7VhNZOlk/X3HespAnrE7M9kXFXmOKeENLqwGBKvWEaxZbfR2sr4jjOifhmW0NEVBA8ANxptRaQctVtUViu347xb5ao61Bv6SjcYaRRm43HgnBqvidQ1idW0gQokDf63HltIywIN3YqbZ34HA3aF88NABBQxDnbIiKiguBmYAliIrty5bFtD2WJIh5qZu/ZAh7S8dg6vd7SESDe6DJiK9RHE1OIJyxMlThC7NNsfWI1TaPPnTEWhEu5+m56dEsR5ZZWcntmWxVQICIqCE4C4lTVQIjznGYFot4ToFcc2GvlVFYqRA+xSwgnhhBjupEa0nEyp5zv05BFqwivKaeEKs3qNM/4VJPlTfM96ZVH6q3lTs++xwvC7c2p4X0fya6gy7uGcuKoLSMiKghOIqOogo5ml3P9JqxLy+Ed6EHnYRwaGN2W0DGYxRH3syWAhZrlCGCFQrhwwpK/EGIUqsON7hqmJ5wgsHapKKOQ3LPUtyabQqq114EZnxiMjBmfxmR5FszVr+txT6x/FNVFX03zoRf5vuhtx2uA8F/ZNYi+eGBgq8u2NxYRUUFwEkrwckv17iIM7ziSUcTWJ+KfaiG1hA4htQkdJUC2XHq43+D360+ySEI4Zw3vXluoDje6a5hh0WqutVXUWu7pP5JfeQlVaT97FMuzeJpKlui7L3TX/auP9O2xU4meeYOot95ZhwlLOAG8hqU/6cyvp63jcREtLi6m5cuX07x582j79u1UjSyhBehM3b17N82fP58WLlxI6enpfD1asV5//XV+rPmUnOxYfEgQGsJRFxnxTVUQDysTrjoEE4+H9ak6g5BNV8IJa257ir7ekC2XHo9Hq+SyfeksWHCdkQE3F6qHG1n71Fy9bKkW/JbUonDGukbloVF0wDeasgI08VTT5WFxwvL84K+1U5bYdR+niahmoeK1wfpUE5awBEdbzMLbwqMiiolGS5YsoZEjR9KsWbOosrKSNm7caNxax5YtW1gYZ86cSZMmTeLec9XL+thjj9FTTz3FJzwH+qX9/eXfUbBOY4vS1bDhhlAWY4i/XjYEV31wbHit1QlRTewSWptNx6R2jH6bvOwALfrurFWXHtcd1KzZF77UjQIIF57Tkr4d9Cx6PRGFGJrEky1OzfIsDo7SLFEfFvTarDtin4iBIut+zzNEj7+qu/kasKjxOmEFYzgyRLyt1YE2hEdFFCOtML4rJiaGfLQPdejQoZSamsrjrsxgrNno0aO1P05fCgsLoxEjRlBKSopxax0ZGRlUVFREcXFxxjWCUB8Vk3QEiBpOlrFNaxSU65ZkaED99klYneb4J6w6JIawZpCyPv/1zWn61b+P06ns+oJ9OreMHvnkCF+G+9yQeOWiVlRZn0gaqaU54LZDFP0DaoU6eLtF1h2uu2lROAVeK14nMvB7n7zGqoi3dTwqollZWdSpUydjC96FL+Xl5VFJiZ69VMTGxhImtwC49pgLCuG1ZP/+/TRs2DDy86tfCiIIAFaoKjR3BBWntOVqm1Hx0NAA2z8pWHMqMQSw5AVimxFw05Nz6K739tdLDt367j62cK/t0d6u+3x1nGZBavxwNlvvdYf1qZJGyLqrpTlAymFez502rayfdTdcdzOwlnFSYYS2nkCyhUdFtKqqioKD6y8whZio5XQ+WKE7duxgd3369Onsxnfv3t24VSc3N5dOnDjh9mGtQssBiRclpI5QlyiyL6J4TiXMlpaoAi45BBTuMay675+8mpe8QGxz36yrqW+nUDqaWURJb+1m4ULp0qHzhdyl9OEU+6MaUfoUU1NICZWZdb3uWBjOnDRS3UaLX9CL6ttH18u6W6IsZuDomLq2ikfnie7cuZPPMVsTwAJF8mjGjBkUFVW3MuCaNWt4e/jw4VRRUUFLly6lpKSkelPat23bxoJ8xRVXGNfUB29zz549xlYdCB+4U3jx+vE64uPj2cJ2F4g/I46M/bqTnBy9B9v8ebqDtLQ0/rMNDKwbrpFWWKW53TUUqJkOvSPti0KFJozHc+ss1kuj/MnPuj7yc+K5A6mSgooy6x3jXRkV9MdvCuhskf5cjw4IoUcH6pajmeO5lTR/XxF9fVav+VTMvi6CftLD6Byygm9FGaWnptHvdpZQiL8PLRjfnSpCTOKp0WXvFxR9+GvOzJ8O7EhHel1PPoOGU3SwbRtqwYEiWnCwmPpqx+nDn1j/7KwdY1fjye8xNMcaHhXRQ4cOccJowoQJvA0RXbZsGU2ePJlCQvSeYFy3YsUKTigpq/X48eM8dHf8+PG8jQz/4sWL6YEHHqh9nCPIUGbXgy88sDXQ1lVYDmVGXBMlRwqsJWStjVKRUVhOacaQDoC4Zm2fuQVoo8RYuQ6alpRnn+NjDIsT5UBw0wGSMihHSuplXZBg+Z3MLqYP95+nv36lh66wztCUwV01K9XKdxpj6tDrXlpM2dnZlPTBKUrxaU/5c35q3EEDySIkjmCFAs11PzvmYTrnF2F3CDMnk17axpc3aW68rdfc2gZf20Mlsq3hUXceCSCs+4N/F4B1TJBZN7v42EaiyZxsKigoqPfvd/ToUbZKGyOgQtvCMq7ZUJxTZdsxbg6o1ktr1PW2+1J+eXVtRxEEFPFEiCFWrLQlRgDuMjLmP7u8C61/cAhNvzKOJvTrpO3f4icK8cw8rY+p0wQUsc/8wAjKCutC2q+CBbBewTwE1FQwX9Vez0H4myc3WWCuBbX3mgUdj4poZGQkDRkyhGbPnk2rVq3iGtBx48Zxpv7gwYO8HRAQQGPGjKG5c+fS2rVradGiRbR161bO0AMIMGpIVUhAEKyh4qDKmsyzE+dEjBMF86CnZkECe3FRJbCrj2TRTSvP1SaO0E0E8URM0RFU3BGlUM+M7MGXwwONsANinRbiyYNCYi6h/KD21ClUtyoLd39dVzBvDArhrLtRMG8e7mwN1IIq8Xf0dbd1POrOK5BMQqywoZUZYY3CMnVW9l3ceddjy51Ha2Sgvw/Fam5lvXmWDaAncXQhgIteXllNYUH+Fw3nMLuaypWHpYcSHWTAsU7RwK5hXHZkiXKtITRYx+hwRpEmPlVc82mZYIHFimEiqCd9aNVhFltMcp833npNpz3UfvGa8PrwXgd3DSW/oty6CUsQz/BIItOqmifTztG9Hx6hB86to0ervufruGB+yq8vShqpNZWQyLI8Ztg/akJxjoL6hkqqxJ3X8aglqkBpkyNL2+I+Ur7U8uH10zVLD3HHA+cL7WbLISRom4QIYn2evecKWLRwguuKuk92Ye1wXtsP8NVEFFly5X5DLKyhrNB0bb9wy9OMInZVC2oGgnQss5h+bgjoxN76QI6m1FMqlx6ij/fdxaeU/DI0q1YJqFEwz1OWVLeRRvDh7fTq+fdpdPWPVOofTDTxsXoF846CNZBwTPAnIAX1juMVIiq0fGDhQBQbAska1UOOSe0QC4igmq2pqBVPTWQhlKrgXT0Op/MF5bTywHl+vL19QxggdPd/eJCFYvzivbxtS7whhmi1vPHtPfzck5Yd4G1roouk0vP/SaZ87TETLutIc67vYNzSNCCkIaRZijXZ1K1Ks0DhxmNEHQYkQxRN4snxzn/+D4WvX0hBlWX0rW8sLbjhj0Qj7zTu4Dh4nxirBxZrVqjgOCKiglOARQaBhBhCAK0B0VJih2w3ss44hzDi8RjWgeeAparEE88FwYT7ibrNTw9n0iMfH6Gr//kt3aKJ4Uubf6Rbl+yjX/77GGUVXSyKcLc/OphBj6w+QvvPFXKsD/HQKcsP0or95y96rRDy13ecrm21RE1nniae2J6zOeWiQv17VxxkQb5cu99bE/sY1zadzpr12bc6m8fV1fhoP08IJ0bUqQHJAIkjtTjciX1Uo4ns3v630P3+42lzTtPKjVCbChDHxWciOI6IqNBsVCYbQAwhgObrAARUud34karYIhI9iE1ixUkAkYWlCnHzJR/adbqAfrPuOEU8t4mS3tzNliQSH7AKUTYE1xO8/3069Xp5Gy3ZfY63AcTyQc3NhgAWlFbVJnqQdQa4/v4Vh/iyApnpN789w5cRF9w762o+Bx/sTeeuImWR3rf8EAsoYotfaS48BLpZ5GZSSEEm+VE1ZfkEU2m0Zn2aC+YBJsu/8mjt4nB0wx10YfpLlNNjMG821BhQVqlb9EH+9ePQS/box21iYmc+FxxHRFRoNki6AAzZUC46YpZwx0GJ9sNVNZfx7dtdVG+JxBKuR+0m0pybT+bSi5qLfMX8nfToJ0dqrSRYhWoM3KnfDGdBRPxx22PD6Iq4CHapH1h5iDuDVp8oorGLD9Aqzd1H189bd/bjOk2IN1oo5992KV+P6UiqkwjnqNPE9WseGFwbF8T5148M4+vX/ZBFo97azb3v7+89x9etvPfyixJOjQL97uh1NxaHu9CuA6X5RlJwkOk4wfpExxFOcONjE4h+9QbR7b9gS7RLqL7/hgamqLCIOaGG967G7LWWZYzdiYio4FAs0x7K6oSQwEVHITeAO34yp4ySc3TLEuKpLE4FfrywHmEB9n/1G7rytW/pV58fo88OX+Dbb0uMZksQa5XDKlRj4Mwu53U9Iumj+wbSKz/tS3Htg/g5f7slm/alF/HrWfKz/lx3aeaxq7vRm3f0YxHE/ZFAwnlMRCC9fWcijb+sbqYDuK5He/rgngH8fLifEva/je9LV8e358tNQq2uCZFE5r1zPPmHRVKI9rpqgfUJ112tb4TEEeZ8xukde2GBvtQ1VBdcZe03BvVeRECbhohoGweJEViJykJpCiprrUpm0AmDGCZinUXleqYZAqqED+4wRDPqhc1s/cF6RH2iEgCzcK6eOogtwYYsPewzKSGS3ps0gH43qieFa8JyW7+O9IYmlCN6Rhr3qgPW79BuEWxx9u+iD97A+QeTB9Iw7XpLcP/EzmH8fJMH6aUuL4zpRUPjwjXBa+LPCMKZcVozDzUhVf3uQXqoIxKhAbP1icsYFoKazwYSR9YSYPYQV755iIi2YRCnRLsiaOwPT4FEC0QS7qHZRYSgItYZqglMuwBfdtcBrDi4wxBNFdeEaGKiEYZy1My5yWHhNIN9wwLGfvHYL+6Kod9cH8/bluEDBYQKt699YBCL9lLNYsW2rf3iNpz+fHNvWn7PQLpFs1Yt37dDKPddjatD3DM6vt60pc6nvqtvfWLOJ4aFWExaMoOQBkAZmKOIK998RETbKOZED7BMBDmKeQ0gS2C9JUQFUUJkIF+GcEJA8aNFfFPFNSGamGjU3FmVXcK0/RiZ/rxS3bLmCfPavq2hxBLJGAhvNemZerYCraDuD8t7VIKe0LL2vu0CixLDkpX7HqkJl7l0ydL6RNE8XHeLOZ/OQlz55iMi2gaBBagEVFmIKDCHRdlYlPgioWQLiBj6yeHCY9/IkiMh5OxSGuwnPlJ/P0VGFtqeNQsLEl1JeN/qeGDbluia76+GO9t73/WwtD5R+wn3PdzUm45lOpB5N8c+G1E0f6kxqEQNPbFEhWzMLZ/iyjcfEdE2BtzvlFxdMFSiR/2ommKNWsZDLcnTnhNroqt+crjNKkvuCvCelHsNMbTlyis6Gberwnu1bQv1PtUfjkOWqDXrE7Wf5mHJWN8dy3SozDusz0YWzTf0Wsoq9desho+IK+8cRETbEKXaj0gVw5sTPUo4VLujo6j2RFtxQWTdr1r4A20/XcQ/VMQ84Ta7GvW+2rdrWODCLITHctsSsyjbet+1OGJ9QlgxbQnru4Mb7tAFtJEtm4g9xxij7cxhGnuIK+8cvGIAiTvA28SyImYKCwt5CEm/fv2Ma1wPpk6tW7eOEhMTqU+f5ne4OEpeUSnt+CGNYuO6UVSwH8VH1JUaoY7zeFYZW279ox0fJpFTWkVpeeUUoQlPz8i654NoztpwmtLy9dKpYV0C6f07e1N7R6w2J7Fp3wkalBBHHcIaDhkcuVBKFVU1FODnQ/06Nfz+D2aWavpYc9FxxIAcrBuGId++xfnkW5hDPpqQovOoOiySqkPrl0IFph6hyI9fJZ/SYq71zLvlESrrO8y41XEwQjIlv5KOFgfRM1+eoWu7hdInd188gamwvJqSc8pYcBGrvum94/xe3rm1B/0k4eKKhIbA2mfdunVzaO6FszAfY3eCYzxgwABjqz5iibYBYC2mFVQQPFD8gMw/fBDs78sCgvtBUB1FDfJAnSKAaMJ1xwmXu0UE0N9HRtI7Yzq4VUBBl2Afu+sdmVGvzdHX2D5If17UmF5EVSX5ZZ8jv/wsFtBqTRwro+PrCShEM/w/Synqgz/z5fLu/Sjzsb83SUDNhBqvx5GwDD4fCCj+AJsioJ7E2+y+NmOJWqOtjMKDC5+VX0w5mek09sr+VhMnqBVF0T1ipCrZ1BCYrASXHp1G/7vhZG3cE647su2YR+ktk+3tgTgx+vatjbqzBpJjGFlnOR2/LDuDzh09QD2xdAVinx2092xZkmQ5bR7zPrFIXDPAMUZTQ1B4JA2b/y1fh1IxSyCu6CRDMuzzoxc42YckH2LUTUFG4emIJdrKgTii5AfC2T3C32bmWQ3/VSVLDQHxxAklRV8cy64VULRlNmYQsTcAIURs09FkFxI4eN/1lhcpzCWfnAy2PmuXKTYLKGKf5mnzqm2zmQLaGFR7Lqblq6y8TK5vPiKirRjz1KQ+HYMpwIaAAggIhAFWmSqFsYdyGeHH/HyVPsQDBfNoy3RV5t2VOGp9A/wRqVIqBuu8awIKKsI76ssUm0fWwfpE6RKmzQNYn6a2TWeAzw6gwQFYK3OqRDxHAzMNkJUHUtrUfEREWylcymRkaZGtvmitHgNYkKPe1AvgVc0j3NWGgHUL/veLE3x/TFOCC99Saazwc5YeVicEFOu8a9REdaYq1Heawcg6N1if6vNtqLoArP9BH/KMTrGW+IfnbYiItkJgSSIOChDjtFUrCeFEXAxWC3rYn/3iJFuYjiQmcB+MhsNUI8RAV9/vvqVOvAIIKAaHQEAR/+zag2rMSxVz4fwjdSPrXGB9WqObYVHbK3Naf1wXUSltcg4ioq0MZNixfhHOYVnaclNhPd6+dD9fVjM5MRbu1iV76fWdafx4W+A2/EjfMuZuurJ43itRAorBITx5yWJoMqxPCCiEFCttujH2qT5vDLa2Bv78dvyoW87iyjsHEdFWAoQN8U8sqgZXHl1ICR1s10hiHiaEED3saMFEHzvEFD+yv32dypaprfZB3OeFL0/xOVzCNmXRYHQduo/U5CUkkAwB9ck5T/Gfzas3MNkd1qcZVaZlKySjPlNx5Z2HiGgLB+Kp1iJSI+2QacZSv7Yy8Wo6PLvhU/XyLsRNIaawKjFTE+VLiJVizibW3jG7h4ijYtE4WLpNLY9pkUBAMboO3UcQUExeUgmkbzdQ4D+epJCzx/W+d6zzfvsvLi5xcjH9jcSStUlOqOvF5wYkK+88RERbKBBPiKa1tYiQoa1XfmMC4qnWD8L0JMshIPcM7sIzNR+5uhuLLMTzqTXHWExhneKxL/xHf/zyKQPajjVjFlC0byoBRekSJi4te5l8SouosKf2p2Ra591d+Bn/l/ge2GPPGV1cRUSdh4hoCwXCCffdLJ6Yum5vCEV+eTW78eC5m3pZ/SHBikUiasZVsXT2f6/npThQkA1BRSIKViy4Z1BX+uml9ae/t1rMAorZn4iBQkBV6ZIxdanirqfozLhH3G59gnb++k+5lxHC+cpKKOa09qeLIdwR2mfZ3LGDQh0ioi0UNXXIEfFUTFuXUVuOZK8YXlmX2AfinXDZc59P4glMEE64+7+8vuWWMzWKIs39NQuoGgxiWbr0zBtUNfTiLiF3A4G0xZcnsvn8eiuT/oWm43ERLS4upuXLl9O8efNo+/btVI3MpwXoTN29ezfNnz+fFi5cSOnpRsucAR5z7Ngxvi05WbeUWjMQQligsBodGsWm8efNqXQku8KhciQMMgaW3UuYwLTgjstozbTBvBxHqwbfw/wsXSTNAgrrExPnLUuXlLh6AVgtAKiCesW3aXo8dHy/NuJBuAmPiigmGi1ZsoRGjhxJs2bNosrKStq4caNxax1btmxhcZw5cyZNmjSJe89VT3ZVVRW98847PNll6tSpbp/u4gnUyDpMcncE/Jj+ookoQPKooTimamtElh+JCPNJdUCpwvxWR6V2bFFAjwx8nl5PWbtsMWKfyvp0c+lSY1Bxbsvlk787rZc2iSXqXDwqohC+6OhoiomJIR/tRzt06FBKTU3lcVdmMHJr9OjR5OvrS2FhYTRixAhKSUnh27755hseRjBq1CgKCLBeVN6agAWqfhyOJnV+vuownz8+OMLhWBiK9GHp2sJRC7jFYBZPFNDD+kRsE7M/v/ui/npHsD6RPHJj6VJjUMubmMuc8EeaX1rFoRi1MJ/gHDwqollZWdSpU51rAZHMy8ujkpL63RaxsbGEyS1AzQWF8MIKPXHiBEVFRbEr//7771NOjvXaxtYCBFQlk+yJnAKJIPyAukcG0eNDHF/aF+46svxD4yKsnloNluIJYHm2CyE6/A3R/KfrXPcrb9bF0wutT/VVwHdD/VGay5xUfWir+uy8BI+KKEQwOLh+iQ3im5bT+WCF7tixg13+6dOn80iq7t27czgAsVC4+g888ACNHTuWXfvc3Fzjka0PZV3YauU0A/FU5UxvTezL54KBNfH00yy4syd1t/3/HtCnzavEEeo+p/zaI5l3R8BMWIAQjDVWH9an2Cdd0oHPBefh48l5ojt37uRzzNYEsECRPJoxYwZbl4o1a9bw9vDhw6miooKWLl1KSUlJbKEuW7aMJk+eTCEhxiJdmzezyz9sWP0Bt3ibe/bsMbbqQPjAnXFUvH68jvj4eH79jaFCszKO5+o/kkujMHWJL9pk0voc+iGnku69NJhmDQjkODL2606UZ2D+PJ2BT001+ZcUkn9pofbhGslITJA31i2Ct9IxOpr8jYEgVUZXUY2fHwUU55NfmT5bIKA4j4IvnKbg7DPUPk2fRqXI7n0l5XcfQHnayRHwp+7JY3yuRrdAiytraPp/cmlo5wBaeKMe/xy8TBfRt0dH0rAuzgl7paWlsUETGOhYbN4ZePIYQ3Os4VERPXToEFuREyZM4G2IqKUo4roVK1ZwQklZrcePH+eBsDfeeONFt1kKsz1a2lBmJHVQYI/seULH+ha8JXDjYYUiU7v3yWuonU8lh0Q8McwWOG0oMyzI/Ow669EGeK8I+Vz0Ay8rITp9XM+ynzmhmfa6uNQy4DqigcP1UyOtTk8ODAanK/XvBNpx0W2GUjYkEuHKYxulcB/cM8BpLr0MZdbxqDsfFxdHp0+f5n8XgHVM/P3967n42EaiyZxsKigo4B8H7odkEv4RAf4PYFnix9MaUbWhDbnyZje+1QwHgfhZut8Quc6aRRLfVz+hjx3bAYHULvNH8j24lWjTh0Qfv0b0/hyiV3+hZ9c/XaD9g+/QBRSWKmKd9zyjufCriR56UV/j3UvddkdAyy/YZ8RE1YJ0EE81d1RwHh4V0cjISBoyZAjNnj2bVq1axcmhcePGcab+4MGDvA2RHDNmDM2dO5fWrl1LixYtoq1bt3KGHtx+++30ySef0Ntvv03/+Mc/2JV3t6nvDtATj3gXfgQNiaLKxmPKfItu70OnEIQOwplhjJ0DSPxAMDH8OEj7w0XrJTLoK+cR/XUG0UvTqcvXy8l/8yqi7zcTpWjH47xe4sUkaJ4H1nRHidLsT/VYZwsXTjO1JU5G/PyrU7q7n5QQRSHW1oUSmoVH3XkFkkmIFTa0aiCsUVimfn4XfxFQYwrxtXabLVqSO6/WQIIVatnvbsbSjVeC62lX02F3Hu56Ya4ujLisQKwT4hmm/SmooR8QTkyLx8g5M5p1Wdg1gdolDCD/8Paay9Nbv97F/eyePsbnqkKoSvs5D44Jp44vfkV5pZU8nQtzD8CuJ67iqg649c5A3Hkdj1qiCpQ2ObLsKu5jSyRtiWtroS4rbzuIj/tg4hJocW68OVteoFlO2MasTghn1x665RnRUfsnLSb6+mO9bvODv9YJKGKZJusSPeyVN00hGnmnLp5uHgjiCZSVWVxRXVvmNG+rHuoaIQX2LsMrRFSwD9x4NeLOXpE7rFAIKRIKLcaNR3ultTpNuOooZkc7JTLrsEzRrw7xVKVH6BpCLHPul3osE4LppQXwnuJTo7Rp/GXS6ukqRERbAKrV0p5liZF1dVZoIp97Nao33VI8YXFCOFV8EmKJJYZVvzrEFDFN1G2i8B2xTOEi1J+omgN7/SViiboKEdEWgGrztJeVVyPqMLbOXszU40AEleWJ3nTVXqnE06jzrCee327QHweXHeL5+Kttwj13Fhg6c2m0Xi8b2FBxsdBoRES9HLjnaOXDch/2Bi0v2X2OfyzeuN67T4VmSSPLjvjlhbO65QnxxHBjlCTBdVfiifpNdAwp8QQoQXr2Pd1lF/F0CFXmBGCVllXqDQmOtAoLjUOOqJej2vjUUAlrqJpQLFnsFVYoXHXD4vTPTCP/rDN6sgjCCbGMjDZqOrvpJUoAlqeakqQGfSjxRAmSF42a81aUlYn4ufl70KLL3FoAIqJeTkmFbkEEGb3RlsAKxQlW6FPDPTgomTuJNPc887TeCWRYnD5VlVSDnnRMQ1JZdlxWlifEdvXruuVpOSVJxLNRKCsTVqf5T1eWRnYtIqJeDur+gC037Ocr9cJ6uPEeK2nC9HcUsyPGWar3pLOrrlmclR3jqBLrEcH6NC8rDFS2HbWeAJYnBhxjSlIrKXz3FChx2vTwUJo7vq93x8hbASKiXo6KZQX5X5wQWLz7LGdfUVgPV97tqPIkuOIqQcSlSb11V12zOGsCrNS1wuK0zLajvlMsT6cCN94j34s2hoiol4P4FrC0RJFwwtrvwCPJJLRkZhqtmCiKh/hBQCGkqqPIEiSWEPNE7FPVeapsu9R3uhT1PbIVFhKajhxRL0Z98a0NjVBW6KCYcF77yK2oxdvKNSHF+uuwOlHjaQMfuPgoV3rlET37jrgnuos8sLRwW6W8yn5YSGg6ckS9mLJK/YtvbWjEkj3n+NytViisTySMlPsO4US80zLWaSJk13qKXjCrrlzphjt08UR3keBUlJWp/nwF9+DjDQNI3AHeJgb1miksLOQhJP369TOucT0Y+7du3TpKTEykPn36GNdaJ6e0itLyyikiyI96RtbFFtPyy+nKhT/w5fSnB/J5Q2B4C8YOJiQ03m32KS8l38Ic8tXOQQ2GH0d0pGo7yR9Yn5Efv0qBqUd4u7x7P8q/5RGqau+eTDHW5erWrZtDMxmcBY4x1g1z92KJGCEJgtt3pOScMgoN9KWEqPrv+6R2fVF5NfXSrg/TbncGbe0YDxhgfTi3WKJejHLBggPqf0zb04r4fFyCbRfaGUA8/bLPkb92goBCPKvCoqiqU5xdAYVwwvrEeVVgO0q96SHKmfIHtwmoJ2kjNolH8bZj3GYsUWt4+yg8Nf4uvn07Xn1TMfHdfTxY4p27Ex2OhzZqhBiy7lma267KlZA4Co+sP4bOFqj5VCVLCZdTxoQnqKZdiPMm2ztIWxvTBkIiO9GxC0VWx90du1BMBWWV2vWhTlupVUbh6Ygl6sWoQnu0fCqQlVeTeSYmduZzp6Ky7hBQiKfmItaOobMnoMi8I3GkBBSJo8dfZQEVPI/qfAux8GqE5iNH1ItBz7wlqw9n8DnG3Tm9uB5LcJiz7o6IJ1ClSzhH2RJqPiVx5FWo75KfrwwgcTYiol6Msh7M7pdaP3xiopPji1y2pFmg5qx7Q+IJlICiaF51HEnNp0dQDRmqQUNwDyKiXoo1KxTUuvLO7IfGhCWULQH0taNwvikC6sXrsrcFVA2olDi5FxFRLwVLPAAkCRRYtRExURTYO60fGm2bmLAEIJ7ocXcEs4CibRMCKghtEBHRFoSKhzrNCoV4qrZNTFiy03VUD7OAxmquO+Z8CkIbRUTUS0E5CggzdSt9lZzL506Jh6rliEGHLna7juoB4UTvuxLQx/8mLryXU1CmYusemvLVyhERbSHsPVtQO7FJreTYZFAHiiw8QAzUURGEcMICRfxUBFQQGBFRL6WwXNX16Zbo4t16y6pTakNRSK+W53A0BgpggcKVFwH1WlRNsarsEFyPiKiXo+r6nJaVhwuvCukxus5RsEyxmsD00AsioF6Kv/F9kQS9+/C4iBYXF9Py5ctp3rx5tH37ds3TvPjTR2fq7t27af78+bRw4UJKTzfKcTSKiopo0aJF/Hh1Sk7W1xxqyZg7TODG44QlQJqzXo5faVFdJh7j6xwpYwKYwPT1x/plzP6UwcmCUItHRRQTjZYsWUIjR46kWbNmUWVlJW3cuNG4tY4tW7awMM6cOZMmTZrEveeqX7igoID8/Pxo2rRptaf4+Hi+rSVj7jBBaRNolhVaUUb+RYaAWluqwxZw3zELFNzzjBTSC4IFHhVRjLSKjo6mmJgY8vHxoaFDh1JqaiqPuzKDkVujR4/WDCdfCgsLoxEjRlBKSgrfhnF2eI6oqKjaU0CA7fXZWwLKClXxLTU7tDnxUJ+cDPKBlY8yJiSTHEElkgCK6a8aq18WWhTWKj0E5+FREc3KyqJOnToZW/AufSkvL49KSkqMa3RiY2N5cguAa4+5oBBekJuby5bozp07+YTwQEtHxbMQ34Ibj8w8aLIlqrnwPpolyqtuRjooxEpAcS7F9IJgE4+KaFVVFQUH1++8QUzUcjofrNAdO3awyz99+nQeSdW9u74AF8ZwYWDqJZdcQiEhITRnzhwW1pZMiWGJYh1x1St/W1NrQ2F95mfzxYpQB0bZKbCInMrESzF9i0HNnlXfIcH1eHSeKCxHgNmaABYokkczZsxgt1yxZs0a3h4+fDhVVFTQ0qVLKSkpyeqU9k2bNvH5qFGj+FyBt7lnzx5jqw6ED9w5JRuvH68DcVtY2NbILKnmU3SwL/1jXxGtOVVKz1wRRvde2vhWz8CCLPIrL6FSHz9KLap0KF4cln6SEtb/iwcqnxz3CyrpEGfc0nhycvQ/AfPn6Q7S0tL4zzYw0Mpqoy4CMX7E6t0dkzcfY/N3Bydg7Tpn0NaOMTTHKhBRT3Hw4MGazz77zNiqqdFc8ZqFCxfWFBUVGdfo173zzjt8rjh27FiNJqx8GffVLFq+DA4cOFCzevVqY8s+Z86cqdm3b5+x5R60P4qaN954o2bv3r3GNRdzKru4ZtfpvJoLReU1PedsraHfbKz5/ky+cWsjKNWOWeoPNTWnT9SUFObXHD161LihAV77ZU3NUzfW1KxbYlzRdNLT0/nkbvBecazdCfbn8DF2IuZjfCavlL87OFdYu84ZtLVjbAuPuvNxcXG87g/+XQDccn9//3ouPraRaDInm5CRV/9+n3/+OR0+fJgvA/w7Ytp2S0YtC5JeUFZb2tSkLqXayUyRRH4OJttQzoR6UMwFHXmHcaXQktFMDD5XNaSCc/GoiEZGRtKQIUNo9uzZtGrVKq4BHTduHGfqNSuVt5FpHzNmDM2dO5fWrl3LNaFbt27lDD3AbevXr6eVK1fSggULKDs7mwYOdGzxNm9FzYM8kqEnyZokoPlZRJUV2i9HE08MVnYEJJE2LNUvj5sqBfWtBGsrJAjOwyvWWEIyCbHChlYNhDUKyxTZeEtQYwrxtXabLbx1jaXdZ/L5fOmedPr7tlR67qZejVsaGeJ5PlVv7ewcTxQU7NjaNEgmbdBOyMajqN4JqHpeWWPJdZiP8dn8MjqneTAx4UEUG6H/nlyxvhKQNZZ0PGqJKlDa5Miyq7iPLZG0Ja4tDTVQ10/7Q/jqlJ4waHSXUo72o1IT6jUBdQi4/hBQMG6afi60ONSsBWV9Cq7HK0RUqKOsUncMQgL9autDGyWicMlVb7yjNaEAq3QCFNX3tr8KqeC9qFkLKg4quB4RUS9DtXvuOq279Jhi3ygQCwURHWDi65cbAomkA9v04SKIhQqC4DAiol6GavncfaYJVihW68RKnbxOfCMet/pf+jlW6JThIq0OlahUC9kJzkVE1MtQbtiOVL3rqlEiqiY0oaTJUVDShM4kKWlqtag4u1rITnAuclS9DJUQOJxRxOeDYx0sM0JGHvFQENYI4ZWSJkFoFiKiXgZioscyiymvpJKXAnF4VU8VC0VG3tFYKOKgyMrDCpUJTa0CzJ8FMtnefYiIehn48u8y6kQdduUxZKREt1wdLqwHcOWBuPGthtrsvJGgFFyPiKgXguJoMNjRzDyWPVZrJqFDyRFggR7crl8WK1QQmoyIqBehlrb9/qwe23TYEi00Rv+1b4QV+pWx3AfqQiUW2mqRpJLrkSPrZaBt70xeqeNDR4o011/1yDvanQS++0I/R1mT0GpRzRtB/vJTdxVyZL0I9Dcfy9Sn+js8dKRYj582OhaKTD4GLsuaSYLQLLxiAIk7wNvEsiJmsD4ThpD069fPuMb1YOzfunXrKDExkfr06WNcq3O+qJKe/+ocffJDLv3qms70q2vtD+3wKS8l/+xzVOPjS5XR8dpfou3/RAxvwdhBDLKO+uDPFJh6hPJveYRKBt5g3MM1YLwhwDpY7gTrcnXr1s2hmQzOAscY64a5c8g3sDzGJ3PKqKi8mnpF6e89WdsODfSlBGPbWbS1YzxgwABjqz5iiXoRheVVtN8Yf3ddfMNxSt8SvaupOrS9XQE143/+RxbQmqAQlwtoW6SN2CQexduOcZuxRK3hbaPwkJW/9BU9Y14z5yY+twnioOdO6ZdjLmkwK187Qmz3p3o89IY7iG7/hXGr65BReK7H8hibR9/p20UUHuSvbYfwtrOQUXg6Yol6EV8bo+8ud6S0SWXkUVzvYFmTL3rrVVmT1Ia2CdSCdWoBO8H5yJH1Ir5L05NEoxwpbSozloZuRHlS+x++0RNKGLosg0baBJVG0T3m0wquQUTUS9A7lRyc3IQOJUxrAo0Q0agD+kqoUtYkCM5DRNRLQE308QsODh1Rg0YaIaC+yQcooCBL75MfONy4VmiNhAXq0+0RFxVcj4ioh0FHSVpeKa3Yn84dS3HtgxoeOqJc+UYU1/tv+1S/IC2eguBUREQ9xPnianrr2zN013sH6Jp/fkczPjrC1zvU6qmGjTTCEvXRLFHmqpv1c0EQnIKIqAf4Mq89jf00ix7++AitOZLJrZ4R7fxp2tAYmn5lnHEvG1SU6cNGkJF3dNjIgW3kU1pEZR2155aEUpsCtccAJU6CaxAR9QBdAyr4/Noe7enZG3vR909eTXnPJ9Hiu/s3bIk2IR7KayhpFMf25XNBEJyHiKgHGBBSTFvu7ETbH7uSXhzTy/E+eaBEtDHDRoza0LxLr+FzQRCch4iohwgPbELdnrm0CbNDHQHrJ2WnU01kZyrr1M24UmjNKNddufKCa/G4iBYXF9Py5ctp3rx5tH37dk0n9PmHZtCZunv3bpo/fz4tXLiQ0tPTjVvqs2/fPtq1a5ex1QqpzcprAurwcsh7+ay610A+FwTBuXhURDHRaMmSJTRy5EiaNWsWVVZW0saNG41b69iyZQslJyfTzJkzadKkSdx7rvqFFRkZGbRgwQI6dcroJ2+N1MZD9Z5ohzDmhlb3v5bPBUFwLh4VUYy0wviumJgY8vHxoaFDh1JqaiqPuzKDkVujR4/WjC9fCgsLoxEjRlBKSopxK1FVVRVt2rSJxo5t5TWQ6H0H7Rx05bEECNx5japEiYe2RVTBfXiQXoAvOB+PimhWVhZ16tTJ2IKH6kt5eXlUUmKIhUFsbCxPbgFw7TEXFMKr2LlzJ2+br2t1oLRJTbAPcHB+o5GVpwHX6eeCIDgdj4ooLMjg4PpZZsRELafzwQrdsWMHu/zTp0/nkVTdu3fn2+DGYyTX8OGtvJWxtPFdSrwkMpA2zzaFWk5JVvx0Dx6dJwoLEmC2JoAFiuTRjBkzKCqqrl5yzZo1vA2hrKiooKVLl1JSUhL17NmTli1bRjfeeCNboXg+hAPuvvtu45F14G3u2bPH2KoD93fnlGy8fryO+Ph4trAdJSgvk3wry6g8vCNVBTompIMW/w+fH7nrf6kwMIzjyNivO8nJ0cf7mT9Pd5CWlsZ/toGBgcY1rgcxfm85xoez6/fNJ3ZwfrF9WzvG0BxreFREDx06xAmjCRMm8DZEFKI4efJkCgnR4364bsWKFZxQUlbr8ePH2frE8hovv/wyx0kBBiwXFRXRzTffTA8++GCDyxZ421Bmm6Bi4cwJ/XJcb8Q99Mv2gBW66Dl9HaVn3vCagcHuoi0PZQa7zxhrbxkMjYswLjkPGcqs41F3Pi4ujtf9wb8LwDom/v7+9Vx8bCPRZE42FRQU8L8fDuTbb7/N5VE4PfHEEzRlyhR67LHH3Lrui8tpSmmTcuWlV77NI7NEXYtHRTQyMpKGDBlCs2fPplWrVnEN6Lhx4zhTf/DgQd4OCAigMWPG0Ny5c2nt2rW0aNEi2rp1K2fo2wyqtKldI+KhJ/fr570H6+dCmyXEGI0nuAavWGMJySTEChuyHmGNwjL183POl6LFuPNYSwmZ+a49HMvMo6zplUf02aF/fJ+vEnfe9XirO++K9ZWAuPM6HrVEFShtcsT9xn2cJaAtBognTr7a+3a0tAnrygPJyrdZxIV3H14hooIdmtKldNKoD+3toKUrtDrEhXcfIqLeTpVRquKoFaq6lNppoiuWqCC4HBFRb0dNbQp0MO6ksvJihQoGgX7i2rsSEVFvB+2ewM/BYmnV6ilWqGAQqFqYBJcgR9fbwVIgwNGlQM4m6+coyhcEweWIiHozamqTowOYkYRCTBTx0LgE40qhLSLZefchIurNoLQJONqlpFx5EdA2T3CA/LTdhRxpb6bKENFABzPzxuxQ6VISBPchIurNqMy8w/ND9aVAxBIVzAT5y8/clcjR9WaUJYpuJUeoTSqJiAp1SHbetcjR9WZqV/Z0YPAIEkpILKFfvkNX40pBEFyNVwwgcQd4m1hWxExhYSEPIME6T+4C0/xPnDjBy6J07NjRuPZifGqqybcoj2p8fKk6tL1xrW0Czv9Igcd3UVWHWCpNvHhROuw3Pz/f7cORMd8VhIY2om3VCWCIbkREhFtnLXjTMS6prKF8Y32lqHb+Lim4b2vHePBg67mGNi+iQA11dhcQbowBxEQqd4GVVHNzc+utaeUO5Bi7HjnGrgfHuG/fvsZWfdqMiFoDo/BAY5bpcAaHDx+mSy655KL1pVwJVgjActKJiYnGNe5BjrHrkWPsenCMbR1fiYkKgiA0AxFRQRCEZiAiKgiC0AzadExUEAShuYglKgiC0AxERAVBEJqBiKggCEIzEBEVBEFoBpJYciNYX/+bb76hb7/9lrp27Uq33norhYQ4fz1wS5KTk+mzzz4ztohb9SZNmuSSVky8R7S1Yh94j4ri4mJ+Denp6XTVVVfRNddcw0tlOwusR3706FFej9xc/L1r1y7aunWrsUXUrVs3uu222yggwMGVAuxw+vRp2rBhA7+3UaNGUf/+/cnHx8eln3N5eTlt376d9u7de9Fzu/JzRovn559/TpmZmRd9fuhcWrNmDXf1mI+DM7B1jNGGuWLFCm4BVeBY9OrVy9hyHyKibgRfBvzAr7/+ehaT1atX00MPPUSBgYHGPVzD119/zV94fAEBvoT4gTlTxMB///tfPmEWAX5kV199NV+PH/7ChQtp4sSJ/MPfsmULd56MHTuWb28OeJ4lS5bwOX5YM2fOrNdX/dFHH7GwxsXF8Tb6vMPDw5v9Iz958iS/1/vvv5+P48qVK7mLZsiQIS77nNE3/u6777KIYV8pKSn073//mx5++GF+bld9zmizxH6nTJnC8x62bdvGojphwgS+Dccf7w9i/vHHH1NCQgIfh+aSmprKwj116lRq164dH0d8jvhe4bjiOEM4FWh7dcafY2MRd95NlJWV8Zdi6NCh/OWOiYlhsTlz5oxxD9cBCwHiBXHBCf3OzhZQMHLkSPrzn//MAmoG7xHvFe8Z7x3HAMcCx6S54McFEXn66acpPj7euLYOvHf88NR7h6g0V0DBkSNHKCkpifcPAcMPG7MZXPk5w+qCzQMBxXOj5RJ/CGoAias+Z7yfK6+8kvvVsV+INAS8oqKCvY5BgwaxgGFfI0aMoH37jBUWmgn+qG688UYWZzz35ZdfTj/88APfhveK46reK06eEFAgIuomYCnhC4gfnZmsrCzjkuuAu4UvHSyIQ4cOsbvpCmxN88F7NA+MwA8iLy+Pj0lzwTG1JRQQNFhvaWlp/N7Rc+0sx2v8+PHUp08fY0sXuPbt27v0c4ZQPPjgg/z8ABY+CArSh3a76nOGeF17bd1kMLj0HTp0YNE6f/48i5kCrwWvwxl/kHDfzccY1qfyKGAB4/u2c+dOPsHd9xQiom4CP1586cxCg+vwI3c1cC0LCgrosssu43/3xYsXO01MHAHv0XJIBX7grn4NEFfsA6KDH+OmTZto/fr1xq3OA8f2+++/ZxfWnZ8z4q54Xyom6urPGe7zs88+Sx988AHdfvvtfB2OrRJxBT5bZwk4rN1Vq1bRU089xQNPbrjhBr4ef1IQc1jjeP9z5sxhYfUEIqJtgLvvvpvjc4hn3XLLLZyEgQXR2oGYIVY3cOBA6ty5MydZjh07Vuv+OgNYQIiHIj6oxMwdIGEGwTRbiK7+nBHDfvHFFzkO+cknn7j8TxDgM7zrrrvo1VdfpR49etDmzZv5+gEDBtB9993Hnys+X1it+CPzBCKibgJxM7h6ZhcWlgPcIlcCi8Ds6sBCglsIt89dIF6WkZFhbOnAvbe0YJwNrD+zWwnrBT9K5QY3Fzz/8uXLWbjwYwbu+JyPHz9O+/fvp3HjxtW69q78nBHrzc7O5svYX79+/Tg8ARHHe7MMVeCztQxnNAXEXdXrh1eBhBoqMGCd4r2arV2EFMyZenciIuomYKXgBBcE4IeMWJ05nuQKYI288847/IUH2C/ikepH7w4Qx0KpihIvHAMM8rV08Z0NYnN478qVxjGAuDhjeDGsMJT1wHU2x+1c/Tnjz2jdunU0efLkeiEDV37OsGYRd1RAxJDQwueHTDySPcoqRdxZJRCbC7wGnBR4jxBo/BEiaw/3XoFjDEvVE/g9r2FcFlwIvlT4cr3xxhv8z41SEGQye/fubdzDNeALhx81SlTwo8J+kVXu2bOncQ/nozLRqMkEsEogZIjRQdgQl0S5jLMnsSMrbK4TxfPDdYe7DUsKNZQoszInuZrKwYMHacGCBXwZAoP4JH7U2D9+zK74nCFe8+bNY4sL1QHYJ074Q8I+XfU54w9gx44dXNKFuCNceYQvcBxR7aBKkVCnivrVn/3sZ/y9ay74veB94DkxFBkxWYRk8D7xx/zhhx/ydw0lc7BKkcm3lWR0JVIn6gHgYsLtc8a/dWPw1H4V+KJDCFztxluCrzgsM3fvt7V9zvj8YA1CxCzBnySOsyuWCsFzY1kQa58frsf7NFvl7kZEVBAEoRlITFQQBKEZiIgKgiA0AxFRQRCEZiAiKgiC0AxERAVBEJqBiKggCEKTIfp/ZbaqNCyZJOAAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "id": "4e230f52-7314-4d01-b388-9c84f8546301",
   "metadata": {},
   "source": [
    "![image.png](attachment:6a03aaca-b747-4a66-956c-bf061f7c2def.png)"
   ]
  },
  {
   "attachments": {
    "6ceb4830-4368-4dcc-9fdb-71090539a85a.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "d3493201-1160-41a5-9667-a59cf5a1bd70",
   "metadata": {},
   "source": [
    "![image.png](attachment:6ceb4830-4368-4dcc-9fdb-71090539a85a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d1f5be",
   "metadata": {},
   "source": [
    "# test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e71f9a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n"
     ]
    }
   ],
   "source": [
    "best_model=keras.models.load_model(\"smv2sl_adam_lrsch_onecycle_batch32_lr0.001_epoch40.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1ce14fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3636/3636 [==============================] - 28s 8ms/step - loss: 0.3187 - accuracy: 0.8796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3186957836151123, 0.8795766830444336]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(X_test_final,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9d3c9b",
   "metadata": {},
   "source": [
    "0.1204 error rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfca493",
   "metadata": {},
   "source": [
    "# test with handwrite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "da419681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이승훈\n",
    "\n",
    "loaded_data=np.loadtxt('./datasets/Emnist/Estela_ExtendMnist-1.csv', delimiter=\",\",dtype='uint8')\n",
    "y_estela_full,X_estela_full=np.split(loaded_data,[1],axis=1)\n",
    "np.savetxt('./datasets/Emnist/estela_data.csv',X_estela_full,fmt='%d',delimiter=',')\n",
    "np.savetxt('./datasets/Emnist/estela_label.csv',y_estela_full,fmt='%d',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "211e3bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현, jmj\n",
    "X_estela=np.reshape(X_estela,[-1,28,28,1])\n",
    "X_estela_resize=np.uint8(tf.image.resize(X_estela, [32, 32]))\n",
    "X_estela_final=keras.applications.mobilenet_v2.preprocess_input(np.array(X_estela_resize,np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "34e72261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 2s 9ms/step - loss: 5.8726 - accuracy: 0.1736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.872628211975098, 0.17357638478279114]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(X_estela_final,y_estela)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456f1f9f",
   "metadata": {},
   "source": [
    "0.8264 error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3f78f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef41235a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
