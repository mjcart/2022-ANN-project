{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c25bd3",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "061d4a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version:  0.24.2\n",
      "TF version:  2.8.0\n",
      "GPU installed:  True\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "print(\"sklearn version: \", sklearn.__version__)\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "print(\"TF version: \", tf.__version__)\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "# GPU test\n",
    "print(\"GPU installed: \",tf.test.is_built_with_gpu_support())\n",
    "\n",
    "# To prevent \"CUDNN_STATUS_ALLOC_FAILED\" error with GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "    \n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"cnn\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "    \n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")    \n",
    "\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aad9190",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8c0a7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "#이승훈\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "loaded_data=np.loadtxt('./datasets/Emnist/emnist-byclass-train.csv', delimiter=\",\",dtype='uint8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d62f7d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이승훈\n",
    "\n",
    "y_train_full,X_train_full=np.split(loaded_data,[1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e21d5f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이승훈\n",
    "\n",
    "loaded_data=np.loadtxt('./datasets/Emnist/emnist-byclass-test.csv', delimiter=\",\",dtype='uint8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6328315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이승훈\n",
    "\n",
    "y_test_full,X_test_full=np.split(loaded_data,[1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이승훈\n",
    "X_train, X_valid, y_train, y_valid=train_test_split(X_train_full, y_train_full, test_size=0.235, random_state=42)\n",
    "np.savetxt('./datasets/Emnist/train_data.csv',X_train,fmt='%d',delimiter=',')\n",
    "np.savetxt('./datasets/Emnist/valid_data.csv',X_valid,fmt='%d',delimiter=',')\n",
    "np.savetxt('./datasets/Emnist/train_label.csv',y_train,fmt='%d',delimiter=',')\n",
    "np.savetxt('./datasets/Emnist/valid_label.csv',y_valid,fmt='%d',delimiter=',')\n",
    "\n",
    "os.chdir('../') #원래 디렉토리로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31a06add",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이승훈\n",
    "np.savetxt('./datasets/Emnist/test_data.csv',X_test_full,fmt='%d',delimiter=',')\n",
    "np.savetxt('./datasets/Emnist/test_label.csv',y_test_full,fmt='%d',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "264b075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#작성자 전민재\n",
    "import csv\n",
    "def load_Emist(exsitNumpy=False, needTranspose=True,make_train=True,make_valid=True,make_test=True):\n",
    "    if (exsitNumpy == False):\n",
    "        #\"./emnist-byclass-test.csv\"\n",
    "        #train-set\n",
    "        #\"공용/datasets/Emnist/\" 위치에 csv 저장 \n",
    "        csv_train_data_file = open(\"./datasets/Emnist/train_data.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "        csv_train_label_file = open(\"./datasets/Emnist/train_label.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "    \n",
    "        \n",
    "        f_train = csv.reader(csv_train_data_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "        l_train=csv.reader(csv_train_label_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "        #valid-set\n",
    "    \n",
    "        csv_valid_data_file = open(\"./datasets/Emnist/valid_data.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "        csv_valid_label_file = open(\"./datasets/Emnist/valid_label.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "        \n",
    "        f_valid = csv.reader(csv_valid_data_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "        l_valid = csv.reader(csv_valid_label_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "        \n",
    "        \n",
    "        #test-set\n",
    "    \n",
    "        csv_test_data_file = open(\"./datasets/Emnist/test_data.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "        csv_test_label_file = open(\"./datasets/Emnist/test_label.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "        \n",
    "        f_test = csv.reader(csv_test_data_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "        l_test = csv.reader(csv_test_label_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "        \n",
    "        \n",
    "        X_train=[]\n",
    "        y_train=[]\n",
    "        X_valid=[]\n",
    "        y_valid=[]\n",
    "        X_test=[]\n",
    "        y_test=[]\n",
    "        if make_train:\n",
    "            for i, row in enumerate(f_train):\n",
    "                #행마다 int로 형변환\n",
    "                for idx, char in enumerate(row):\n",
    "                    row[idx]=int(char)\n",
    "                #train\n",
    "                #data 추가    \n",
    "                X_train.append(row)\n",
    "            for i, row in enumerate(l_train):\n",
    "\n",
    "                #train\n",
    "                #label 추가\n",
    "                y_train.append(int(row[0]))\n",
    "            \n",
    "            \n",
    "        if make_valid:\n",
    "            for i, row in enumerate(f_valid):\n",
    "                #행마다 int로 형변환\n",
    "                for idx, char in enumerate(row):\n",
    "                    row[idx]=int(char)\n",
    "                #valid\n",
    "                #data 추가    \n",
    "                X_valid.append(row)\n",
    "\n",
    "\n",
    "            for i, row in enumerate(l_valid):\n",
    "\n",
    "                #valid\n",
    "                #label 추가\n",
    "                y_valid.append(int(row[0]))\n",
    "                \n",
    "        if make_test:\n",
    "            for i, row in enumerate(f_test):\n",
    "                #행마다 int로 형변환\n",
    "                for idx, char in enumerate(row):\n",
    "                    row[idx]=int(char)\n",
    "                #valid\n",
    "                #data 추가    \n",
    "                X_test.append(row)\n",
    "\n",
    "\n",
    "            for i, row in enumerate(l_test):\n",
    "\n",
    "                #valid\n",
    "                #label 추가\n",
    "                y_test.append(int(row[0]))\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "        #train\n",
    "        X_train=np.array(X_train,dtype=np.uint8)\n",
    "        X_train=X_train.reshape(-1,28,28)\n",
    "        #valid\n",
    "        X_valid=np.array(X_valid,dtype=np.uint8)\n",
    "        X_valid=X_valid.reshape(-1,28,28)\n",
    "        #test\n",
    "        X_test=np.array(X_test,dtype=np.uint8)\n",
    "        X_test=X_test.reshape(-1,28,28)\n",
    "        \n",
    "        \n",
    "        csv_train_data_file.close()\n",
    "        csv_train_label_file.close()\n",
    "        csv_valid_data_file.close()\n",
    "        csv_valid_label_file.close()\n",
    "        csv_test_data_file.close()\n",
    "        csv_test_label_file.close()\n",
    "        #kaggle dataset이 시계반대방향으로 90도 회전 되있고 상하 반전 되어있음\n",
    "        def rotate_90(m):\n",
    "            N = len(m)\n",
    "            ret = [[0] * N for _ in range(N)]\n",
    "\n",
    "            for r in range(N):\n",
    "                for c in range(N):\n",
    "                    ret[c][N-1-r] = m[r][c]\n",
    "            return np.array(ret,dtype=np.uint8)\n",
    "\n",
    "        def vreflect(m):\n",
    "            N = len(m)\n",
    "            ret = [[0] * N for _ in range(N)]\n",
    "\n",
    "            for r in range(N):\n",
    "                for c in range(N):\n",
    "                    ret[r][c] = m[r][N-1-c]\n",
    "            return np.array(ret,dtype=np.uint8)\n",
    "        \n",
    "        if needTranspose == True:\n",
    "            if make_train:\n",
    "                #train\n",
    "                #회전\n",
    "                for idx,i in enumerate(X_train):\n",
    "                    X_train[idx]=rotate_90(i)\n",
    "                #상하반전\n",
    "                for idx,i in enumerate(X_train):\n",
    "                    X_train[idx]=vreflect(i)\n",
    "                np.save('./X_train',X_train)\n",
    "                np.save('./y_train',y_train)\n",
    "                \n",
    "                \n",
    "            if make_valid:\n",
    "                #valid\n",
    "                #회전\n",
    "                for idx,i in enumerate(X_valid):\n",
    "                    X_valid[idx]=rotate_90(i)\n",
    "                #상하반전\n",
    "                for idx,i in enumerate(X_valid):\n",
    "                    X_valid[idx]=vreflect(i)\n",
    "                np.save('./X_valid',X_valid)\n",
    "                np.save('./y_valid',y_valid)\n",
    "            if make_test:\n",
    "\n",
    "                #test\n",
    "                #회전\n",
    "                for idx,i in enumerate(X_test):\n",
    "                    X_test[idx]=rotate_90(i)\n",
    "                #상하반전\n",
    "                for idx,i in enumerate(X_test):\n",
    "                    X_test[idx]=vreflect(i)\n",
    "                    \n",
    "                np.save('./X_test',X_test)\n",
    "                np.save('./y_test',y_test)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "   \n",
    "    X_train=np.load('./X_train.npy')\n",
    "    y_train=np.load('./y_train.npy')\n",
    "    X_valid=np.load('./X_valid.npy')\n",
    "    y_valid=np.load('./y_valid.npy')\n",
    "    X_test=np.load('./X_test.npy')\n",
    "    y_test=np.load('./y_test.npy')\n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8bae2929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((533917, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현\n",
    "#npy 파일이 존재할 경우 exsitNumpy = True, 업으면 False\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = load_Emist(exsitNumpy=False,make_train=False,make_valid=False,make_test=True)\n",
    "X_train.shape,X_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a66674a",
   "metadata": {},
   "source": [
    "# [224,224,3] tensoeflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d19732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_letters = X_train[np.where(y_train>10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "113dde7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_letters = y_train[np.where(y_train>10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09828178",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (3):\n",
    "    X_train = np.append(X_train,X_train_letters,axis=0)\n",
    "    y_train = np.append(y_train, y_train_letters,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc216c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1329679, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ddf70e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "#이승훈\n",
    "import cv2 as cv\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "ids=1\n",
    "X_new=X_train[ids]\n",
    "y_new=y_train[ids]\n",
    "c=X_new.reshape(28,28)\n",
    "\n",
    "\n",
    "plt.imshow(c, cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4547afdd",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49ea9a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1329679"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현\n",
    "#data, batch size 성정\n",
    "train_size=len(X_train)\n",
    "valid_size=len(X_valid)\n",
    "batch_size=32\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb196c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1329679, 784), (164015, 784))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현\n",
    "X_train=np.reshape(X_train,[-1,784])\n",
    "X_valid=np.reshape(X_valid,[-1,784])\n",
    "X_train.shape,X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f8c165c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1329679, 1), (164015, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현\n",
    "y_train=np.reshape(y_train,[-1,1])\n",
    "y_valid=np.reshape(y_valid,[-1,1])\n",
    "\n",
    "y_train.shape,y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52542ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_inputs = 784\n"
     ]
    }
   ],
   "source": [
    "n_inputs = X_train.shape[-1]\n",
    "print(\"n_inputs =\",n_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58fc22e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "def save_to_multiple_csv_files(data, name_prefix, rewrite, header=None, n_parts=10):\n",
    "    \n",
    "    Emnist_dir = os.path.join(\"../공용/datasets\", \"Emnist\")\n",
    "    os.makedirs(Emnist_dir, exist_ok=True)\n",
    "    path_format = os.path.join(Emnist_dir, \"my_{}_{:02d}.csv\")\n",
    "\n",
    "    filepaths = []\n",
    "    m = len(data)\n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        filepaths.append(part_csv)\n",
    "        if rewrite:\n",
    "            \n",
    "            try:\n",
    "                with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
    "                    if header is not None:\n",
    "                        f.write(header)\n",
    "                        f.write(\"\\n\")\n",
    "                    for row_idx in row_indices:\n",
    "                        f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                        f.write(\"\\n\")\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            try:\n",
    "                with open(part_csv, \"xt\", encoding=\"utf-8\") as f:\n",
    "                    if header is not None:\n",
    "                        f.write(header)\n",
    "                        f.write(\"\\n\")\n",
    "                    for row_idx in row_indices:\n",
    "                        f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                        f.write(\"\\n\")\n",
    "            except:\n",
    "                continue\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6576a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full=np.append(X_train,y_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a8dcd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1329679, 785)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "418d2d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_full=np.append(X_valid,y_valid,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a2a0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "train_filepaths = save_to_multiple_csv_files(train_full, \"train\", n_parts=20,rewrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7584e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "\n",
    "valid_filepaths = save_to_multiple_csv_files(valid_full, \"valid\", n_parts=20,rewrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b0fcde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "\n",
    "def dataaugmentation(X):\n",
    "    datagen=ImageDataGenerator(rotation_range=40,width_shift_range = 0.2, \n",
    "        height_shift_range = 0.2)\n",
    "    #영어 부분 2배 생성\n",
    "    #차원변환 \n",
    "    X=tf.reshape(X,[28,28,1])\n",
    "\n",
    "    #새로운 데이터 생성\n",
    "    angle=(random.random()%1)*0.8 - 0.4\n",
    "    image_result =tfa.image.rotate(X, tf.constant(angle))#rotate -pi/10 ~ pi/10\n",
    "    shift=(random.random()%1)*2 - 1\n",
    "    image_result=tfa.image.translate(image_result,[tf.constant(shift),tf.constant(shift)])\n",
    "    \n",
    "    return image_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc19f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "@tf.function\n",
    "def preprocess_mobilenet_v2(line,randomize=False):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    x=tf.reshape(x,[28,28,1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    augment_image = x\n",
    "    if y > 10 and randomize:\n",
    "        augment_image = dataaugmentation(x)\n",
    "        \n",
    "        \n",
    "    resized_image = tf.image.resize(augment_image, [224, 224])\n",
    "    if resized_image.shape[2] == 1:\n",
    "        temp=tf.concat([resized_image,resized_image],2)\n",
    "        resized_image=tf.concat([temp,resized_image],2)\n",
    "    final_image = keras.applications.mobilenet_v2.preprocess_input(resized_image)\n",
    "    \n",
    "    return final_image, y\n",
    "\n",
    "@tf.function\n",
    "def preprocess_resnet50(line,randomize=False):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    x=tf.reshape(x,[28,28,1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    augment_image = x\n",
    "    if y > 10 and randomize:\n",
    "        augment_image = dataaugmentation(x)\n",
    "        \n",
    "        \n",
    "    resized_image = tf.image.resize(augment_image, [224, 224])\n",
    "    if resized_image.shape[2] == 1:\n",
    "        temp=tf.concat([resized_image,resized_image],2)\n",
    "        resized_image=tf.concat([temp,resized_image],2)\n",
    "    final_image = keras.applications.resnet50.preprocess_input(resized_image)\n",
    "    \n",
    "    return final_image, y\n",
    "\n",
    "@tf.function\n",
    "def preprocess_vgg16(line,randomize=False):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    x=tf.reshape(x,[28,28,1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    augment_image = x\n",
    "    if y > 10 and randomize:\n",
    "        augment_image = dataaugmentation(x)\n",
    "        \n",
    "        \n",
    "    resized_image = tf.image.resize(augment_image, [224, 224])\n",
    "    if resized_image.shape[2] == 1:\n",
    "        temp=tf.concat([resized_image,resized_image],2)\n",
    "        resized_image=tf.concat([temp,resized_image],2)\n",
    "    final_image = keras.applications.vgg16.preprocess_input(resized_image)\n",
    "    \n",
    "    return final_image, y\n",
    "\n",
    "@tf.function\n",
    "def preprocess_renet(line,randomize=False):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    x=tf.reshape(x,[28,28,1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    augment_image = x\n",
    "    if y > 10 and randomize:\n",
    "        augment_image = dataaugmentation(x)\n",
    "        \n",
    "   \n",
    "    return augment_image, y\n",
    "\n",
    "@tf.function\n",
    "def preprocess_xception(line,randomize=False):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    x=tf.reshape(x,[28,28,1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    augment_image = x\n",
    "    if y > 10 and randomize:\n",
    "        augment_image = dataaugmentation(x)\n",
    "        \n",
    "        \n",
    "    resized_image = tf.image.resize(augment_image, [224, 224])\n",
    "    if resized_image.shape[2] == 1:\n",
    "        temp=tf.concat([resized_image,resized_image],2)\n",
    "        resized_image=tf.concat([temp,resized_image],2)\n",
    "    final_image = keras.applications.xception.preprocess_input(resized_image)\n",
    "    \n",
    "    return final_image, y\n",
    "\n",
    "@tf.function\n",
    "def preprocess_inception_v3(line,randomize=False):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    x=tf.reshape(x,[28,28,1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    augment_image = x\n",
    "    if y > 10 and randomize:\n",
    "        augment_image = dataaugmentation(x)\n",
    "        \n",
    "        \n",
    "    resized_image = tf.image.resize(augment_image, [224, 224])\n",
    "    if resized_image.shape[2] == 1:\n",
    "        temp=tf.concat([resized_image,resized_image],2)\n",
    "        resized_image=tf.concat([temp,resized_image],2)\n",
    "    final_image = keras.applications.inception_v3.preprocess_input(resized_image)\n",
    "    \n",
    "    return final_image, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acd61bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "from enum import Enum\n",
    "class eModelName(Enum):\n",
    "    mobilenet_v2 = 0,\n",
    "    resnet50 = 1,\n",
    "    vgg16 = 3,\n",
    "    renet = 4,\n",
    "    xception = 5,\n",
    "    inception_v3 = 6\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5359b35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "from functools import partial\n",
    "def csv_reader_dataset(filepaths, model_name, repeat=1, n_readers=5,\n",
    "                       n_read_threads=None, shuffle_buffer_size=50000,\n",
    "                       n_parse_threads=5, batch_size=32,randomize=True):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    if model_name == eModelName.mobilenet_v2:\n",
    "        dataset = dataset.map(partial(preprocess_mobilenet_v2,randomize=randomize), num_parallel_calls=n_parse_threads)\n",
    "        print(model_name.name)\n",
    "    elif model_name == eModelName.resnet50:\n",
    "        dataset = dataset.map(partial(preprocess_resnet50,randomize=randomize), num_parallel_calls=n_parse_threads)\n",
    "        print(model_name.name)\n",
    "    elif model_name == eModelName.vgg16:\n",
    "        dataset = dataset.map(partial(preprocess_vgg16,randomize=randomize), num_parallel_calls=n_parse_threads)\n",
    "        print(model_name.name)\n",
    "    elif model_name == eModelName.renet:\n",
    "        dataset = dataset.map(partial(preprocess_renet,randomize=randomize), num_parallel_calls=n_parse_threads)\n",
    "        print(model_name.name)\n",
    "    elif model_name == eModelName.xception:\n",
    "        dataset = dataset.map(partial(preprocess_xception,randomize=randomize), num_parallel_calls=n_parse_threads)\n",
    "        print(model_name.name)\n",
    "    elif model_name == eModelName.inception_v3:\n",
    "        dataset = dataset.map(partial(preprocess_inception_v3,randomize=randomize), num_parallel_calls=n_parse_threads)\n",
    "        print(model_name.name)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe30ef1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_v2\n",
      "mobilenet_v2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>,\n",
       " <PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현\n",
    "#csv_reader_dataset의 파라미터 model_name에 eModelNAme class의 맴버 변수 중 사용할 모델 입력\n",
    "#ex) model_name = eModelName.inception_v3, model_name = eModelName.renet \n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "batch_size=32\n",
    "train_set = csv_reader_dataset(train_filepaths, model_name = eModelName.mobilenet_v2, batch_size=batch_size, repeat=None)\n",
    "valid_set = csv_reader_dataset(valid_filepaths, model_name = eModelName.mobilenet_v2, \n",
    "                               batch_size=batch_size, repeat=None, randomize = False)\n",
    "train_set,valid_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1b7d0f",
   "metadata": {},
   "source": [
    "# [32,32,1] np dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8d471ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "X_train=tf.reshape(X_train,[-1,28,28,1])\n",
    "X_valid=tf.reshape(X_valid,[-1,28,28,1])\n",
    "X_test=tf.reshape(X_test,[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dc182d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현, jmj\n",
    "X_train_resize=np.uint8(tf.image.resize(X_train, [32, 32]))\n",
    "X_valid_resize=np.uint8(tf.image.resize(X_valid, [32, 32]))\n",
    "X_test_resize=np.uint8(tf.image.resize(X_test, [32, 32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "018323ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((533917, 32, 32, 1), dtype('uint8'), (164015, 32, 32, 1), (116323, 32, 32, 1))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현\n",
    "X_train_resize.shape,X_valid_resize.dtype,X_valid_resize.shape,X_test_resize.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea376b0",
   "metadata": {},
   "source": [
    "# [32,32,1] augmentation np dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35ef2673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "def dataaugmentation(X,y):\n",
    "    datagen=ImageDataGenerator(width_shift_range = 0.2, \n",
    "        height_shift_range = 0.2)\n",
    "\n",
    "    X_new=[]\n",
    "    y_new=[]\n",
    "    #영어 부분 2배 생성\n",
    "    for i in range(2):\n",
    "        #X_valid[:10]부분을 교체하고 실행\n",
    "        for idx,image in enumerate(X):\n",
    "            #숫자 제외하고 augmentation\n",
    "            if y[idx]>9:\n",
    "\n",
    "                #차원변환 \n",
    "                x=image.reshape(32,32,1)\n",
    "                x=x[tf.newaxis,...]\n",
    "\n",
    "                #새로운 데이터 생성\n",
    "                image_result = next(iter(datagen.flow(x)))\n",
    "                X_new.append(np.squeeze(image_result))\n",
    "                y_new.append(y[idx])\n",
    "    return X_new,y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69549163",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new,y_new=dataaugmentation(X_train_resize,y_train)\n",
    "X_train_new=np.append(X_train_resize,np.int8((X_new)),axis=0)\n",
    "y_train_new=np.append(y_train,np.int8(y_new[idx]),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21842144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "np.save('./X_train_aug',X_train_new)\n",
    "np.save('./y_train_aug',y_train_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26e806ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_aug=np.load('./X_train_aug.npy')\n",
    "y_train_aug=np.load('./y_train_aug.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61f609b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1074263, 32, 32, 1), (164015, 32, 32, 1), tf.uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid=tf.reshape(X_valid,[-1,28,28,1])\n",
    "X_valid_resize=np.uint8(tf.image.resize(X_valid, [32, 32]))\n",
    "\n",
    "X_train_aug.shape,X_valid_resize.shape,X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b4330c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess input\n",
    "X_train_aug=keras.applications.mobilenet_v2.preprocess_input(np.array(X_train_aug,np.float32))\n",
    "X_valid_final=keras.applications.mobilenet_v2.preprocess_input(np.array(X_valid_resize,np.float32))\n",
    "X_test_final=keras.applications.mobilenet_v2.preprocess_input(np.array(X_test_resize,np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59bf126",
   "metadata": {},
   "source": [
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a248b1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c031f2d",
   "metadata": {},
   "source": [
    "# Baseline 1: Lenet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3a8f40",
   "metadata": {},
   "source": [
    "train & finetuning logs in lenet.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef7e9fa",
   "metadata": {},
   "source": [
    "best lenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c570d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet_model():\n",
    "    return keras.models.Sequential(\n",
    "        [\n",
    "            keras.layers.Conv2D(24, kernel_size=5, strides=1, padding=\"valid\", kernel_initializer=\"lecun_uniform\", input_shape=(32, 32, 1)),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Activation('elu'),\n",
    "            keras.layers.MaxPooling2D(pool_size=2, strides=2, padding=\"valid\"),\n",
    "            keras.layers.Conv2D(64, kernel_size=5, strides=1, padding=\"valid\", kernel_initializer=\"lecun_uniform\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Activation('elu'),\n",
    "            keras.layers.MaxPooling2D(pool_size=2, strides=2, padding=\"valid\"),\n",
    "            keras.layers.Conv2D(480, kernel_size=5, strides=1, padding=\"valid\", kernel_initializer=\"lecun_uniform\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Activation('elu'),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(324, kernel_initializer=\"lecun_uniform\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Activation('elu'),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Dense(62, activation=\"softmax\"),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b50d98e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2086/2086 [==============================] - 27s 11ms/step - loss: 0.5575 - accuracy: 0.8149 - val_loss: 0.4166 - val_accuracy: 0.8522\n",
      "Epoch 2/100\n",
      "2086/2086 [==============================] - 21s 10ms/step - loss: 0.4236 - accuracy: 0.8485 - val_loss: 0.4048 - val_accuracy: 0.8518\n",
      "Epoch 3/100\n",
      "2086/2086 [==============================] - 21s 10ms/step - loss: 0.3971 - accuracy: 0.8558 - val_loss: 0.3842 - val_accuracy: 0.8602\n",
      "Epoch 4/100\n",
      "2086/2086 [==============================] - 22s 11ms/step - loss: 0.3801 - accuracy: 0.8601 - val_loss: 0.3690 - val_accuracy: 0.8622\n",
      "Epoch 5/100\n",
      "2086/2086 [==============================] - 22s 11ms/step - loss: 0.3672 - accuracy: 0.8638 - val_loss: 0.3668 - val_accuracy: 0.8661\n",
      "Epoch 6/100\n",
      "2086/2086 [==============================] - 21s 10ms/step - loss: 0.3564 - accuracy: 0.8671 - val_loss: 0.3674 - val_accuracy: 0.8621\n",
      "Epoch 7/100\n",
      "2086/2086 [==============================] - 21s 10ms/step - loss: 0.3469 - accuracy: 0.8700 - val_loss: 0.3529 - val_accuracy: 0.8692\n",
      "Epoch 8/100\n",
      "2086/2086 [==============================] - 21s 10ms/step - loss: 0.3383 - accuracy: 0.8722 - val_loss: 0.3539 - val_accuracy: 0.8702\n",
      "Epoch 9/100\n",
      "2086/2086 [==============================] - 21s 10ms/step - loss: 0.3305 - accuracy: 0.8739 - val_loss: 0.3569 - val_accuracy: 0.8696\n",
      "Epoch 10/100\n",
      "2086/2086 [==============================] - 21s 10ms/step - loss: 0.3227 - accuracy: 0.8764 - val_loss: 0.3554 - val_accuracy: 0.8684\n",
      "Epoch 11/100\n",
      "2086/2086 [==============================] - 21s 10ms/step - loss: 0.3161 - accuracy: 0.8780 - val_loss: 0.3606 - val_accuracy: 0.8678\n",
      "Epoch 12/100\n",
      "2086/2086 [==============================] - 21s 10ms/step - loss: 0.3090 - accuracy: 0.8805 - val_loss: 0.3571 - val_accuracy: 0.8692\n",
      "Epoch 13/100\n",
      "2086/2086 [==============================] - 21s 10ms/step - loss: 0.3022 - accuracy: 0.8822 - val_loss: 0.3592 - val_accuracy: 0.8686\n",
      "Epoch 14/100\n",
      "2086/2086 [==============================] - 21s 10ms/step - loss: 0.2965 - accuracy: 0.8841 - val_loss: 0.3600 - val_accuracy: 0.8687\n",
      "Epoch 15/100\n",
      "2086/2086 [==============================] - 21s 10ms/step - loss: 0.2897 - accuracy: 0.8860 - val_loss: 0.3612 - val_accuracy: 0.8695\n",
      "Epoch 16/100\n",
      "2086/2086 [==============================] - 21s 10ms/step - loss: 0.2829 - accuracy: 0.8878 - val_loss: 0.3685 - val_accuracy: 0.8670\n",
      "Epoch 17/100\n",
      "2086/2086 [==============================] - 21s 10ms/step - loss: 0.2776 - accuracy: 0.8895 - val_loss: 0.3698 - val_accuracy: 0.8689\n"
     ]
    }
   ],
   "source": [
    "model = lenet_model()\n",
    "model.compile(\n",
    "    optimizer=\"Adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "logs = \"logs/lenet_x4\"\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logs, histogram_freq=1, profile_batch=\"500,520\"\n",
    ")\n",
    "check_best_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath= \"lenet_x4_best.h5\", save_best_only=True\n",
    ")\n",
    "check_last_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath= \"lenet_x4_last.h5\", save_best_only=False\n",
    ")\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    x=X_train_resize,\n",
    "    y=y_train,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_valid_resize, y_valid),\n",
    "    epochs=100,\n",
    "    callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab3ad6e",
   "metadata": {},
   "source": [
    "# Baseline 1: MobilenetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80a331d",
   "metadata": {},
   "source": [
    "train & finetuning logs in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0701923f",
   "metadata": {},
   "source": [
    "best mobilenetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1383f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenetv2_model():\n",
    "    return keras.applications.MobileNetV2(\n",
    "        input_shape=(32, 32, 1),\n",
    "        alpha=1.0,\n",
    "        include_top=True,\n",
    "        weights=None,\n",
    "        input_tensor=None,\n",
    "        pooling=None,\n",
    "        classes=62,\n",
    "        classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1448800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8343/8343 [==============================] - 185s 22ms/step - loss: 0.6670 - accuracy: 0.7843 - val_loss: 6.4851 - val_accuracy: 0.5861\n",
      "Epoch 2/100\n",
      "8343/8343 [==============================] - 177s 21ms/step - loss: 0.4544 - accuracy: 0.8398 - val_loss: 0.5445 - val_accuracy: 0.8247\n",
      "Epoch 3/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.4108 - accuracy: 0.8511 - val_loss: 0.4380 - val_accuracy: 0.8413\n",
      "Epoch 4/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.3902 - accuracy: 0.8571 - val_loss: 0.4017 - val_accuracy: 0.8535\n",
      "Epoch 5/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.3749 - accuracy: 0.8619 - val_loss: 0.4055 - val_accuracy: 0.8543\n",
      "Epoch 6/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.3649 - accuracy: 0.8645 - val_loss: 0.3942 - val_accuracy: 0.8574\n",
      "Epoch 7/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.3585 - accuracy: 0.8663 - val_loss: 0.3681 - val_accuracy: 0.8646\n",
      "Epoch 8/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.3508 - accuracy: 0.8682 - val_loss: 0.3820 - val_accuracy: 0.8588\n",
      "Epoch 9/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.3448 - accuracy: 0.8702 - val_loss: 0.4075 - val_accuracy: 0.8524\n",
      "Epoch 10/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.3408 - accuracy: 0.8712 - val_loss: 0.3730 - val_accuracy: 0.8558\n",
      "Epoch 11/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.3362 - accuracy: 0.8727 - val_loss: 0.4147 - val_accuracy: 0.8477\n",
      "Epoch 12/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.3315 - accuracy: 0.8741 - val_loss: 0.3994 - val_accuracy: 0.8543\n",
      "Epoch 13/100\n",
      "8343/8343 [==============================] - 178s 21ms/step - loss: 0.3292 - accuracy: 0.8748 - val_loss: 0.4188 - val_accuracy: 0.8472\n",
      "Epoch 14/100\n",
      "8343/8343 [==============================] - 177s 21ms/step - loss: 0.3257 - accuracy: 0.8758 - val_loss: 0.3843 - val_accuracy: 0.8591\n",
      "Epoch 15/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.3227 - accuracy: 0.8770 - val_loss: 0.3497 - val_accuracy: 0.8694\n",
      "Epoch 16/100\n",
      "8343/8343 [==============================] - 177s 21ms/step - loss: 0.3200 - accuracy: 0.8776 - val_loss: 0.3442 - val_accuracy: 0.8700\n",
      "Epoch 17/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.3172 - accuracy: 0.8781 - val_loss: 0.3495 - val_accuracy: 0.8688\n",
      "Epoch 18/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.3163 - accuracy: 0.8789 - val_loss: 0.4032 - val_accuracy: 0.8543\n",
      "Epoch 19/100\n",
      "8343/8343 [==============================] - 177s 21ms/step - loss: 0.3126 - accuracy: 0.8799 - val_loss: 0.3562 - val_accuracy: 0.8695\n",
      "Epoch 20/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.3150 - accuracy: 0.8789 - val_loss: 0.3557 - val_accuracy: 0.8685\n",
      "Epoch 21/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.3096 - accuracy: 0.8809 - val_loss: 0.3482 - val_accuracy: 0.8711\n",
      "Epoch 22/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.3082 - accuracy: 0.8810 - val_loss: 0.3409 - val_accuracy: 0.8737\n",
      "Epoch 23/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.3074 - accuracy: 0.8814 - val_loss: 0.3490 - val_accuracy: 0.8704\n",
      "Epoch 24/100\n",
      "8343/8343 [==============================] - 177s 21ms/step - loss: 0.3061 - accuracy: 0.8816 - val_loss: 0.3554 - val_accuracy: 0.8670\n",
      "Epoch 25/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.3041 - accuracy: 0.8821 - val_loss: 0.3434 - val_accuracy: 0.8726\n",
      "Epoch 26/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.3025 - accuracy: 0.8826 - val_loss: 0.3445 - val_accuracy: 0.8736\n",
      "Epoch 27/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.3016 - accuracy: 0.8830 - val_loss: 0.3443 - val_accuracy: 0.8731\n",
      "Epoch 28/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.3013 - accuracy: 0.8832 - val_loss: 0.3510 - val_accuracy: 0.8713\n",
      "Epoch 29/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.3002 - accuracy: 0.8833 - val_loss: 0.3518 - val_accuracy: 0.8698\n",
      "Epoch 30/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.2987 - accuracy: 0.8838 - val_loss: 0.3530 - val_accuracy: 0.8700\n",
      "Epoch 31/100\n",
      "8343/8343 [==============================] - 176s 21ms/step - loss: 0.2969 - accuracy: 0.8846 - val_loss: 0.3606 - val_accuracy: 0.8690\n",
      "Epoch 32/100\n",
      "8343/8343 [==============================] - 177s 21ms/step - loss: 0.2941 - accuracy: 0.8852 - val_loss: 0.4046 - val_accuracy: 0.8739\n"
     ]
    }
   ],
   "source": [
    "model = mobilenetv2_model()\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "logs = \"logs/mobilenetv2_batch_64\"\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir = logs, histogram_freq = 1, profile_batch = \"500, 520\"\n",
    ")\n",
    "check_best_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = \"mobilenetv2_batch_64_best.h5\", save_best_only = True\n",
    ")\n",
    "check_last_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = \"mobilenetv2_batch_64_last.h5\", save_best_only = False\n",
    ")\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history = model.fit(\n",
    "    x=X_train_resize,\n",
    "    y=y_train,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_valid_resize, y_valid),\n",
    "    epochs = 100,\n",
    "    callbacks = [tboard_callback, check_best_cb, check_last_cb, earlystop_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bc49d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5126/5126 [==============================] - 52s 10ms/step - loss: 0.3409 - accuracy: 0.8737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3408726453781128, 0.8737493753433228]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilenetv2=keras.models.load_model(\"mobilenetv2_batch_64_best.h5\")\n",
    "mobilenetv2.evaluate(X_valid_resize, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd06e11",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5860aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n",
      "58900480/58889256 [==============================] - 1s 0us/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                31806     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,746,494\n",
      "Trainable params: 14,746,494\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#박민성, 황성현\n",
    "n_classes=62\n",
    "base_model = keras.applications.vgg16.VGG16(weights=\"imagenet\",\n",
    "                                                  include_top=False)\n",
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
    "model_vgg16 = keras.models.Model(inputs=base_model.input, outputs=output)\n",
    "model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6c5ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#박민성, 황성현\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model_vgg16.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "check_best_cb = tf.keras.callbacks.ModelCheckpoint(\"vgg16_best_nadam.h5\",save_best_only=True)\n",
    "check_last_cb = tf.keras.callbacks.ModelCheckpoint(\"vgg16_last_nadam.h5\",save_best_only=False)\n",
    "\n",
    "\n",
    "history = model_vgg16.fit(train_set,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=2,callbacks=[check_best_cb,check_last_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51be7cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#박민성, 황성현\n",
    "import datetime as dt\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "model_vgg16.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "logs = \"logs/\" + dt.datetime.now().strftime(\"VGG16%Y%m%d-%H%M%S\")\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "early_stop_cb=tf.keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
    "history = model_vgg16.fit(train_set,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=300,callbacks=[check_best_cb,check_last_cb,tboard_callback,early_stop_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37647a89",
   "metadata": {},
   "source": [
    "train VGG16 log in VGG16.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6493876e",
   "metadata": {},
   "source": [
    "# Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75c1a333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 2s 0us/step\n",
      "94781440/94765736 [==============================] - 2s 0us/step\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, None, None,   0           ['input_2[0][0]']                \n",
      "                                3)                                                                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, None, None,   9472        ['conv1_pad[0][0]']              \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, None, None,   256         ['conv1_conv[0][0]']             \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, None, None,   0           ['conv1_bn[0][0]']               \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, None, None,   0           ['conv1_relu[0][0]']             \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, None, None,   0           ['pool1_pad[0][0]']              \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, None, None,   4160        ['pool1_pool[0][0]']             \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, None, None,   256        ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, None, None,   0          ['conv2_block1_1_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, None, None,   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, None, None,   256        ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, None, None,   0          ['conv2_block1_2_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, None, None,   16640       ['pool1_pool[0][0]']             \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, None, None,   16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, None, None,   1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, None, None,   1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, None, None,   0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                256)                              'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, None, None,   0           ['conv2_block1_add[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, None, None,   16448       ['conv2_block1_out[0][0]']       \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, None, None,   256        ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, None, None,   0          ['conv2_block2_1_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, None, None,   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, None, None,   256        ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, None, None,   0          ['conv2_block2_2_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, None, None,   16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, None, None,   1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, None, None,   0           ['conv2_block1_out[0][0]',       \n",
      "                                256)                              'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, None, None,   0           ['conv2_block2_add[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, None, None,   16448       ['conv2_block2_out[0][0]']       \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, None, None,   256        ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, None, None,   0          ['conv2_block3_1_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, None, None,   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, None, None,   256        ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, None, None,   0          ['conv2_block3_2_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, None, None,   16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, None, None,   1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, None, None,   0           ['conv2_block2_out[0][0]',       \n",
      "                                256)                              'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, None, None,   0           ['conv2_block3_add[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, None, None,   32896       ['conv2_block3_out[0][0]']       \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, None, None,   0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, None, None,   147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, None, None,   0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, None, None,   131584      ['conv2_block3_out[0][0]']       \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, None, None,   2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, None, None,   2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, None, None,   0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                512)                              'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, None, None,   0           ['conv3_block1_add[0][0]']       \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, None, None,   65664       ['conv3_block1_out[0][0]']       \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, None, None,   0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, None, None,   147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, None, None,   0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, None, None,   2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, None, None,   0           ['conv3_block1_out[0][0]',       \n",
      "                                512)                              'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, None, None,   0           ['conv3_block2_add[0][0]']       \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, None, None,   65664       ['conv3_block2_out[0][0]']       \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, None, None,   0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, None, None,   147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, None, None,   0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, None, None,   2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, None, None,   0           ['conv3_block2_out[0][0]',       \n",
      "                                512)                              'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, None, None,   0           ['conv3_block3_add[0][0]']       \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, None, None,   65664       ['conv3_block3_out[0][0]']       \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, None, None,   0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, None, None,   147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, None, None,   0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, None, None,   2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, None, None,   0           ['conv3_block3_out[0][0]',       \n",
      "                                512)                              'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, None, None,   0           ['conv3_block4_add[0][0]']       \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, None, None,   131328      ['conv3_block4_out[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, None, None,   0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, None, None,   0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, None, None,   525312      ['conv3_block4_out[0][0]']       \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, None, None,   4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, None, None,   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                1024)                             'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, None, None,   0           ['conv4_block1_add[0][0]']       \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, None, None,   262400      ['conv4_block1_out[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, None, None,   0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, None, None,   0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, None, None,   0           ['conv4_block1_out[0][0]',       \n",
      "                                1024)                             'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, None, None,   0           ['conv4_block2_add[0][0]']       \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, None, None,   262400      ['conv4_block2_out[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, None, None,   0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, None, None,   0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, None, None,   0           ['conv4_block2_out[0][0]',       \n",
      "                                1024)                             'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, None, None,   0           ['conv4_block3_add[0][0]']       \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, None, None,   262400      ['conv4_block3_out[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, None, None,   0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, None, None,   0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, None, None,   0           ['conv4_block3_out[0][0]',       \n",
      "                                1024)                             'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, None, None,   0           ['conv4_block4_add[0][0]']       \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, None, None,   262400      ['conv4_block4_out[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, None, None,   0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, None, None,   0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, None, None,   0           ['conv4_block4_out[0][0]',       \n",
      "                                1024)                             'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, None, None,   0           ['conv4_block5_add[0][0]']       \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, None, None,   262400      ['conv4_block5_out[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, None, None,   0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, None, None,   590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, None, None,   0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, None, None,   4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, None, None,   0           ['conv4_block5_out[0][0]',       \n",
      "                                1024)                             'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, None, None,   0           ['conv4_block6_add[0][0]']       \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, None, None,   524800      ['conv4_block6_out[0][0]']       \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, None, None,   2048       ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, None, None,   0          ['conv5_block1_1_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, None, None,   2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, None, None,   2048       ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, None, None,   0          ['conv5_block1_2_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, None, None,   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, None, None,   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, None, None,   8192       ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                       2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, None, None,   8192       ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                       2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, None, None,   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                2048)                             'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, None, None,   0           ['conv5_block1_add[0][0]']       \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, None, None,   1049088     ['conv5_block1_out[0][0]']       \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, None, None,   2048       ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, None, None,   0          ['conv5_block2_1_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, None, None,   2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, None, None,   2048       ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, None, None,   0          ['conv5_block2_2_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, None, None,   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, None, None,   8192       ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                       2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, None, None,   0           ['conv5_block1_out[0][0]',       \n",
      "                                2048)                             'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, None, None,   0           ['conv5_block2_add[0][0]']       \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, None, None,   1049088     ['conv5_block2_out[0][0]']       \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, None, None,   2048       ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, None, None,   0          ['conv5_block3_1_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, None, None,   2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, None, None,   2048       ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, None, None,   0          ['conv5_block3_2_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, None, None,   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, None, None,   8192       ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                       2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, None, None,   0           ['conv5_block2_out[0][0]',       \n",
      "                                2048)                             'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, None, None,   0           ['conv5_block3_add[0][0]']       \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 62)           127038      ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,714,750\n",
      "Trainable params: 23,661,630\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#박민성, 황성현\n",
    "n_classes=62\n",
    "base_model = keras.applications.resnet50.ResNet50(weights=\"imagenet\",\n",
    "                                                  include_top=False)\n",
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
    "model_resnet50 = keras.models.Model(inputs=base_model.input, outputs=output)\n",
    "model_resnet50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85971119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#박민성, 황성현\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_resnet50.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "check_best_cb = tf.keras.callbacks.ModelCheckpoint(\"resnet50_best_nadam.h5\",save_best_only=True)\n",
    "check_last_cb = tf.keras.callbacks.ModelCheckpoint(\"resnet50_last_nadam.h5\",save_best_only=False)\n",
    "\n",
    "\n",
    "history = model_resnet50.fit(train_set,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=2,callbacks=[check_best_cb,check_last_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f9bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#박민성, 황성현\n",
    "import datetime as dt\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_resnet50.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "logs = \"logs/\" + dt.datetime.now().strftime(\"resnet50%Y%m%d-%H%M%S\")\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "\n",
    "early_stop_cb=tf.keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
    "\n",
    "history = model_resnet50.fit(train_set,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=300,callbacks=[check_best_cb,check_last_cb,tboard_callback,early_stop_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f823b516",
   "metadata": {},
   "source": [
    "train Resnet50 log in Resnet50.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24160ebb",
   "metadata": {},
   "source": [
    "# Inceptionv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ada52f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 1s 0us/step\n",
      "87924736/87910968 [==============================] - 1s 0us/step\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, None, None,   864         ['input_3[0][0]']                \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, None, None,   96         ['conv2d[0][0]']                 \n",
      " alization)                     32)                                                               \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, None, None,   0           ['batch_normalization[0][0]']    \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, None, None,   9216        ['activation[0][0]']             \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, None, None,   96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   32)                                                               \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, None, None,   0           ['batch_normalization_1[0][0]']  \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, None, None,   18432       ['activation_1[0][0]']           \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, None, None,   192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   64)                                                               \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, None, None,   0           ['batch_normalization_2[0][0]']  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, None, None,   0           ['activation_2[0][0]']           \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, None, None,   5120        ['max_pooling2d[0][0]']          \n",
      "                                80)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, None, None,   240        ['conv2d_3[0][0]']               \n",
      " rmalization)                   80)                                                               \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, None, None,   0           ['batch_normalization_3[0][0]']  \n",
      "                                80)                                                               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, None, None,   138240      ['activation_3[0][0]']           \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, None, None,   576        ['conv2d_4[0][0]']               \n",
      " rmalization)                   192)                                                              \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, None, None,   0           ['batch_normalization_4[0][0]']  \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, None, None,   0          ['activation_4[0][0]']           \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, None, None,   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, None, None,   192        ['conv2d_8[0][0]']               \n",
      " rmalization)                   64)                                                               \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, None, None,   0           ['batch_normalization_8[0][0]']  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, None, None,   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                48)                                                               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, None, None,   55296       ['activation_8[0][0]']           \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, None, None,   144        ['conv2d_6[0][0]']               \n",
      " rmalization)                   48)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, None, None,   288        ['conv2d_9[0][0]']               \n",
      " rmalization)                   96)                                                               \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, None, None,   0           ['batch_normalization_6[0][0]']  \n",
      "                                48)                                                               \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, None, None,   0           ['batch_normalization_9[0][0]']  \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, None, None,   0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                         192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, None, None,   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, None, None,   76800       ['activation_6[0][0]']           \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, None, None,   82944       ['activation_9[0][0]']           \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, None, None,   6144        ['average_pooling2d[0][0]']      \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, None, None,   192        ['conv2d_5[0][0]']               \n",
      " rmalization)                   64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, None, None,   192        ['conv2d_7[0][0]']               \n",
      " rmalization)                   64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, None, None,   288        ['conv2d_10[0][0]']              \n",
      " ormalization)                  96)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, None, None,   96         ['conv2d_11[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, None, None,   0           ['batch_normalization_5[0][0]']  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, None, None,   0           ['batch_normalization_7[0][0]']  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, None, None,   0           ['batch_normalization_10[0][0]'] \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, None, None,   0           ['batch_normalization_11[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, None, None,   0           ['activation_5[0][0]',           \n",
      "                                256)                              'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, None, None,   16384       ['mixed0[0][0]']                 \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, None, None,   192        ['conv2d_15[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, None, None,   0           ['batch_normalization_15[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, None, None,   12288       ['mixed0[0][0]']                 \n",
      "                                48)                                                               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, None, None,   55296       ['activation_15[0][0]']          \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, None, None,   144        ['conv2d_13[0][0]']              \n",
      " ormalization)                  48)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, None, None,   288        ['conv2d_16[0][0]']              \n",
      " ormalization)                  96)                                                               \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, None, None,   0           ['batch_normalization_13[0][0]'] \n",
      "                                48)                                                               \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, None, None,   0           ['batch_normalization_16[0][0]'] \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, None, None,   0          ['mixed0[0][0]']                 \n",
      " oling2D)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, None, None,   16384       ['mixed0[0][0]']                 \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, None, None,   76800       ['activation_13[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, None, None,   82944       ['activation_16[0][0]']          \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, None, None,   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, None, None,   192        ['conv2d_12[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, None, None,   192        ['conv2d_14[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, None, None,   288        ['conv2d_17[0][0]']              \n",
      " ormalization)                  96)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, None, None,   192        ['conv2d_18[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, None, None,   0           ['batch_normalization_12[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, None, None,   0           ['batch_normalization_14[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, None, None,   0           ['batch_normalization_17[0][0]'] \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, None, None,   0           ['batch_normalization_18[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, None, None,   0           ['activation_12[0][0]',          \n",
      "                                288)                              'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, None, None,   18432       ['mixed1[0][0]']                 \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, None, None,   192        ['conv2d_22[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, None, None,   0           ['batch_normalization_22[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, None, None,   13824       ['mixed1[0][0]']                 \n",
      "                                48)                                                               \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, None, None,   55296       ['activation_22[0][0]']          \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, None, None,   144        ['conv2d_20[0][0]']              \n",
      " ormalization)                  48)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, None, None,   288        ['conv2d_23[0][0]']              \n",
      " ormalization)                  96)                                                               \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, None, None,   0           ['batch_normalization_20[0][0]'] \n",
      "                                48)                                                               \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, None, None,   0           ['batch_normalization_23[0][0]'] \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, None, None,   0          ['mixed1[0][0]']                 \n",
      " oling2D)                       288)                                                              \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, None, None,   18432       ['mixed1[0][0]']                 \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, None, None,   76800       ['activation_20[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, None, None,   82944       ['activation_23[0][0]']          \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, None, None,   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, None, None,   192        ['conv2d_19[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, None, None,   192        ['conv2d_21[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, None, None,   288        ['conv2d_24[0][0]']              \n",
      " ormalization)                  96)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, None, None,   192        ['conv2d_25[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, None, None,   0           ['batch_normalization_19[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, None, None,   0           ['batch_normalization_21[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, None, None,   0           ['batch_normalization_24[0][0]'] \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, None, None,   0           ['batch_normalization_25[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, None, None,   0           ['activation_19[0][0]',          \n",
      "                                288)                              'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, None, None,   18432       ['mixed2[0][0]']                 \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, None, None,   192        ['conv2d_27[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, None, None,   0           ['batch_normalization_27[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, None, None,   55296       ['activation_27[0][0]']          \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, None, None,   288        ['conv2d_28[0][0]']              \n",
      " ormalization)                  96)                                                               \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, None, None,   0           ['batch_normalization_28[0][0]'] \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, None, None,   995328      ['mixed2[0][0]']                 \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, None, None,   82944       ['activation_28[0][0]']          \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, None, None,   1152       ['conv2d_26[0][0]']              \n",
      " ormalization)                  384)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, None, None,   288        ['conv2d_29[0][0]']              \n",
      " ormalization)                  96)                                                               \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, None, None,   0           ['batch_normalization_26[0][0]'] \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, None, None,   0           ['batch_normalization_29[0][0]'] \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, None, None,   0          ['mixed2[0][0]']                 \n",
      "                                288)                                                              \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, None, None,   0           ['activation_26[0][0]',          \n",
      "                                768)                              'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, None, None,   98304       ['mixed3[0][0]']                 \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, None, None,   384        ['conv2d_34[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, None, None,   0           ['batch_normalization_34[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, None, None,   114688      ['activation_34[0][0]']          \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, None, None,   384        ['conv2d_35[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, None, None,   0           ['batch_normalization_35[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, None, None,   98304       ['mixed3[0][0]']                 \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, None, None,   114688      ['activation_35[0][0]']          \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, None, None,   384        ['conv2d_31[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, None, None,   384        ['conv2d_36[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, None, None,   0           ['batch_normalization_31[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, None, None,   0           ['batch_normalization_36[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, None, None,   114688      ['activation_31[0][0]']          \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, None, None,   114688      ['activation_36[0][0]']          \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, None, None,   384        ['conv2d_32[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, None, None,   384        ['conv2d_37[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, None, None,   0           ['batch_normalization_32[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, None, None,   0           ['batch_normalization_37[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, None, None,   0          ['mixed3[0][0]']                 \n",
      " oling2D)                       768)                                                              \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, None, None,   147456      ['mixed3[0][0]']                 \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, None, None,   172032      ['activation_32[0][0]']          \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, None, None,   172032      ['activation_37[0][0]']          \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, None, None,   147456      ['average_pooling2d_3[0][0]']    \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, None, None,   576        ['conv2d_30[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, None, None,   576        ['conv2d_33[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, None, None,   576        ['conv2d_38[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, None, None,   576        ['conv2d_39[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, None, None,   0           ['batch_normalization_30[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, None, None,   0           ['batch_normalization_33[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, None, None,   0           ['batch_normalization_38[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, None, None,   0           ['batch_normalization_39[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, None, None,   0           ['activation_30[0][0]',          \n",
      "                                768)                              'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, None, None,   122880      ['mixed4[0][0]']                 \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, None, None,   480        ['conv2d_44[0][0]']              \n",
      " ormalization)                  160)                                                              \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, None, None,   0           ['batch_normalization_44[0][0]'] \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, None, None,   179200      ['activation_44[0][0]']          \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, None, None,   480        ['conv2d_45[0][0]']              \n",
      " ormalization)                  160)                                                              \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, None, None,   0           ['batch_normalization_45[0][0]'] \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, None, None,   122880      ['mixed4[0][0]']                 \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, None, None,   179200      ['activation_45[0][0]']          \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, None, None,   480        ['conv2d_41[0][0]']              \n",
      " ormalization)                  160)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, None, None,   480        ['conv2d_46[0][0]']              \n",
      " ormalization)                  160)                                                              \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, None, None,   0           ['batch_normalization_41[0][0]'] \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, None, None,   0           ['batch_normalization_46[0][0]'] \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, None, None,   179200      ['activation_41[0][0]']          \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, None, None,   179200      ['activation_46[0][0]']          \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, None, None,   480        ['conv2d_42[0][0]']              \n",
      " ormalization)                  160)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, None, None,   480        ['conv2d_47[0][0]']              \n",
      " ormalization)                  160)                                                              \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, None, None,   0           ['batch_normalization_42[0][0]'] \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, None, None,   0           ['batch_normalization_47[0][0]'] \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, None, None,   0          ['mixed4[0][0]']                 \n",
      " oling2D)                       768)                                                              \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, None, None,   147456      ['mixed4[0][0]']                 \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, None, None,   215040      ['activation_42[0][0]']          \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, None, None,   215040      ['activation_47[0][0]']          \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, None, None,   147456      ['average_pooling2d_4[0][0]']    \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, None, None,   576        ['conv2d_40[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, None, None,   576        ['conv2d_43[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, None, None,   576        ['conv2d_48[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, None, None,   576        ['conv2d_49[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, None, None,   0           ['batch_normalization_40[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, None, None,   0           ['batch_normalization_43[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, None, None,   0           ['batch_normalization_48[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, None, None,   0           ['batch_normalization_49[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, None, None,   0           ['activation_40[0][0]',          \n",
      "                                768)                              'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, None, None,   122880      ['mixed5[0][0]']                 \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, None, None,   480        ['conv2d_54[0][0]']              \n",
      " ormalization)                  160)                                                              \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, None, None,   0           ['batch_normalization_54[0][0]'] \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, None, None,   179200      ['activation_54[0][0]']          \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, None, None,   480        ['conv2d_55[0][0]']              \n",
      " ormalization)                  160)                                                              \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, None, None,   0           ['batch_normalization_55[0][0]'] \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, None, None,   122880      ['mixed5[0][0]']                 \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, None, None,   179200      ['activation_55[0][0]']          \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, None, None,   480        ['conv2d_51[0][0]']              \n",
      " ormalization)                  160)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, None, None,   480        ['conv2d_56[0][0]']              \n",
      " ormalization)                  160)                                                              \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, None, None,   0           ['batch_normalization_51[0][0]'] \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, None, None,   0           ['batch_normalization_56[0][0]'] \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, None, None,   179200      ['activation_51[0][0]']          \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, None, None,   179200      ['activation_56[0][0]']          \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, None, None,   480        ['conv2d_52[0][0]']              \n",
      " ormalization)                  160)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, None, None,   480        ['conv2d_57[0][0]']              \n",
      " ormalization)                  160)                                                              \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, None, None,   0           ['batch_normalization_52[0][0]'] \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, None, None,   0           ['batch_normalization_57[0][0]'] \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, None, None,   0          ['mixed5[0][0]']                 \n",
      " oling2D)                       768)                                                              \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, None, None,   147456      ['mixed5[0][0]']                 \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, None, None,   215040      ['activation_52[0][0]']          \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, None, None,   215040      ['activation_57[0][0]']          \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, None, None,   147456      ['average_pooling2d_5[0][0]']    \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, None, None,   576        ['conv2d_50[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, None, None,   576        ['conv2d_53[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, None, None,   576        ['conv2d_58[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, None, None,   576        ['conv2d_59[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, None, None,   0           ['batch_normalization_50[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, None, None,   0           ['batch_normalization_53[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, None, None,   0           ['batch_normalization_58[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, None, None,   0           ['batch_normalization_59[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, None, None,   0           ['activation_50[0][0]',          \n",
      "                                768)                              'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, None, None,   147456      ['mixed6[0][0]']                 \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, None, None,   576        ['conv2d_64[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, None, None,   0           ['batch_normalization_64[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, None, None,   258048      ['activation_64[0][0]']          \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, None, None,   576        ['conv2d_65[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, None, None,   0           ['batch_normalization_65[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, None, None,   147456      ['mixed6[0][0]']                 \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, None, None,   258048      ['activation_65[0][0]']          \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, None, None,   576        ['conv2d_61[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, None, None,   576        ['conv2d_66[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, None, None,   0           ['batch_normalization_61[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, None, None,   0           ['batch_normalization_66[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, None, None,   258048      ['activation_61[0][0]']          \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, None, None,   258048      ['activation_66[0][0]']          \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, None, None,   576        ['conv2d_62[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, None, None,   576        ['conv2d_67[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, None, None,   0           ['batch_normalization_62[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, None, None,   0           ['batch_normalization_67[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, None, None,   0          ['mixed6[0][0]']                 \n",
      " oling2D)                       768)                                                              \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, None, None,   147456      ['mixed6[0][0]']                 \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, None, None,   258048      ['activation_62[0][0]']          \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, None, None,   258048      ['activation_67[0][0]']          \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, None, None,   147456      ['average_pooling2d_6[0][0]']    \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, None, None,   576        ['conv2d_60[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, None, None,   576        ['conv2d_63[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, None, None,   576        ['conv2d_68[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, None, None,   576        ['conv2d_69[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, None, None,   0           ['batch_normalization_60[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, None, None,   0           ['batch_normalization_63[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, None, None,   0           ['batch_normalization_68[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, None, None,   0           ['batch_normalization_69[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, None, None,   0           ['activation_60[0][0]',          \n",
      "                                768)                              'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, None, None,   147456      ['mixed7[0][0]']                 \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, None, None,   576        ['conv2d_72[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, None, None,   0           ['batch_normalization_72[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, None, None,   258048      ['activation_72[0][0]']          \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, None, None,   576        ['conv2d_73[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, None, None,   0           ['batch_normalization_73[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, None, None,   147456      ['mixed7[0][0]']                 \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, None, None,   258048      ['activation_73[0][0]']          \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, None, None,   576        ['conv2d_70[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, None, None,   576        ['conv2d_74[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, None, None,   0           ['batch_normalization_70[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, None, None,   0           ['batch_normalization_74[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, None, None,   552960      ['activation_70[0][0]']          \n",
      "                                320)                                                              \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, None, None,   331776      ['activation_74[0][0]']          \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, None, None,   960        ['conv2d_71[0][0]']              \n",
      " ormalization)                  320)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, None, None,   576        ['conv2d_75[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, None, None,   0           ['batch_normalization_71[0][0]'] \n",
      "                                320)                                                              \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, None, None,   0           ['batch_normalization_75[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, None, None,   0          ['mixed7[0][0]']                 \n",
      "                                768)                                                              \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, None, None,   0           ['activation_71[0][0]',          \n",
      "                                1280)                             'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, None, None,   573440      ['mixed8[0][0]']                 \n",
      "                                448)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, None, None,   1344       ['conv2d_80[0][0]']              \n",
      " ormalization)                  448)                                                              \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, None, None,   0           ['batch_normalization_80[0][0]'] \n",
      "                                448)                                                              \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, None, None,   491520      ['mixed8[0][0]']                 \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, None, None,   1548288     ['activation_80[0][0]']          \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, None, None,   1152       ['conv2d_77[0][0]']              \n",
      " ormalization)                  384)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, None, None,   1152       ['conv2d_81[0][0]']              \n",
      " ormalization)                  384)                                                              \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, None, None,   0           ['batch_normalization_77[0][0]'] \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, None, None,   0           ['batch_normalization_81[0][0]'] \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, None, None,   442368      ['activation_77[0][0]']          \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, None, None,   442368      ['activation_77[0][0]']          \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, None, None,   442368      ['activation_81[0][0]']          \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, None, None,   442368      ['activation_81[0][0]']          \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, None, None,   0          ['mixed8[0][0]']                 \n",
      " oling2D)                       1280)                                                             \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, None, None,   409600      ['mixed8[0][0]']                 \n",
      "                                320)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, None, None,   1152       ['conv2d_78[0][0]']              \n",
      " ormalization)                  384)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, None, None,   1152       ['conv2d_79[0][0]']              \n",
      " ormalization)                  384)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, None, None,   1152       ['conv2d_82[0][0]']              \n",
      " ormalization)                  384)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, None, None,   1152       ['conv2d_83[0][0]']              \n",
      " ormalization)                  384)                                                              \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, None, None,   245760      ['average_pooling2d_7[0][0]']    \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, None, None,   960        ['conv2d_76[0][0]']              \n",
      " ormalization)                  320)                                                              \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, None, None,   0           ['batch_normalization_78[0][0]'] \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, None, None,   0           ['batch_normalization_79[0][0]'] \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, None, None,   0           ['batch_normalization_82[0][0]'] \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, None, None,   0           ['batch_normalization_83[0][0]'] \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, None, None,   576        ['conv2d_84[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, None, None,   0           ['batch_normalization_76[0][0]'] \n",
      "                                320)                                                              \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, None, None,   0           ['activation_78[0][0]',          \n",
      "                                768)                              'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, None, None,   0           ['activation_82[0][0]',          \n",
      "                                768)                              'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, None, None,   0           ['batch_normalization_84[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, None, None,   0           ['activation_76[0][0]',          \n",
      "                                2048)                             'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, None, None,   917504      ['mixed9[0][0]']                 \n",
      "                                448)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, None, None,   1344       ['conv2d_89[0][0]']              \n",
      " ormalization)                  448)                                                              \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, None, None,   0           ['batch_normalization_89[0][0]'] \n",
      "                                448)                                                              \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, None, None,   786432      ['mixed9[0][0]']                 \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, None, None,   1548288     ['activation_89[0][0]']          \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, None, None,   1152       ['conv2d_86[0][0]']              \n",
      " ormalization)                  384)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, None, None,   1152       ['conv2d_90[0][0]']              \n",
      " ormalization)                  384)                                                              \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, None, None,   0           ['batch_normalization_86[0][0]'] \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, None, None,   0           ['batch_normalization_90[0][0]'] \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, None, None,   442368      ['activation_86[0][0]']          \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, None, None,   442368      ['activation_86[0][0]']          \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, None, None,   442368      ['activation_90[0][0]']          \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, None, None,   442368      ['activation_90[0][0]']          \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, None, None,   0          ['mixed9[0][0]']                 \n",
      " oling2D)                       2048)                                                             \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, None, None,   655360      ['mixed9[0][0]']                 \n",
      "                                320)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, None, None,   1152       ['conv2d_87[0][0]']              \n",
      " ormalization)                  384)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, None, None,   1152       ['conv2d_88[0][0]']              \n",
      " ormalization)                  384)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, None, None,   1152       ['conv2d_91[0][0]']              \n",
      " ormalization)                  384)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, None, None,   1152       ['conv2d_92[0][0]']              \n",
      " ormalization)                  384)                                                              \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, None, None,   393216      ['average_pooling2d_8[0][0]']    \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, None, None,   960        ['conv2d_85[0][0]']              \n",
      " ormalization)                  320)                                                              \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, None, None,   0           ['batch_normalization_87[0][0]'] \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, None, None,   0           ['batch_normalization_88[0][0]'] \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, None, None,   0           ['batch_normalization_91[0][0]'] \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, None, None,   0           ['batch_normalization_92[0][0]'] \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, None, None,   576        ['conv2d_93[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, None, None,   0           ['batch_normalization_85[0][0]'] \n",
      "                                320)                                                              \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, None, None,   0           ['activation_87[0][0]',          \n",
      "                                768)                              'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, None, None,   0           ['activation_91[0][0]',          \n",
      "                                768)                              'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, None, None,   0           ['batch_normalization_93[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, None, None,   0           ['activation_85[0][0]',          \n",
      "                                2048)                             'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 2048)        0           ['mixed10[0][0]']                \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 62)           127038      ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,929,822\n",
      "Trainable params: 21,895,390\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#박민성, 황성현\n",
    "n_classes=62\n",
    "base_model=tf.keras.applications.inception_v3.InceptionV3(weights='imagenet', include_top=False)\n",
    "avg=tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output=keras.layers.Dense(n_classes, activation='softmax')(avg)\n",
    "model_inceptionv3=keras.models.Model(inputs=base_model.input, outputs=output)\n",
    "model_inceptionv3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fc4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#박민성, 황성현\n",
    "for layer in base_model.layers:\n",
    "\n",
    "    layer.trainable = False\n",
    "\n",
    "model_inceptionv3.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    " \n",
    "\n",
    "check_best_cb = tf.keras.callbacks.ModelCheckpoint(\"inceptionv3_best_nadam.h5\",save_best_only=True)\n",
    "\n",
    "check_last_cb = tf.keras.callbacks.ModelCheckpoint(\"inceptionv3_last_nadam.h5\",save_best_only=False)\n",
    "\n",
    " \n",
    "\n",
    "history = model_inceptionv3.fit(train_set,\n",
    "\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "\n",
    "                    validation_data=valid_set,\n",
    "\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "\n",
    "                    epochs=2,callbacks=[check_best_cb,check_last_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9e5417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#박민성, 황성현\n",
    "import datetime as dt\n",
    "\n",
    "for layer in base_model.layers:\n",
    "\n",
    "    layer.trainable = True\n",
    "\n",
    "model_inceptionv3.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    " \n",
    "\n",
    "check_best_cb = tf.keras.callbacks.ModelCheckpoint(\"inceptionv3_best_nadam.h5\",save_best_only=True)\n",
    "\n",
    "check_last_cb = tf.keras.callbacks.ModelCheckpoint(\"inceptionv3_last_nadam.h5\",save_best_only=False)\n",
    "\n",
    "logs = \"logs/\" + dt.datetime.now().strftime(\"inceptionv3%Y%m%d-%H%M%S\")\n",
    "\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "\n",
    "                                                 histogram_freq = 1,\n",
    "\n",
    "                                                 profile_batch = '500,520')\n",
    "\n",
    "early_stop_cb=tf.keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
    " \n",
    "\n",
    "history = model_inceptionv3.fit(train_set,\n",
    "\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "\n",
    "                    validation_data=valid_set,\n",
    "\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "\n",
    "                    epochs=300,callbacks=[check_best_cb,check_last_cb,tboard_callback,early_stop_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817244dd",
   "metadata": {},
   "source": [
    "train inceptionv3 log in Inception.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6dbdfb",
   "metadata": {},
   "source": [
    "# SMV2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ab46622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "class Inveted_Residual_Block(keras.layers.Layer):\n",
    "    def __init__(self,c,s=1,t=1,n=1,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.layers.ReLU(max_value=6)\n",
    "        self.main_layers = [\n",
    "            \n",
    "            ]\n",
    "        self.strides_layers=[\n",
    "           ]\n",
    "        self.s=s\n",
    "        self.t=t\n",
    "        self.c=c\n",
    "        self.n=n\n",
    "        \n",
    "    def build(self,batch_input_shape):\n",
    "        print(self.name,\": batch_input_shape =\",batch_input_shape)\n",
    "        \n",
    "        self.main_layers = [\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=batch_input_shape[-1]*self.t, kernel_size=1,strides=1, \n",
    "                                padding=\"SAME\", activation=self.activation),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.DepthwiseConv2D(kernel_size=3, strides=1,padding=\"SAME\", activation=self.activation),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=self.c,kernel_size=1, strides=1,padding=\"SAME\",activation=self.activation),\n",
    "            ]\n",
    "        self.strides_layers=[\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=batch_input_shape[-1]*self.t, kernel_size=1,strides=1,\n",
    "                                padding=\"SAME\", activation=self.activation),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.DepthwiseConv2D(kernel_size=3, strides=self.s,padding=\"SAME\",activation=self.activation),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=self.c, kernel_size=1,strides=1,padding=\"SAME\",activation=self.activation),\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        \n",
    "        for n in range(0,self.n):\n",
    "            if n == 0:\n",
    "                for layer in self.strides_layers:\n",
    "                    Z = layer(Z)\n",
    "            else:\n",
    "                skip_Z = Z\n",
    "                for layer in self.main_layers:\n",
    "                    Z = layer(Z)\n",
    "                \n",
    "                Z += skip_Z\n",
    "    \n",
    "        return Z\n",
    "    \n",
    "    def get_config(self):\n",
    "        base=super().get_config()\n",
    "        return{**base,\"s\":self.s,\"t\":self.t,\"c\":self.c,\"n\":self.n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab0065d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 112, 112, 32)\n",
      "IRB2 : batch_input_shape = (None, 112, 112, 16)\n",
      "IRB3 : batch_input_shape = (None, 56, 56, 16)\n",
      "IRB4 : batch_input_shape = (None, 28, 28, 32)\n",
      "IRB5 : batch_input_shape = (None, 14, 14, 64)\n",
      "IRB6 : batch_input_shape = (None, 7, 7, 128)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (None, 224, 224, 3)      12        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 112, 112, 32)      896       \n",
      "                                                                 \n",
      " IRB1 (Inveted_Residual_Bloc  (None, 112, 112, 16)     2288      \n",
      " k)                                                              \n",
      "                                                                 \n",
      " IRB2 (Inveted_Residual_Bloc  (None, 56, 56, 16)       6688      \n",
      " k)                                                              \n",
      "                                                                 \n",
      " IRB3 (Inveted_Residual_Bloc  (None, 28, 28, 32)       19456     \n",
      " k)                                                              \n",
      "                                                                 \n",
      " IRB4 (Inveted_Residual_Bloc  (None, 14, 14, 64)       67584     \n",
      " k)                                                              \n",
      "                                                                 \n",
      " IRB5 (Inveted_Residual_Bloc  (None, 7, 7, 128)        108416    \n",
      " k)                                                              \n",
      "                                                                 \n",
      " IRB6 (Inveted_Residual_Bloc  (None, 7, 7, 1024)       1200640   \n",
      " k)                                                              \n",
      "                                                                 \n",
      " re_lu_6 (ReLU)              (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1024)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                63550     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,473,626\n",
      "Trainable params: 1,460,916\n",
      "Non-trainable params: 12,710\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#황성현\n",
    "n_classes=62\n",
    "smv2_l=keras.models.Sequential([\n",
    "    keras.layers.BatchNormalization(input_shape=[224,224,3]),\n",
    "    keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "    Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "    Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "    Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "    Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "    Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "    Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "    keras.layers.ReLU(max_value=6),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "])\n",
    "smv2_l.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a055f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711927c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L%Y%m%d-%H%M%S\")\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_last.h5\",save_best_only=True)\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_best.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_l.fit(train_set, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_last_cb,check_best_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa49e8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 112, 112, 32)\n",
      "IRB2 : batch_input_shape = (None, 112, 112, 16)\n",
      "IRB3 : batch_input_shape = (None, 56, 56, 16)\n",
      "IRB4 : batch_input_shape = (None, 28, 28, 32)\n",
      "IRB5 : batch_input_shape = (None, 14, 14, 64)\n",
      "IRB6 : batch_input_shape = (None, 7, 7, 128)\n"
     ]
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_nadam_last.h5a\",custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "696ed3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14f52a96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "41552/41552 [==============================] - 8762s 211ms/step - loss: 0.3231 - accuracy: 0.8801 - val_loss: 1.0675 - val_accuracy: 0.7649\n",
      "Epoch 2/300\n",
      "41552/41552 [==============================] - 8739s 210ms/step - loss: 0.2940 - accuracy: 0.8895 - val_loss: 11.2437 - val_accuracy: 0.1270\n",
      "Epoch 3/300\n",
      "41552/41552 [==============================] - 8779s 211ms/step - loss: 0.3131 - accuracy: 0.8817 - val_loss: 1.6895 - val_accuracy: 0.7141 accuracy\n",
      "Epoch 4/300\n",
      "41552/41552 [==============================] - 8815s 212ms/step - loss: 0.3288 - accuracy: 0.8782 - val_loss: 4.8713 - val_accuracy: 0.3668\n",
      "Epoch 5/300\n",
      "41552/41552 [==============================] - 8759s 211ms/step - loss: 0.3198 - accuracy: 0.8804 - val_loss: 1.4416 - val_accuracy: 0.7255los\n",
      "Epoch 6/300\n",
      "41552/41552 [==============================] - 8648s 208ms/step - loss: 1.6377 - accuracy: 0.5769 - val_loss: 98.7684 - val_accuracy: 0.0070\n",
      "Epoch 7/300\n",
      "41552/41552 [==============================] - 8648s 208ms/step - loss: 3.8695 - accuracy: 0.0604 - val_loss: 41.4147 - val_accuracy: 0.0201\n",
      "Epoch 8/300\n",
      "41552/41552 [==============================] - 8653s 208ms/step - loss: 3.8593 - accuracy: 0.0611 - val_loss: 5.2386 - val_accuracy: 0.0071\n",
      "Epoch 9/300\n",
      "41552/41552 [==============================] - 8761s 211ms/step - loss: 3.8256 - accuracy: 0.0591 - val_loss: 30.9823 - val_accuracy: 0.0499\n",
      "Epoch 10/300\n",
      "41552/41552 [==============================] - 8610s 207ms/step - loss: 3.8618 - accuracy: 0.0583 - val_loss: 4.0457 - val_accuracy: 0.0360\n",
      "Epoch 11/300\n",
      "41552/41552 [==============================] - 8702s 209ms/step - loss: 3.8083 - accuracy: 0.0589 - val_loss: 8.1110 - val_accuracy: 0.0034\n"
     ]
    }
   ],
   "source": [
    "#황성현\n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L%Y%m%d-%H%M%S\")\n",
    "logs=\"logs/SMV2L20220525-150153\"\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_last.h5\",save_best_only=True)\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_best2.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_l.fit(train_set, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_last_cb,check_best_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7a7c0c",
   "metadata": {},
   "source": [
    "# SMV2P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e896dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "with strategy.scope():\n",
    "    n_classes=62\n",
    "    smv2_p=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[224,224,3]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=32,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_p.summary()\n",
    "    smv2_p.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1dc93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 \n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2P%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2p_nadam_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2p_nadam_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_p.fit(train_set, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac956cb1",
   "metadata": {},
   "source": [
    "train SMV2P log in SMV2P&SMV2B.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e221c85",
   "metadata": {},
   "source": [
    "# SMV2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbe4db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "\n",
    "with strategy.scope():\n",
    "    n_classes=62\n",
    "    smv2_b=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[224,224,3]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=24,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=48,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_b.summary()\n",
    "    smv2_b.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                   optimizer=\"nadam\",\n",
    "                   metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ece3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 \n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2B%Y%m%d-%H%M%S\")\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2b_nadam_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2b_nadam_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "#cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "\n",
    "history=smv2_b.fit(train_set, batch_size = batch_size,\n",
    "                    steps_per_epoch=int(train_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(valid_size / batch_size),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4960928d",
   "metadata": {},
   "source": [
    "train SMV2B log in SMV2P&SMV2B.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ace1afc",
   "metadata": {},
   "source": [
    "# Select the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff156d",
   "metadata": {},
   "source": [
    "# SMV2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de5832e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 112, 112, 32)\n",
      "IRB2 : batch_input_shape = (None, 112, 112, 16)\n",
      "IRB3 : batch_input_shape = (None, 56, 56, 16)\n",
      "IRB4 : batch_input_shape = (None, 28, 28, 32)\n",
      "IRB5 : batch_input_shape = (None, 14, 14, 64)\n",
      "IRB6 : batch_input_shape = (None, 7, 7, 128)\n"
     ]
    }
   ],
   "source": [
    "#황성현 \n",
    "smv2l=keras.models.load_model(\"smv2l_nadam_last.h5\",custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52326618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5125/5125 [==============================] - 136s 26ms/step - loss: 1.0651 - accuracy: 0.7656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.065091848373413, 0.7656341195106506]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현 \n",
    "smv2l.evaluate(valid_set,steps=int(valid_size / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0826be",
   "metadata": {},
   "source": [
    "# SMV2P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4473204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 112, 112, 32)\n",
      "IRB2 : batch_input_shape = (None, 112, 112, 16)\n",
      "IRB3 : batch_input_shape = (None, 56, 56, 32)\n",
      "IRB4 : batch_input_shape = (None, 28, 28, 64)\n",
      "IRB5 : batch_input_shape = (None, 14, 14, 64)\n",
      "IRB6 : batch_input_shape = (None, 7, 7, 128)\n"
     ]
    }
   ],
   "source": [
    "#황성현 \n",
    "smv2p=keras.models.load_model(\"smv2p_nadam_best.h5\",custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53598402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5125/5125 [==============================] - 149s 28ms/step - loss: 1.3054 - accuracy: 0.7546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.305375337600708, 0.7546097636222839]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현 \n",
    "smv2p.evaluate(valid_set,steps=int(valid_size / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4f9866",
   "metadata": {},
   "source": [
    "# SMV2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e37bae2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 112, 112, 32)\n",
      "IRB2 : batch_input_shape = (None, 112, 112, 16)\n",
      "IRB3 : batch_input_shape = (None, 56, 56, 24)\n",
      "IRB4 : batch_input_shape = (None, 28, 28, 48)\n",
      "IRB5 : batch_input_shape = (None, 14, 14, 64)\n",
      "IRB6 : batch_input_shape = (None, 7, 7, 128)\n"
     ]
    }
   ],
   "source": [
    "#황성현 \n",
    "mv2b=keras.models.load_model(\"smv2b_nadam_best.h5\",custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f4819bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5125/5125 [==============================] - 158s 30ms/step - loss: 1.8271 - accuracy: 0.6875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.827067255973816, 0.6874512434005737]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현 \n",
    "smv2b.evaluate(valid_set,steps=int(valid_size / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dde535e",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b626d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 \n",
    "vgg16=keras.models.load_model(\"vgg16_best_nadam.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d1f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_set = csv_reader_dataset(valid_filepaths, model_name = eModelName.vgg16 , \n",
    "                               batch_size=batch_size, repeat=None, randomize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a2846d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5125/5125 [==============================] - 512s 99ms/step - loss: 2.1865 - accuracy: 0.6587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.1864590644836426, 0.6587256193161011]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현 \n",
    "vgg16.evaluate(valid_set,steps=int(valid_size / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40830040",
   "metadata": {},
   "source": [
    "# Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "591d75fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 \n",
    "resnet50=keras.models.load_model(\"resnet50_best_nadam.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a080115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50\n"
     ]
    }
   ],
   "source": [
    "#황성현 \n",
    "valid_set = csv_reader_dataset(valid_filepaths, model_name = eModelName.resnet50, \n",
    "                               batch_size=batch_size, repeat=None, randomize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1fc4540d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5125/5125 [==============================] - 348s 68ms/step - loss: 4.4647 - accuracy: 0.5483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.464682579040527, 0.5483048558235168]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#황성현 \n",
    "resnet50.evaluate(valid_set,steps=int(valid_size / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1d89fe",
   "metadata": {},
   "source": [
    "# InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b51c097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 \n",
    "inceptionv3=keras.models.load_model(\"inceptionv3_best_nadam.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8445acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_set = csv_reader_dataset(valid_filepaths, model_name = eModelName.inception_v3  , \n",
    "                               batch_size=batch_size, repeat=None, randomize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8bfc573f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5125/5125 [==============================] - 236s 46ms/step - loss: 3.1794 - accuracy: 0.6305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.1794281005859375, 0.6305426955223083]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inceptionv3.evaluate(valid_set,steps=int(valid_size / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e687b9af",
   "metadata": {},
   "source": [
    "# Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6c73d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xception=keras.models.load_model(\"xception_best_nadam.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b1e3aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xception\n"
     ]
    }
   ],
   "source": [
    "valid_set = csv_reader_dataset(valid_filepaths, model_name = eModelName.xception, \n",
    "                               batch_size=batch_size, repeat=None, randomize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfc87007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5125/5125 [==============================] - 375s 72ms/step - loss: 4.9617 - accuracy: 0.5064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.961658954620361, 0.5064146518707275]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xception.evaluate(valid_set,steps=int(valid_size / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda9abf7",
   "metadata": {},
   "source": [
    "in validation set, SMV2L has 26ms/step inferance time and  0.7656 accuracy,\n",
    "SMV2P has 28ms/step inferance time and 0.7546 accuracy\n",
    "SMV2L is best, SMV2P is second"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d037c3",
   "metadata": {},
   "source": [
    "we find that [224,224,3] input size very big, so we change input size to [32,32,1], delete data augmentation, and train on two model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2abd33",
   "metadata": {},
   "source": [
    "# MobilenetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b79f826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5126/5126 [==============================] - 38s 7ms/step - loss: 0.3409 - accuracy: 0.8737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3408726155757904, 0.8737493753433228]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilenetv2=keras.models.load_model(\"mobilenetv2_batch_64_best.h5\")\n",
    "mobilenetv2.evaluate(X_valid_resize, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098e08e0",
   "metadata": {},
   "source": [
    "# Lenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d561149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5126/5126 [==============================] - 12s 2ms/step - loss: 0.3529 - accuracy: 0.8692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35291048884391785, 0.8691887855529785]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet=keras.models.load_model(\"lenet_x4_best.h5\")\n",
    "lenet.evaluate(X_valid_resize, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9582a03e",
   "metadata": {},
   "source": [
    "# SMV2P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0b24845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 32)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 64)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_5 (Batch (None, 32, 32, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 32)        320       \n",
      "_________________________________________________________________\n",
      "IRB1 (Inveted_Residual_Block (None, 16, 16, 16)        2288      \n",
      "_________________________________________________________________\n",
      "IRB2 (Inveted_Residual_Block (None, 8, 8, 32)          9856      \n",
      "_________________________________________________________________\n",
      "IRB3 (Inveted_Residual_Block (None, 4, 4, 64)          67584     \n",
      "_________________________________________________________________\n",
      "IRB4 (Inveted_Residual_Block (None, 2, 2, 64)          151168    \n",
      "_________________________________________________________________\n",
      "IRB5 (Inveted_Residual_Block (None, 1, 1, 128)         108416    \n",
      "_________________________________________________________________\n",
      "IRB6 (Inveted_Residual_Block (None, 1, 1, 1024)        1200640   \n",
      "_________________________________________________________________\n",
      "re_lu_20 (ReLU)              (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 62)                63550     \n",
      "=================================================================\n",
      "Total params: 1,607,922\n",
      "Trainable params: 1,591,952\n",
      "Non-trainable params: 15,970\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#황성현\n",
    "with strategy.scope():\n",
    "    n_classes=62\n",
    "    smv2_p=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=32,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_p.summary()\n",
    "    smv2_p.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77357fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/SMV2P_NP20220603-203609\n",
      "Epoch 1/300\n",
      "INFO:tensorflow:batch_all_reduce: 116 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 116 all-reduces with algorithm = nccl, num_packs = 1\n",
      "16685/16685 [==============================] - 593s 34ms/step - loss: 0.7839 - accuracy: 0.7547 - val_loss: 0.4886 - val_accuracy: 0.8305\n",
      "Epoch 2/300\n",
      "16685/16685 [==============================] - 564s 34ms/step - loss: 0.4895 - accuracy: 0.8291 - val_loss: 0.4362 - val_accuracy: 0.8448\n",
      "Epoch 3/300\n",
      "16685/16685 [==============================] - 565s 34ms/step - loss: 0.4553 - accuracy: 0.8392 - val_loss: 0.4216 - val_accuracy: 0.8449\n",
      "Epoch 4/300\n",
      "16685/16685 [==============================] - 565s 34ms/step - loss: 0.4368 - accuracy: 0.8446 - val_loss: 0.4119 - val_accuracy: 0.8510\n",
      "Epoch 5/300\n",
      "16685/16685 [==============================] - 564s 34ms/step - loss: 0.4271 - accuracy: 0.8471 - val_loss: 0.4103 - val_accuracy: 0.8519\n",
      "Epoch 6/300\n",
      "16685/16685 [==============================] - 565s 34ms/step - loss: 0.4201 - accuracy: 0.8492 - val_loss: 0.4070 - val_accuracy: 0.8523\n",
      "Epoch 7/300\n",
      "16685/16685 [==============================] - 564s 34ms/step - loss: 0.4185 - accuracy: 0.8496 - val_loss: 0.4009 - val_accuracy: 0.8524\n",
      "Epoch 8/300\n",
      "16685/16685 [==============================] - 565s 34ms/step - loss: 0.4138 - accuracy: 0.8508 - val_loss: 0.4027 - val_accuracy: 0.8547\n",
      "Epoch 9/300\n",
      "16685/16685 [==============================] - 564s 34ms/step - loss: 0.4110 - accuracy: 0.8515 - val_loss: 0.3973 - val_accuracy: 0.8554\n",
      "Epoch 10/300\n",
      "16685/16685 [==============================] - 563s 34ms/step - loss: 0.4078 - accuracy: 0.8527 - val_loss: 0.4021 - val_accuracy: 0.8544\n",
      "Epoch 11/300\n",
      "16685/16685 [==============================] - 563s 34ms/step - loss: 0.4059 - accuracy: 0.8530 - val_loss: 0.3970 - val_accuracy: 0.8554\n",
      "Epoch 12/300\n",
      "16685/16685 [==============================] - 568s 34ms/step - loss: 0.4075 - accuracy: 0.8529 - val_loss: 0.4051 - val_accuracy: 0.8530\n",
      "Epoch 13/300\n",
      "16685/16685 [==============================] - 563s 34ms/step - loss: 0.4053 - accuracy: 0.8534 - val_loss: 0.3936 - val_accuracy: 0.8569\n",
      "Epoch 14/300\n",
      "16685/16685 [==============================] - 563s 34ms/step - loss: 0.4038 - accuracy: 0.8540 - val_loss: 0.3902 - val_accuracy: 0.8575\n",
      "Epoch 15/300\n",
      "16685/16685 [==============================] - 564s 34ms/step - loss: 0.4012 - accuracy: 0.8545 - val_loss: 0.3903 - val_accuracy: 0.8580\n",
      "Epoch 16/300\n",
      "16685/16685 [==============================] - 564s 34ms/step - loss: 0.4003 - accuracy: 0.8549 - val_loss: 0.3900 - val_accuracy: 0.8577\n",
      "Epoch 17/300\n",
      "16685/16685 [==============================] - 563s 34ms/step - loss: 0.4020 - accuracy: 0.8547 - val_loss: 0.3916 - val_accuracy: 0.8566\n",
      "Epoch 18/300\n",
      "16685/16685 [==============================] - 563s 34ms/step - loss: 0.4016 - accuracy: 0.8547 - val_loss: 0.3918 - val_accuracy: 0.8572\n",
      "Epoch 19/300\n",
      "16685/16685 [==============================] - 562s 34ms/step - loss: 0.3996 - accuracy: 0.8554 - val_loss: 0.3873 - val_accuracy: 0.8581\n",
      "Epoch 20/300\n",
      "16685/16685 [==============================] - 562s 34ms/step - loss: 0.3996 - accuracy: 0.8553 - val_loss: 0.3951 - val_accuracy: 0.8546\n",
      "Epoch 21/300\n",
      "16685/16685 [==============================] - 561s 34ms/step - loss: 0.4038 - accuracy: 0.8543 - val_loss: 0.4342 - val_accuracy: 0.8509\n",
      "Epoch 22/300\n",
      "16685/16685 [==============================] - 561s 34ms/step - loss: 0.4038 - accuracy: 0.8539 - val_loss: 0.4424 - val_accuracy: 0.8520\n",
      "Epoch 23/300\n",
      "16685/16685 [==============================] - 561s 34ms/step - loss: 0.4058 - accuracy: 0.8534 - val_loss: 0.4052 - val_accuracy: 0.8529\n",
      "Epoch 24/300\n",
      "16685/16685 [==============================] - 560s 34ms/step - loss: 0.4070 - accuracy: 0.8534 - val_loss: 0.4014 - val_accuracy: 0.8549\n",
      "Epoch 25/300\n",
      "16685/16685 [==============================] - 559s 34ms/step - loss: 0.4047 - accuracy: 0.8544 - val_loss: 0.3977 - val_accuracy: 0.8529\n",
      "Epoch 26/300\n",
      "16685/16685 [==============================] - 560s 34ms/step - loss: 0.4034 - accuracy: 0.8543 - val_loss: 0.3922 - val_accuracy: 0.8580\n",
      "Epoch 27/300\n",
      "16685/16685 [==============================] - 560s 34ms/step - loss: 0.4026 - accuracy: 0.8542 - val_loss: 0.3988 - val_accuracy: 0.8529\n",
      "Epoch 28/300\n",
      "16685/16685 [==============================] - 560s 34ms/step - loss: 0.4077 - accuracy: 0.8529 - val_loss: 0.4106 - val_accuracy: 0.8504\n",
      "Epoch 29/300\n",
      "16685/16685 [==============================] - 560s 34ms/step - loss: 0.4080 - accuracy: 0.8529 - val_loss: 0.3981 - val_accuracy: 0.8573\n"
     ]
    }
   ],
   "source": [
    "#황성현\n",
    "from datetime import datetime\n",
    "batch_size=32\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2P_NP%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 )\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2p_np_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2p_np_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "\n",
    "history=smv2_p.fit(X_train_resize,y_train, batch_size = batch_size,\n",
    "                    validation_data=(X_valid_resize,y_valid),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec4adf",
   "metadata": {},
   "source": [
    "# SMV2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "20c7e302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_10 (Bat  (None, 32, 32, 1)        4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 16, 16, 32)        320       \n",
      "                                                                 \n",
      " IRB1 (Inveted_Residual_Bloc  (None, 16, 16, 16)       2288      \n",
      " k)                                                              \n",
      "                                                                 \n",
      " IRB2 (Inveted_Residual_Bloc  (None, 8, 8, 16)         6688      \n",
      " k)                                                              \n",
      "                                                                 \n",
      " IRB3 (Inveted_Residual_Bloc  (None, 4, 4, 32)         19456     \n",
      " k)                                                              \n",
      "                                                                 \n",
      " IRB4 (Inveted_Residual_Bloc  (None, 2, 2, 64)         67584     \n",
      " k)                                                              \n",
      "                                                                 \n",
      " IRB5 (Inveted_Residual_Bloc  (None, 1, 1, 128)        108416    \n",
      " k)                                                              \n",
      "                                                                 \n",
      " IRB6 (Inveted_Residual_Bloc  (None, 1, 1, 1024)       1200640   \n",
      " k)                                                              \n",
      "                                                                 \n",
      " re_lu_103 (ReLU)            (None, 1, 1, 1024)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 1024)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 1024)             4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 62)                63550     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,473,042\n",
      "Trainable params: 1,460,336\n",
      "Non-trainable params: 12,706\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#황성현\n",
    "#multygpu\n",
    "with strategy.scope():\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fd6c868f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/SMV2L_NP20220609-162807\n",
      "Epoch 1/300\n",
      "16685/16685 [==============================] - 1276s 76ms/step - loss: 0.7813 - accuracy: 0.7554 - val_loss: 0.5048 - val_accuracy: 0.8269 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "16685/16685 [==============================] - 1377s 83ms/step - loss: 0.4711 - accuracy: 0.8339 - val_loss: 0.4283 - val_accuracy: 0.8477 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "16685/16685 [==============================] - 1379s 83ms/step - loss: 0.4345 - accuracy: 0.8447 - val_loss: 0.4092 - val_accuracy: 0.8512 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "16685/16685 [==============================] - 1375s 82ms/step - loss: 0.4179 - accuracy: 0.8492 - val_loss: 0.4004 - val_accuracy: 0.8531 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "16685/16685 [==============================] - 1370s 82ms/step - loss: 0.4058 - accuracy: 0.8523 - val_loss: 0.3916 - val_accuracy: 0.8583 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "16685/16685 [==============================] - 1369s 82ms/step - loss: 0.3973 - accuracy: 0.8550 - val_loss: 0.3918 - val_accuracy: 0.8574 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "16685/16685 [==============================] - 1368s 82ms/step - loss: 0.3908 - accuracy: 0.8568 - val_loss: 0.3829 - val_accuracy: 0.8584 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "16685/16685 [==============================] - 1371s 82ms/step - loss: 0.3853 - accuracy: 0.8583 - val_loss: 0.3824 - val_accuracy: 0.8600 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "16685/16685 [==============================] - 1373s 82ms/step - loss: 0.3808 - accuracy: 0.8599 - val_loss: 0.3783 - val_accuracy: 0.8611 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "16685/16685 [==============================] - 1372s 82ms/step - loss: 0.3770 - accuracy: 0.8614 - val_loss: 0.3758 - val_accuracy: 0.8610 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "16685/16685 [==============================] - 1368s 82ms/step - loss: 0.3732 - accuracy: 0.8624 - val_loss: 0.3735 - val_accuracy: 0.8624 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "16685/16685 [==============================] - 1369s 82ms/step - loss: 0.3701 - accuracy: 0.8631 - val_loss: 0.3773 - val_accuracy: 0.8598 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "16685/16685 [==============================] - 1370s 82ms/step - loss: 0.3686 - accuracy: 0.8632 - val_loss: 0.3880 - val_accuracy: 0.8580 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "16685/16685 [==============================] - 1371s 82ms/step - loss: 0.3659 - accuracy: 0.8640 - val_loss: 0.3691 - val_accuracy: 0.8622 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "16685/16685 [==============================] - 1371s 82ms/step - loss: 0.3641 - accuracy: 0.8646 - val_loss: 0.3661 - val_accuracy: 0.8648 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "16685/16685 [==============================] - 1369s 82ms/step - loss: 0.3614 - accuracy: 0.8652 - val_loss: 0.3661 - val_accuracy: 0.8629 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "16685/16685 [==============================] - 1372s 82ms/step - loss: 0.3589 - accuracy: 0.8659 - val_loss: 0.3688 - val_accuracy: 0.8636 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "16685/16685 [==============================] - 1372s 82ms/step - loss: 0.3579 - accuracy: 0.8664 - val_loss: 0.3620 - val_accuracy: 0.8658 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "16685/16685 [==============================] - 1372s 82ms/step - loss: 0.3570 - accuracy: 0.8666 - val_loss: 0.3694 - val_accuracy: 0.8642 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "16685/16685 [==============================] - 1370s 82ms/step - loss: 0.3559 - accuracy: 0.8670 - val_loss: 0.3666 - val_accuracy: 0.8636 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "16685/16685 [==============================] - 1373s 82ms/step - loss: 0.3549 - accuracy: 0.8670 - val_loss: 0.3974 - val_accuracy: 0.8542 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "16685/16685 [==============================] - 1372s 82ms/step - loss: 0.3543 - accuracy: 0.8672 - val_loss: 0.3804 - val_accuracy: 0.8600 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "16685/16685 [==============================] - 1369s 82ms/step - loss: 0.3538 - accuracy: 0.8675 - val_loss: 0.3621 - val_accuracy: 0.8664 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "16685/16685 [==============================] - 1369s 82ms/step - loss: 0.3319 - accuracy: 0.8741 - val_loss: 0.3531 - val_accuracy: 0.8685 - lr: 5.0000e-04\n",
      "Epoch 25/300\n",
      "16685/16685 [==============================] - 1373s 82ms/step - loss: 0.3248 - accuracy: 0.8759 - val_loss: 0.3486 - val_accuracy: 0.8703 - lr: 5.0000e-04\n",
      "Epoch 26/300\n",
      "16685/16685 [==============================] - 1370s 82ms/step - loss: 0.3214 - accuracy: 0.8770 - val_loss: 0.3461 - val_accuracy: 0.8718 - lr: 5.0000e-04\n",
      "Epoch 27/300\n",
      "16685/16685 [==============================] - 1366s 82ms/step - loss: 0.3187 - accuracy: 0.8774 - val_loss: 0.3466 - val_accuracy: 0.8717 - lr: 5.0000e-04\n",
      "Epoch 28/300\n",
      "16685/16685 [==============================] - 1374s 82ms/step - loss: 0.3168 - accuracy: 0.8781 - val_loss: 0.3472 - val_accuracy: 0.8699 - lr: 5.0000e-04\n",
      "Epoch 29/300\n",
      "16685/16685 [==============================] - 1376s 82ms/step - loss: 0.3149 - accuracy: 0.8789 - val_loss: 0.3463 - val_accuracy: 0.8729 - lr: 5.0000e-04\n",
      "Epoch 30/300\n",
      "16685/16685 [==============================] - 1370s 82ms/step - loss: 0.3144 - accuracy: 0.8791 - val_loss: 0.3513 - val_accuracy: 0.8700 - lr: 5.0000e-04\n",
      "Epoch 31/300\n",
      "16685/16685 [==============================] - 1373s 82ms/step - loss: 0.3122 - accuracy: 0.8795 - val_loss: 0.3624 - val_accuracy: 0.8650 - lr: 5.0000e-04\n",
      "Epoch 32/300\n",
      "16685/16685 [==============================] - 1372s 82ms/step - loss: 0.2991 - accuracy: 0.8837 - val_loss: 0.3415 - val_accuracy: 0.8746 - lr: 2.5000e-04\n",
      "Epoch 33/300\n",
      "16685/16685 [==============================] - 1378s 83ms/step - loss: 0.2955 - accuracy: 0.8849 - val_loss: 0.3412 - val_accuracy: 0.8745 - lr: 2.5000e-04\n",
      "Epoch 34/300\n",
      "16685/16685 [==============================] - 1368s 82ms/step - loss: 0.2935 - accuracy: 0.8855 - val_loss: 0.3412 - val_accuracy: 0.8742 - lr: 2.5000e-04\n",
      "Epoch 35/300\n",
      "16685/16685 [==============================] - 1369s 82ms/step - loss: 0.2914 - accuracy: 0.8860 - val_loss: 0.3414 - val_accuracy: 0.8744 - lr: 2.5000e-04\n",
      "Epoch 36/300\n",
      "16685/16685 [==============================] - 1373s 82ms/step - loss: 0.2905 - accuracy: 0.8863 - val_loss: 0.3430 - val_accuracy: 0.8738 - lr: 2.5000e-04\n",
      "Epoch 37/300\n",
      "16685/16685 [==============================] - 1368s 82ms/step - loss: 0.2892 - accuracy: 0.8865 - val_loss: 0.3456 - val_accuracy: 0.8723 - lr: 2.5000e-04\n",
      "Epoch 38/300\n",
      "16685/16685 [==============================] - 1362s 82ms/step - loss: 0.2877 - accuracy: 0.8870 - val_loss: 0.3443 - val_accuracy: 0.8746 - lr: 2.5000e-04\n",
      "Epoch 39/300\n",
      "16685/16685 [==============================] - 1368s 82ms/step - loss: 0.2804 - accuracy: 0.8895 - val_loss: 0.3428 - val_accuracy: 0.8747 - lr: 1.2500e-04\n",
      "Epoch 40/300\n",
      "16685/16685 [==============================] - 1364s 82ms/step - loss: 0.2783 - accuracy: 0.8900 - val_loss: 0.3443 - val_accuracy: 0.8741 - lr: 1.2500e-04\n",
      "Epoch 41/300\n",
      "16685/16685 [==============================] - 1370s 82ms/step - loss: 0.2771 - accuracy: 0.8907 - val_loss: 0.3449 - val_accuracy: 0.8744 - lr: 1.2500e-04\n",
      "Epoch 42/300\n",
      "16685/16685 [==============================] - 1372s 82ms/step - loss: 0.2761 - accuracy: 0.8911 - val_loss: 0.3456 - val_accuracy: 0.8745 - lr: 1.2500e-04\n",
      "Epoch 43/300\n",
      "16685/16685 [==============================] - 1372s 82ms/step - loss: 0.2754 - accuracy: 0.8911 - val_loss: 0.3469 - val_accuracy: 0.8742 - lr: 1.2500e-04\n",
      "Epoch 44/300\n",
      "16685/16685 [==============================] - 1370s 82ms/step - loss: 0.2711 - accuracy: 0.8925 - val_loss: 0.3461 - val_accuracy: 0.8744 - lr: 6.2500e-05\n"
     ]
    }
   ],
   "source": [
    "#황성현\n",
    "from datetime import datetime\n",
    "batch_size=32\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_NP%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1)\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_np_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_np_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_l.fit(X_train_resize,y_train, batch_size = batch_size,\n",
    "                    validation_data=(X_valid_resize,y_valid),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11fa6d8",
   "metadata": {},
   "source": [
    "# 민재형 이거 실행해주세요!!!!\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803a5240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "from datetime import datetime\n",
    "batch_size=32\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_NP%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1)\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_np_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_np_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_l.fit(X_train_resize,y_train, batch_size = batch_size,\n",
    "                    validation_data=(X_valid_resize,y_valid),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418a1312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d43e12c3",
   "metadata": {},
   "source": [
    "SMV2L is best model! we use only SMV2L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a47879",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bae7880",
   "metadata": {},
   "source": [
    "# Fine Tune the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957ad3ae",
   "metadata": {},
   "source": [
    "# Batch size up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f45034d",
   "metadata": {},
   "source": [
    "# Batch 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec50933",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes=62\n",
    "smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "smv2_l.summary()\n",
    "smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0bde72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#천문성\n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_BATCH64_%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "batch_size=64\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_batch64_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_batch64_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_l.fit(X_train_resize,y_train, batch_size = batch_size,\n",
    "                    validation_data=(X_valid_resize,y_valid),                   \n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6334dc5",
   "metadata": {},
   "source": [
    "train logs in SMV2L_batch_up.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d54c8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 41s 7ms/step - loss: 0.3501 - accuracy: 0.8714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3500642478466034, 0.8713958859443665]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_nadam_batch64_best.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243636e7",
   "metadata": {},
   "source": [
    "# Batch 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ecc048",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_classes=62\n",
    "smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "smv2_l.summary()\n",
    "smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778fd64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#천문성\n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_BATCH128_%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "batch_size=128\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_batch128_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_batch128_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_l.fit(X_train_resize,y_train, batch_size = batch_size,\n",
    "                    validation_data=(X_valid_resize,y_valid),                   \n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0183de8",
   "metadata": {},
   "source": [
    "train logs in SMV2L_batch_up.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1af0561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 36s 7ms/step - loss: 0.3537 - accuracy: 0.8674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35373783111572266, 0.8674450516700745]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_nadam_batch128_best.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8c3807",
   "metadata": {},
   "source": [
    "# Batch size up & Learning rateup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd5c266",
   "metadata": {},
   "source": [
    "# smv2l when batch_size=64, lr=0.002 by minsung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c84178dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_9 (Batch (None, 32, 32, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 32)        320       \n",
      "_________________________________________________________________\n",
      "IRB1 (Inveted_Residual_Block (None, 16, 16, 16)        2288      \n",
      "_________________________________________________________________\n",
      "IRB2 (Inveted_Residual_Block (None, 8, 8, 16)          6688      \n",
      "_________________________________________________________________\n",
      "IRB3 (Inveted_Residual_Block (None, 4, 4, 32)          19456     \n",
      "_________________________________________________________________\n",
      "IRB4 (Inveted_Residual_Block (None, 2, 2, 64)          67584     \n",
      "_________________________________________________________________\n",
      "IRB5 (Inveted_Residual_Block (None, 1, 1, 128)         108416    \n",
      "_________________________________________________________________\n",
      "IRB6 (Inveted_Residual_Block (None, 1, 1, 1024)        1200640   \n",
      "_________________________________________________________________\n",
      "re_lu_34 (ReLU)              (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 62)                63550     \n",
      "=================================================================\n",
      "Total params: 1,473,042\n",
      "Trainable params: 1,460,336\n",
      "Non-trainable params: 12,706\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#황성현\n",
    "n_classes=62\n",
    "smv2_l=keras.models.Sequential([\n",
    "    keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "    keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "    Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "    Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "    Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "    Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "    Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "    Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "    keras.layers.ReLU(max_value=6),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "])\n",
    "smv2_l.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab004a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Nadam(learning_rate=0.002)\n",
    "batch_size=64\n",
    "smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536d88cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#황성현 \n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_batch_64_lr_002%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "\n",
    "check_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"SMV2L_batch_64_lr_002.h5\",save_best_only=True)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_l.fit(X_train_resize,y_train, batch_size = batch_size,\n",
    "                    validation_data=(X_valid_resize,y_valid),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_cb, earlystop_cb])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adb7c0e",
   "metadata": {},
   "source": [
    "train logs in np_batch_lr_up_tunining.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c18dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "smv2_l=keras.models.load_model(\"SMV2L_batch_64_lr_002.h5\",\n",
    "                              custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9977cf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5126/5126 [==============================] - 37s 7ms/step - loss: 0.3861 - accuracy: 0.8584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38609299063682556, 0.8584336638450623]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5505d01a",
   "metadata": {},
   "source": [
    "# smv2l when batch_size=256, lr=0.008 by minsung, seounghyun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a489d7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_11 (Batc (None, 32, 32, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 32)        320       \n",
      "_________________________________________________________________\n",
      "IRB1 (Inveted_Residual_Block (None, 16, 16, 16)        2288      \n",
      "_________________________________________________________________\n",
      "IRB2 (Inveted_Residual_Block (None, 8, 8, 16)          6688      \n",
      "_________________________________________________________________\n",
      "IRB3 (Inveted_Residual_Block (None, 4, 4, 32)          19456     \n",
      "_________________________________________________________________\n",
      "IRB4 (Inveted_Residual_Block (None, 2, 2, 64)          67584     \n",
      "_________________________________________________________________\n",
      "IRB5 (Inveted_Residual_Block (None, 1, 1, 128)         108416    \n",
      "_________________________________________________________________\n",
      "IRB6 (Inveted_Residual_Block (None, 1, 1, 1024)        1200640   \n",
      "_________________________________________________________________\n",
      "re_lu_53 (ReLU)              (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 62)                63550     \n",
      "=================================================================\n",
      "Total params: 1,473,042\n",
      "Trainable params: 1,460,336\n",
      "Non-trainable params: 12,706\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#황성현\n",
    "n_classes=62\n",
    "smv2_l=keras.models.Sequential([\n",
    "    keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "    keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "    Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "    Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "    Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "    Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "    Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "    Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "    keras.layers.ReLU(max_value=6),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "])\n",
    "smv2_l.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1887691",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Nadam(learning_rate=0.008)\n",
    "batch_size=256\n",
    "smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43868cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 \n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_batch_256_lr_008%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "\n",
    "check_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"SMV2L_batch_256_lr_008.h5\",save_best_only=True)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_l.fit(X_train_resize,y_train, batch_size = batch_size,\n",
    "                    validation_data=(X_valid_resize,y_valid),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc1efb1",
   "metadata": {},
   "source": [
    "train logs in np_batch_lr_up_tunining.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c8590b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n"
     ]
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"SMV2L_batch_256_lr_008.h5\",\n",
    "                              custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "448f0db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5126/5126 [==============================] - 34s 6ms/step - loss: 0.4856 - accuracy: 0.8300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4856473207473755, 0.8299667835235596]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c61eaa",
   "metadata": {},
   "source": [
    "valid loss is not good. but in train logs, this model arrived 80% accuracy fastly, so we decided use this with learning rate schedular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8da0bff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_13 (Batc (None, 32, 32, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 32)        320       \n",
      "_________________________________________________________________\n",
      "IRB1 (Inveted_Residual_Block (None, 16, 16, 16)        2288      \n",
      "_________________________________________________________________\n",
      "IRB2 (Inveted_Residual_Block (None, 8, 8, 16)          6688      \n",
      "_________________________________________________________________\n",
      "IRB3 (Inveted_Residual_Block (None, 4, 4, 32)          19456     \n",
      "_________________________________________________________________\n",
      "IRB4 (Inveted_Residual_Block (None, 2, 2, 64)          67584     \n",
      "_________________________________________________________________\n",
      "IRB5 (Inveted_Residual_Block (None, 1, 1, 128)         108416    \n",
      "_________________________________________________________________\n",
      "IRB6 (Inveted_Residual_Block (None, 1, 1, 1024)        1200640   \n",
      "_________________________________________________________________\n",
      "re_lu_66 (ReLU)              (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 62)                63550     \n",
      "=================================================================\n",
      "Total params: 1,473,042\n",
      "Trainable params: 1,460,336\n",
      "Non-trainable params: 12,706\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#황성현\n",
    "n_classes=62\n",
    "smv2_l=keras.models.Sequential([\n",
    "    keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "    keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "    Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "    Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "    Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "    Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "    Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "    Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "    keras.layers.ReLU(max_value=6),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "])\n",
    "smv2_l.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b6c4899",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Nadam(learning_rate=0.008)\n",
    "batch_size=256\n",
    "smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0eda21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 \n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_batch_256_lr_008_sch_exp%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 2:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "check_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"SMV2L_batch_256_lr_008_sch_exp.h5\",save_best_only=True)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_l.fit(X_train_resize,y_train, batch_size = batch_size,\n",
    "                    validation_data=(X_valid_resize,y_valid),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_cb, earlystop_cb,lr_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1de370",
   "metadata": {},
   "source": [
    "train logs in np_batch_lr_up_tunining.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0c87e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n"
     ]
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"SMV2L_batch_256_lr_008_sch_exp.h5\",\n",
    "                              custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8634ea54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641/641 [==============================] - 5s 8ms/step - loss: 0.3488 - accuracy: 0.8723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34879040718078613, 0.872304379940033]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l.evaluate(X_valid_resize,y_valid,batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceabf5f",
   "metadata": {},
   "source": [
    "it arrived 87% accuracy faster than 32 batch size, 0.001 learning rate. So we try to finetune with batch size up learning rate up "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bde21c3",
   "metadata": {},
   "source": [
    "# Optimizer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81d3aaa",
   "metadata": {},
   "source": [
    "finetuning - optimizer logs in np_SMV2_optimizer.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893345d9",
   "metadata": {},
   "source": [
    "adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ab2383",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e4bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "from datetime import datetime\n",
    "batch_size=32\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_NP_ADAM%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_adam_np_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_adam_np_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "lr_callback=keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.4)\n",
    "history=smv2_l.fit(X_train_resize,y_train, batch_size = batch_size,\n",
    "                    validation_data=(X_valid_resize,y_valid),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb,lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8c4f9117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 28s 5ms/step - loss: 0.3377 - accuracy: 0.8751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3376833498477936, 0.875054121017456]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_adam_np_best.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74272bcd",
   "metadata": {},
   "source": [
    "rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "#multygpu\n",
    "with strategy.scope():\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c5cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "from datetime import datetime\n",
    "batch_size=32\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2P_NP_RMSPROP%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_rmsprop_np_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_rmsprop_np_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "lr_callback=keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.4)\n",
    "history=smv2_l.fit(X_train_resize,y_train, batch_size = batch_size,\n",
    "                    validation_data=(X_valid_resize,y_valid),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb,lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "52545804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 29s 6ms/step - loss: 0.3403 - accuracy: 0.8740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3402675986289978, 0.874029815196991]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_rmsprop_np_best.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5ddf8d",
   "metadata": {},
   "source": [
    "neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20ed283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "#multygpu\n",
    "with strategy.scope():\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                   optimizer=keras.optimizers.SGD(learning_rate=0.01,momentum=0.9,nesterov=True)\n",
    "                   ,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90e99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "from datetime import datetime\n",
    "batch_size=32\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2P_NP_NAG%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nag_np_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nag_np_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "lr_callback=keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.4)\n",
    "history=smv2_l.fit(X_train_resize,y_train, batch_size = batch_size,\n",
    "                    validation_data=(X_valid_resize,y_valid),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb,lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46af46e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      " 643/5126 [==>...........................] - ETA: 36s - loss: 867.5457 - accuracy: 0.0038"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12420/3944482564.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m smv2_l=keras.models.load_model(\"smv2l_nag_np_best.h5\",\n\u001b[0;32m      2\u001b[0m                              custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msmv2_l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid_resize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1714\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1715\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1716\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1717\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1718\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 954\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    955\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_nag_np_best.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4001779",
   "metadata": {},
   "source": [
    "Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7abd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "#multygpu\n",
    "with strategy.scope():\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                   optimizer=keras.optimizers.SGD(learning_rate=0.01,momentum=0.9)\n",
    "                   ,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15093ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "from datetime import datetime\n",
    "batch_size=32\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2P_NP_MOMENTUM%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_momentum_np_best.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_momentum_np_last.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "lr_callback=keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.4)\n",
    "history=smv2_l.fit(X_train_resize,y_train, batch_size = batch_size,\n",
    "                    validation_data=(X_valid_resize,y_valid),\n",
    "                    epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb,lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e52c8b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 28s 5ms/step - loss: 0.3524 - accuracy: 0.8695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35244783759117126, 0.8694936633110046]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_momentum_np_best.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b486da62",
   "metadata": {},
   "source": [
    "adam is best!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b74cee1",
   "metadata": {},
   "source": [
    "# augmentation + learning rate schedular + adam + batchup learningrate up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61969288",
   "metadata": {},
   "source": [
    "ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eaebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #전민재\n",
    "    #multygpu\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.006)\n",
    "    batch_size=256\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 \n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_lrsch_plat_aug_adam_%Y%m%d-%H%M%S\")\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=3, min_lr=0.000001)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_best_lrsch_plat_aug_adam.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_last_lrsch_plat_aug_adam.h5\",save_best_only=False)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_l.fit(X_train_aug,y_train_aug,\n",
    "                   validation_data=(X_valid_final,y_valid),batch_size = batch_size, \n",
    "                   epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb,reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f765502",
   "metadata": {},
   "source": [
    "train logs in smv2l_adam_best_lrsch_plat_aug.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1dd8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_nadam_best_lrsch_plat_aug_adam.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3d134c",
   "metadata": {},
   "source": [
    "change batch_size 128, learning rate 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9143354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #황성현\n",
    "    #multygpu\n",
    "\n",
    "\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.003)\n",
    "    batch_size=128\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a34c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 \n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_lrsch_plat_aug128%Y%m%d-%H%M%S\")\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=3, min_lr=0.000001)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_best_lrsch_plat_aug128.h5\",save_best_only=True)\n",
    "check_last_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_nadam_last_lrsch_plat_aug128.h5\",save_best_only=True)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history=smv2_l.fit(X_train_aug,y_train_aug,\n",
    "                   validation_data=(X_valid_final,y_valid),batch_size = batch_size, \n",
    "                   epochs=300,callbacks=[tboard_callback, check_best_cb, check_last_cb, earlystop_cb,reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdc4ba9",
   "metadata": {},
   "source": [
    "train logs in smv2l_adam_lrsch_plat_aug_128.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34919ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 39s 8ms/step - loss: 0.3390 - accuracy: 0.8745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3389529585838318, 0.8744931817054749]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_adam_lrsch_plat_aug128.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac1af70",
   "metadata": {},
   "source": [
    "Onecycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155c4985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전민재\n",
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "            rate = max(rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.lr, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30bd1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #황성현 전민재\n",
    "    #multygpu\n",
    "\n",
    "\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "    batch_size=128\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd1161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 전민재\n",
    "from datetime import datetime\n",
    "K = keras.backend\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_lrsch_onecycle_aug128%Y%m%d-%H%M%S\")\n",
    "epochs=50\n",
    "onecycle = OneCycleScheduler(len(X_train) // batch_size * epochs, max_rate=0.003)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_adam_best_lrsch_onecycle_aug128.h5\",save_best_only=True)\n",
    "\n",
    "history=smv2_l.fit(X_train_aug,y_train_aug,\n",
    "                   validation_data=(X_valid_final,y_valid),batch_size = batch_size, \n",
    "                   epochs=epochs,callbacks=[tboard_callback, check_best_cb,onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb8888a",
   "metadata": {},
   "source": [
    "train logs in smv2l_adam_lrsch_onecycle_aug_128.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ac6bdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 40s 8ms/step - loss: 0.3331 - accuracy: 0.8774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33308178186416626, 0.8774136304855347]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_adam_lrsch_onecycle_aug128.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764fa276",
   "metadata": {},
   "source": [
    "# Drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea6b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #황성현 전민재\n",
    "    #multygpu\n",
    "\n",
    "\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "    batch_size=128\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d303adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 전민재\n",
    "from datetime import datetime\n",
    "K = keras.backend\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_lrsch_onecycle_aug_dropout_128%Y%m%d-%H%M%S\")\n",
    "onecycle = OneCycleScheduler(len(X_train) // batch_size * 50, max_rate=0.003)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_adam_best_lrsch_onecycle_aug_dropout_128.h5\",save_best_only=True)\n",
    "\n",
    "history=smv2_l.fit(X_train_aug,y_train_aug,\n",
    "                   validation_data=(X_valid_final,y_valid),batch_size = batch_size, \n",
    "                   epochs=50,callbacks=[tboard_callback, check_best_cb,onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c86bd91",
   "metadata": {},
   "source": [
    "train logs in smv2l_adam_lrsch_onecycle_aug_dropout128.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0470d8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 40s 8ms/step - loss: 0.3265 - accuracy: 0.8785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3265077769756317, 0.8784623146057129]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_adam_lrsch_onecycle_aug_dropout_128.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aadf5d",
   "metadata": {},
   "source": [
    "change epochs 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1f0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #황성현 전민재\n",
    "    #multygpu\n",
    "\n",
    "\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=4,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=8,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=8,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=8,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=8,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "    batch_size=128\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b573fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 전민재\n",
    "from datetime import datetime\n",
    "K = keras.backend\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_lrsch_onecycle_aug_dropout_128_epoch40%Y%m%d-%H%M%S\")\n",
    "epochs=40\n",
    "onecycle = OneCycleScheduler(len(X_train) // batch_size * epochs, max_rate=0.003)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_adam_best_lrsch_onecycle_aug_dropout_128_epoch40.h5\",save_best_only=True)\n",
    "\n",
    "history=smv2_l.fit(X_train_aug,y_train_aug,\n",
    "                   validation_data=(X_valid_final,y_valid),batch_size = batch_size,\n",
    "                   epochs=epochs,callbacks=[tboard_callback, check_best_cb,onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed90f23",
   "metadata": {},
   "source": [
    "train logs in smv2l_adam_lrsch_onecycle_aug_dropout128_epoch40.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58ba0cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 39s 8ms/step - loss: 0.3291 - accuracy: 0.8782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3291375935077667, 0.8781574964523315]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_adam_lrsch_onecycle_aug_dropout_128_epoch40.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_resize,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f3d49d",
   "metadata": {},
   "source": [
    "At seleting model step, we see that smv2l,much simple than smv2p, is better than smv2p. So, how about making more simple model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daed644",
   "metadata": {},
   "source": [
    "# SMV2SL + preprocess input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36356b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #황성현 전민재 IRB6512, maxlr 0.002\n",
    "    #multygpu\n",
    "\n",
    "\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=2,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=4,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=4,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=4,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=4,c=512,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "    batch_size=128\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbf4d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 전민재\n",
    "from datetime import datetime\n",
    "K = keras.backend\n",
    "epochs=40\n",
    "logs = \"logs/\" + datetime.now().strftime(\"smv2l_adam_best_lrsch_onecycle_aug_dropout_128_he_irb6_512_t4_epoch40%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "onecycle = OneCycleScheduler(len(X_train_resize) // batch_size * epochs, max_rate=0.003)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2l_adam_best_lrsch_onecycle_aug_dropout_128_he_irb6_512_t4_epoch40.h5\",save_best_only=True)\n",
    "\n",
    "history=smv2_l.fit(X_train_aug,y_train_aug,\n",
    "                   validation_data=(X_valid_final,y_valid),batch_size = batch_size, \n",
    "                   epochs=epochs,callbacks=[tboard_callback, check_best_cb,onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4fb314",
   "metadata": {},
   "source": [
    "train logs in smv2sl_adam_lrsch_onecycle_aug_dropout_epoch40.lpynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "257bffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 39s 7ms/step - loss: 0.3349 - accuracy: 0.8773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3349411189556122, 0.8773038983345032]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2l_adam_best_lrsch_onecycle_aug_dropout_128_he_irb6_512_t4_epoch40.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block})\n",
    "smv2_l.evaluate(X_valid_final,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af301bdd",
   "metadata": {},
   "source": [
    "# SMV2SL + preprocess input + 1x1 conv2d linear activation + Swap BN and Activation positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7088e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 \n",
    "class Inveted_Residual_Block2(keras.layers.Layer):\n",
    "    def __init__(self,c,s=1,t=1,n=1,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.layers.ReLU(max_value=6)\n",
    "        self.main_layers = [\n",
    "            \n",
    "            ]\n",
    "        self.strides_layers=[\n",
    "           ]\n",
    "        self.s=s\n",
    "        self.t=t\n",
    "        self.c=c\n",
    "        self.n=n\n",
    "        \n",
    "    def build(self,batch_input_shape):\n",
    "        print(self.name,\": batch_input_shape =\",batch_input_shape)\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        self.main_layers = [\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=batch_input_shape[-1]*self.t, kernel_size=1,strides=1, kernel_initializer=initializer,\n",
    "                                padding=\"SAME\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            keras.layers.DepthwiseConv2D(kernel_size=3, strides=1,padding=\"SAME\",kernel_initializer=initializer),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            keras.layers.Conv2D(filters=self.c,kernel_size=1, strides=1,padding=\"SAME\",kernel_initializer=initializer),\n",
    "            ]\n",
    "        self.strides_layers=[\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=batch_input_shape[-1]*self.t, kernel_size=1,strides=1,kernel_initializer=initializer,\n",
    "                                padding=\"SAME\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            keras.layers.DepthwiseConv2D(kernel_size=3, strides=self.s,padding=\"SAME\",kernel_initializer=initializer),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            keras.layers.Conv2D(filters=self.c, kernel_size=1,strides=1,padding=\"SAME\",kernel_initializer=initializer),\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        \n",
    "        for n in range(0,self.n):\n",
    "            if n == 0:\n",
    "                for layer in self.strides_layers:\n",
    "                    Z = layer(Z)\n",
    "            else:\n",
    "                skip_Z = Z\n",
    "                for layer in self.main_layers:\n",
    "                    Z = layer(Z)\n",
    "                \n",
    "                Z += skip_Z\n",
    "    \n",
    "        return Z\n",
    "    \n",
    "    def get_config(self):\n",
    "        base=super().get_config()\n",
    "        return{**base,\"s\":self.s,\"t\":self.t,\"c\":self.c,\"n\":self.n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10acb651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (None, 32, 32, 1)        4         \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 16, 16, 32)        320       \n",
      "                                                                 \n",
      " IRB1 (Inveted_Residual_Bloc  (None, 16, 16, 16)       2288      \n",
      " k2)                                                             \n",
      "                                                                 \n",
      " IRB2 (Inveted_Residual_Bloc  (None, 8, 8, 16)         3424      \n",
      " k2)                                                             \n",
      "                                                                 \n",
      " IRB3 (Inveted_Residual_Bloc  (None, 4, 4, 32)         9856      \n",
      " k2)                                                             \n",
      "                                                                 \n",
      " IRB4 (Inveted_Residual_Bloc  (None, 2, 2, 64)         34048     \n",
      " k2)                                                             \n",
      "                                                                 \n",
      " IRB5 (Inveted_Residual_Bloc  (None, 1, 1, 128)        54400     \n",
      " k2)                                                             \n",
      "                                                                 \n",
      " IRB6 (Inveted_Residual_Bloc  (None, 1, 1, 512)        338432    \n",
      " k2)                                                             \n",
      "                                                                 \n",
      " re_lu_66 (ReLU)             (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                31806     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 476,626\n",
      "Trainable params: 469,808\n",
      "Non-trainable params: 6,818\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "    #이승훈 황성현\n",
    "    #SMV2SL\n",
    "\n",
    "n_classes=62\n",
    "smv2_SL=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block2(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block2(t=2,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block2(t=4,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block2(t=4,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block2(t=4,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block2(t=4,c=512,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    \n",
    "smv2_SL.summary()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "batch_size=128\n",
    "smv2_SL.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bf8bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 전민재\n",
    "from datetime import datetime\n",
    "K = keras.backend\n",
    "epochs=40\n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2SL_adam_best_lrsch_onecycle_aug_epoch40%Y%m%d-%H%M%S\")\n",
    "print(logs)\n",
    "onecycle = OneCycleScheduler(len(X_train_resize) // batch_size * epochs, max_rate=0.003)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"SMV2SL_adam_best_lrsch_onecycle_aug_epoch40.h5\",save_best_only=True)\n",
    "\n",
    "history=smv2_SL.fit(X_train_final,y_train,\n",
    "                   validation_data=(X_valid_final,y_valid),batch_size = batch_size, \n",
    "                   epochs=epochs,callbacks=[tboard_callback, check_best_cb,onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5127c881",
   "metadata": {},
   "source": [
    "train logs in SMV2SL.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cfdb1375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 38s 7ms/step - loss: 0.3275 - accuracy: 0.8801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32748278975486755, 0.8801146149635315]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"SMV2SL_adam_best_lrsch_onecycle_aug_epoch40.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block2})\n",
    "smv2_l.evaluate(X_valid_final,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba25a773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a578b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #황성현 전민재 IRB61024, maxlr 0.003\n",
    "    #multygpu\n",
    "\n",
    "\n",
    "    n_classes=62\n",
    "    smv2_l=keras.models.Sequential([\n",
    "        keras.layers.BatchNormalization(input_shape=[32,32,1]),\n",
    "        keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\"),\n",
    "        Inveted_Residual_Block(t=1,c=16,n=1,s=1,name=\"IRB1\"),\n",
    "        Inveted_Residual_Block(t=2,c=16,n=2,s=2,name=\"IRB2\"),\n",
    "        Inveted_Residual_Block(t=4,c=32,n=2,s=2,name=\"IRB3\"),\n",
    "        Inveted_Residual_Block(t=4,c=64,n=2,s=2,name=\"IRB4\"),\n",
    "        Inveted_Residual_Block(t=4,c=128,n=1,s=2,name=\"IRB5\"),\n",
    "        Inveted_Residual_Block(t=4,c=1024,n=1,s=1,name=\"IRB6\"),\n",
    "        keras.layers.ReLU(max_value=6),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(n_classes,activation=\"softmax\")\n",
    "    ])\n",
    "    smv2_l.summary()\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "    batch_size=32\n",
    "    smv2_l.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2eedab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 전민재\n",
    "from datetime import datetime\n",
    "K = keras.backend\n",
    "epochs=40                                 \n",
    "logs = \"logs/\" + datetime.now().strftime(\"SMV2L_lrsch_onecycle001_dropout_128_he_irb6_1024_epoch40%Y%m%d-%H%M%S\")\n",
    "onecycle = OneCycleScheduler(len(X_train_resize) // batch_size * epochs, max_rate=0.001,start_rate=0.0003)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "check_best_cb=tf.keras.callbacks.ModelCheckpoint(filepath=\"smv2sl_adam_lrsch_onecycle_batch32_lr0.001_epoch40.h5\",save_best_only=True)\n",
    "\n",
    "history=smv2_l.fit(X_train,y_train,\n",
    "                   validation_data=(X_valid_final,y_valid),batch_size = batch_size, \n",
    "                   epochs=epochs,callbacks=[tboard_callback, check_best_cb,onecycle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1a13de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "5126/5126 [==============================] - 40s 8ms/step - loss: 0.3219 - accuracy: 0.8802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32189807295799255, 0.8801512122154236]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv2_l=keras.models.load_model(\"smv2sl_adam_lrsch_onecycle_batch32_lr0.001_epoch40.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block2})\n",
    "smv2_l.evaluate(X_valid_final,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f9ad55",
   "metadata": {},
   "source": [
    "smv2sl_adam_lrsch_onecycle_batch32_lr0.001_epoch40 is best model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c8a432",
   "metadata": {},
   "source": [
    "# test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b2ca8142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n"
     ]
    }
   ],
   "source": [
    "best_model=keras.models.load_model(\"smv2sl_adam_lrsch_onecycle_batch32_lr0.001_epoch40.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a436cc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3636/3636 [==============================] - 28s 8ms/step - loss: 0.3187 - accuracy: 0.8796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3186957836151123, 0.8795766830444336]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(X_test_final,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a789809e",
   "metadata": {},
   "source": [
    "# lerning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eed5e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e5dfdf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cec5491f6c0b620a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cec5491f6c0b620a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/SMV2L_lrsch_onecycle001_dropout_128_he_irb6_1024_epoch40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52847af",
   "metadata": {},
   "source": [
    "# test with handwrite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2db5cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이승훈\n",
    "\n",
    "loaded_data=np.loadtxt('./datasets/Emnist/Estela_ExtendMnist-1.csv', delimiter=\",\",dtype='uint8')\n",
    "y_estela_full,X_estela_full=np.split(loaded_data,[1],axis=1)\n",
    "np.savetxt('./datasets/Emnist/estela_data.csv',X_estela_full,fmt='%d',delimiter=',')\n",
    "np.savetxt('./datasets/Emnist/estela_label.csv',y_estela_full,fmt='%d',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "11d34555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#작성자 전민재\n",
    "import csv\n",
    "def load_estela_Emist(file_path=None,exsitNumpy=False, needTranspose=False):\n",
    "    if (exsitNumpy == False):\n",
    "        #\"./emnist-byclass-test.csv\"\n",
    "        #train-set\n",
    "        #\"공용/datasets/Emnist/\" 위치에 csv 저장 \n",
    "        if file_path is None:\n",
    "            csv_estela_data_file = open(\"./datasets/Emnist/estela_data.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "            csv_estela_label_file = open(\"./datasets/Emnist/estela_label.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "        else:\n",
    "            csv_estela_data_file = open(file_path, \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "            csv_estela_label_file = open(file_path, \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "        \n",
    "        \n",
    "        f_estela = csv.reader(csv_estela_data_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "        l_estela=csv.reader(csv_estela_label_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "\n",
    "        X_estela=[]\n",
    "        y_estela=[]\n",
    "        \n",
    "        for i, row in enumerate(f_estela):\n",
    "                #행마다 int로 형변환\n",
    "                for idx, char in enumerate(row):\n",
    "                    row[idx]=int(char)\n",
    "                #train\n",
    "                #data 추가    \n",
    "                X_estela.append(row)\n",
    "        for i, row in enumerate(l_estela):\n",
    "\n",
    "                #train\n",
    "                #label 추가\n",
    "                y_estela.append(int(row[0]))\n",
    "        \n",
    "\n",
    "        \n",
    "        X_estela=np.array(X_estela,dtype=np.uint8)\n",
    "        X_estela=X_estela.reshape(-1,28,28)\n",
    "        \n",
    "        \n",
    "        \n",
    "        csv_estela_data_file.close()\n",
    "        csv_estela_label_file.close()\n",
    "        \n",
    "        #kaggle dataset이 시계반대방향으로 90도 회전 되있고 상하 반전 되어있음\n",
    "        def rotate_90(m):\n",
    "            N = len(m)\n",
    "            ret = [[0] * N for _ in range(N)]\n",
    "\n",
    "            for r in range(N):\n",
    "                for c in range(N):\n",
    "                    ret[c][N-1-r] = m[r][c]\n",
    "            return np.array(ret,dtype=np.uint8)\n",
    "\n",
    "        def vreflect(m):\n",
    "            N = len(m)\n",
    "            ret = [[0] * N for _ in range(N)]\n",
    "\n",
    "            for r in range(N):\n",
    "                for c in range(N):\n",
    "                    ret[r][c] = m[r][N-1-c]\n",
    "            return np.array(ret,dtype=np.uint8)\n",
    "        \n",
    "        if needTranspose == True:\n",
    "                \n",
    "                #회전\n",
    "                for idx,i in enumerate(X_estela):\n",
    "                    X_estela[idx]=rotate_90(i)\n",
    "                #상하반전\n",
    "                for idx,i in enumerate(X_estela):\n",
    "                    X_estela[idx]=vreflect(i)\n",
    "        np.save('./X_estela',X_estela)\n",
    "        np.save('./y_estela',y_estela)       \n",
    "                \n",
    "              \n",
    "        \n",
    "        \n",
    "        \n",
    "    X_estela=np.load('./X_estela.npy')\n",
    "    y_estela=np.load('./y_estela.npy')\n",
    "    \n",
    "    return X_estela, y_estela\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "50fe03cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6199, 28, 28), (6199,))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_estela, y_estela = load_estela_Emist(exsitNumpy=False)\n",
    "X_estela.shape, y_estela.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8a615507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현, jmj\n",
    "X_estela=np.reshape(X_estela,[-1,28,28,1])\n",
    "X_estela_resize=np.uint8(tf.image.resize(X_estela, [32, 32]))\n",
    "X_estela_final=keras.applications.mobilenet_v2.preprocess_input(np.array(X_estela_resize,np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a1a28577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 2s 9ms/step - loss: 5.8726 - accuracy: 0.1736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.872628211975098, 0.17357638478279114]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(X_estela_final,y_estela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906714ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df2c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
