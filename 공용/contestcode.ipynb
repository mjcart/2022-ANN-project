{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3e6f4b5-6a62-4d1f-a9b6-c9d6fe732b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version:  1.0.2\n",
      "TF version:  2.8.0\n",
      "GPU installed:  True\n",
      "4 Physical GPUs, 4 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-15 14:40:25.638171: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-15 14:40:28.958447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14786 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:19:00.0, compute capability: 7.5\n",
      "2022-06-15 14:40:28.962896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14786 MB memory:  -> device: 1, name: Quadro RTX 5000, pci bus id: 0000:1a:00.0, compute capability: 7.5\n",
      "2022-06-15 14:40:28.964711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14786 MB memory:  -> device: 2, name: Quadro RTX 5000, pci bus id: 0000:67:00.0, compute capability: 7.5\n",
      "2022-06-15 14:40:28.966495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14605 MB memory:  -> device: 3, name: Quadro RTX 5000, pci bus id: 0000:68:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "print(\"sklearn version: \", sklearn.__version__)\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "print(\"TF version: \", tf.__version__)\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "# GPU test\n",
    "print(\"GPU installed: \",tf.test.is_built_with_gpu_support())\n",
    "\n",
    "# To prevent \"CUDNN_STATUS_ALLOC_FAILED\" error with GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "    \n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"cnn\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "    \n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")    \n",
    "\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7418618c-4977-411b-be53-de885ab20de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdc72d63-27a6-4324-844f-b68aeb5b7c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현 \n",
    "class Inveted_Residual_Block2(keras.layers.Layer):\n",
    "    def __init__(self,c,s=1,t=1,n=1,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.layers.ReLU(max_value=6)\n",
    "        self.main_layers = [\n",
    "            \n",
    "            ]\n",
    "        self.strides_layers=[\n",
    "           ]\n",
    "        self.s=s\n",
    "        self.t=t\n",
    "        self.c=c\n",
    "        self.n=n\n",
    "        \n",
    "    def build(self,batch_input_shape):\n",
    "        print(self.name,\": batch_input_shape =\",batch_input_shape)\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        self.main_layers = [\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=batch_input_shape[-1]*self.t, kernel_size=1,strides=1, kernel_initializer=initializer,\n",
    "                                padding=\"SAME\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            keras.layers.DepthwiseConv2D(kernel_size=3, strides=1,padding=\"SAME\",kernel_initializer=initializer),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            keras.layers.Conv2D(filters=self.c,kernel_size=1, strides=1,padding=\"SAME\",kernel_initializer=initializer),\n",
    "            ]\n",
    "        self.strides_layers=[\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=batch_input_shape[-1]*self.t, kernel_size=1,strides=1,kernel_initializer=initializer,\n",
    "                                padding=\"SAME\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            keras.layers.DepthwiseConv2D(kernel_size=3, strides=self.s,padding=\"SAME\",kernel_initializer=initializer),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            keras.layers.Conv2D(filters=self.c, kernel_size=1,strides=1,padding=\"SAME\",kernel_initializer=initializer),\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        \n",
    "        for n in range(0,self.n):\n",
    "            if n == 0:\n",
    "                for layer in self.strides_layers:\n",
    "                    Z = layer(Z)\n",
    "            else:\n",
    "                skip_Z = Z\n",
    "                for layer in self.main_layers:\n",
    "                    Z = layer(Z)\n",
    "                \n",
    "                Z += skip_Z\n",
    "    \n",
    "        return Z\n",
    "    \n",
    "    def get_config(self):\n",
    "        base=super().get_config()\n",
    "        return{**base,\"s\":self.s,\"t\":self.t,\"c\":self.c,\"n\":self.n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b66d307-09bd-42ff-8cc5-2b96ea051796",
   "metadata": {},
   "outputs": [],
   "source": [
    "#황성현\n",
    "class Inveted_Residual_Block(keras.layers.Layer):\n",
    "    def __init__(self,c,s=1,t=1,n=1,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.layers.ReLU(max_value=6)\n",
    "        self.main_layers = [\n",
    "            \n",
    "            ]\n",
    "        self.strides_layers=[\n",
    "           ]\n",
    "        self.s=s\n",
    "        self.t=t\n",
    "        self.c=c\n",
    "        self.n=n\n",
    "        \n",
    "    def build(self,batch_input_shape):\n",
    "        print(self.name,\": batch_input_shape =\",batch_input_shape)\n",
    "        \n",
    "        self.main_layers = [\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=batch_input_shape[-1]*self.t, kernel_size=1,strides=1, \n",
    "                                padding=\"SAME\", activation=self.activation),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.DepthwiseConv2D(kernel_size=3, strides=1,padding=\"SAME\", activation=self.activation),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=self.c,kernel_size=1, strides=1,padding=\"SAME\",activation=self.activation),\n",
    "            ]\n",
    "        self.strides_layers=[\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=batch_input_shape[-1]*self.t, kernel_size=1,strides=1,\n",
    "                                padding=\"SAME\", activation=self.activation),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.DepthwiseConv2D(kernel_size=3, strides=self.s,padding=\"SAME\",activation=self.activation),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(filters=self.c, kernel_size=1,strides=1,padding=\"SAME\",activation=self.activation),\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        \n",
    "        for n in range(0,self.n):\n",
    "            if n == 0:\n",
    "                for layer in self.strides_layers:\n",
    "                    Z = layer(Z)\n",
    "            else:\n",
    "                skip_Z = Z\n",
    "                for layer in self.main_layers:\n",
    "                    Z = layer(Z)\n",
    "                \n",
    "                Z += skip_Z\n",
    "    \n",
    "        return Z\n",
    "    \n",
    "    def get_config(self):\n",
    "        base=super().get_config()\n",
    "        return{**base,\"s\":self.s,\"t\":self.t,\"c\":self.c,\"n\":self.n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0eaf885e-ad6e-4350-9965-258f7392f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#작성자 전민재\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "#contest csv파일명 바꿔!\n",
    "csv_data_file = open(\"./emnist-byclass-test.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" ) #리스트 형식 \n",
    "\n",
    "\n",
    "\n",
    "f = csv.reader(csv_data_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "\n",
    "X_contest=[]\n",
    "y_contest=[]\n",
    "\n",
    "\n",
    "for i, row in enumerate(f):\n",
    "    #행마다 int로 형변환\n",
    "    for idx, char in enumerate(row):\n",
    "        row[idx]=int(char)\n",
    "    #train\n",
    "    #data 추가    \n",
    "    X_contest.append(np.uint8(row[1:]))\n",
    "    y_contest.append(np.float32(row[0]))\n",
    "\n",
    "#데이터셋의 transpose 대비\n",
    "def rotate_90(m):\n",
    "    N = len(m)\n",
    "    ret = [[0] * N for _ in range(N)]\n",
    "    \n",
    "    for r in range(N):\n",
    "        for c in range(N):\n",
    "            ret[c][N-1-r] = m[r][c]\n",
    "    return np.array(ret)\n",
    "\n",
    "def vreflect(m):\n",
    "    N = len(m)\n",
    "    ret = [[0] * N for _ in range(N)]\n",
    "    \n",
    "    for r in range(N):\n",
    "        for c in range(N):\n",
    "            ret[r][c] = m[r][N-1-c]\n",
    "    return np.array(ret)\n",
    "\n",
    "\n",
    "#contest set \n",
    "X_contest=np.array(X_contest)\n",
    "y_contest=np.array(y_contest)\n",
    "X_contest=X_contest.reshape(-1,28,28)\n",
    "\n",
    "#만약 data set들이 transpose 되어있다면 사용하자\n",
    "#회전\n",
    "#for idx,i in enumerate(X_contest):\n",
    "#    X_contest[idx]=rotate_90(i)\n",
    "#상하반전\n",
    "#for idx,i in enumerate(X_contest):\n",
    "#    X_contest[idx]=vreflect(i)\n",
    "\n",
    "X_contest=tf.reshape(X_contest,[-1,28,28,1])\n",
    "X_contest_resize=np.uint8(tf.image.resize(X_contest, [32, 32]))\n",
    "X_contest_final=keras.applications.mobilenet_v2.preprocess_input(np.array(X_contest_resize,np.float32))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d430c4ca-a699-4a85-8b2e-c1b44cd928a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([116323, 28, 28, 1]), tf.uint8, (116323,), dtype('float32'))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_contest.shape,X_contest.dtype,y_contest.shape,y_contest.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9353a8e-a28b-4cb2-8987-39296351eb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRB1 : batch_input_shape = (None, 16, 16, 32)\n",
      "IRB2 : batch_input_shape = (None, 16, 16, 16)\n",
      "IRB3 : batch_input_shape = (None, 8, 8, 16)\n",
      "IRB4 : batch_input_shape = (None, 4, 4, 32)\n",
      "IRB5 : batch_input_shape = (None, 2, 2, 64)\n",
      "IRB6 : batch_input_shape = (None, 1, 1, 128)\n",
      "3636/3636 [==============================] - 42s 12ms/step - loss: 0.3187 - accuracy: 0.8796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3186958134174347, 0.8795766830444336]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 이름 바꾸기!\n",
    "best_model=keras.models.load_model(\"smv2l_adam_lrsch_onecycle001_aug_dropout_128_he_irb6_512_noact.h5\",\n",
    "                             custom_objects={\"Inveted_Residual_Block\":Inveted_Residual_Block2})\n",
    "best_model.evaluate(X_contest_final,y_contest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "76a2ea7e-e10b-4a49-b6be-32a179aad272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "c=X_contest[0]\n",
    "\n",
    "\n",
    "plt.imshow(c, cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f4a0d8-6ca0-431c-8466-889236fdaf69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3554df3-a334-4e20-b69e-963ccb180908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c8bbcb-8ddb-4379-88db-ca8adba356b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c6b3c-10a8-4de4-bf73-83e18ad7b9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
